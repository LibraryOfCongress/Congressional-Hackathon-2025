Title: 0915 1500 Committee on Veterans' Affairs 118596
Description: Hearing: Oversight: Advancing VA Care Through Artificial Intelligence

    Subcommittee on Technology Modernization
Channel: 33 - VA 0360
Recorded On: 9/15/2025 2:45:00 PM
Original Air Date: 9/15/2025
Transcript Generated by SnapStream
==================================



[2:58:08 PM]

morning, the subcommittee will come to order, and without objection, the chair may declare a recess at any time. Like many who have worn the uniform and received va health care, I know the frustration. When the system is slow, the paperwork stacks up, or the technology fails or doesn't lead us in the direction we're trying to go. And that's why this subcommittee's work is so critical, and why it's important that we have the folks here joining us today. It's our duty to ensure va's technology is efficient and reliable, helping veterans rather than standing in the way of their care. And that brings us to the focus of today's hearing artificial intelligence, or ai, as it's, of course, commonly referred to right now. For some, ai sounds like a science fiction movie. We've all seen many of them, something only computer scientists worry about, or even something 

[3:04:14 PM]

Ng together to have a frank conversation about the underlying it challenges at the department of veterans affairs and how we can support the va in closing those gaps through technology. However, today's review of artificial intelligence use cases at the veterans health administration feels like a distraction. Va is struggling with the basics. We are here discussing the newest technologies while va is still working with a crumbling it infrastructure and still grapples to modernize systems and workflows. As ranking member on the technology modernization subcommittee, I am certainly excited by the potential of both ai and innovation. I could improve some va's challenges through large language models and higher processing speeds. We have seen promising studies of providers using ai to identify cancers more easily, improve patient outcomes, and ease clinician burnout by taking on 

[3:05:15 PM]

more administrative tasks. Va has certainly been a leader in the research, development, and widespread usage of a number of significant and groundbreaking technologies, and it stands to do so again with ai. However, success in these efforts requires adequate resources and investments in its budgets, its processes, and its people. Veterans chose va choose va for the community it provides, for the people it employs, and for the fact that it is not driven by profit. With va does best is make veterans feel seen and understood. As we have seen, ai can be a tool to provide decision support, ease, provider burden and help with note taking so doctors can be more present with the patient. But we should also acknowledge that it is not the answer to every challenge the va faces. Also, we as a committee and as congress need to have a real conversation about ai policy and how to implement it safely. 

[3:06:15 PM]

I am excited about the opportunities that ai presents, but I'm not convinced that va is prepared to deploy this technology just yet. I have a number of concerns that I hope to address today, like the lack of regulation and governance structures and the need for better transparency around what data is involved in training such models further. Like all technology modernization efforts, implementing ai successfully requires a highly skilled, adequately staffed workforce. Almost two weeks ago, the acting head of the department on government efficiency stressed the need to, quote, hire and empower great tech talent in government. End quote. I couldn't agree more with that. However, I think we should all note the irony of that statement, considering oit is proposing a massive reorganization and intends to cut at least 20% of its workforce, success is also reliant on strong it leadership. 

[3:07:16 PM]

If oit is in fact undergoing significant changes to its organizational structure, priorities, list and workforce makeup, we need a confirmed chief information officer at va. This position is particularly critical as we see the acceleration and progression of modernization efforts at the department. It seems the va still lacks a coherent enterprise it strategy, leaving projects like ai integration to happen in silos. Without stable and competent leadership, veterans and va employees will continue to be stuck with cobbled together systems and workflows that don't meet their needs. Rather than a solid strategy for technology usage to guide its decision making, I hope that we can get some clarity into the administration's plan to propose a nominee for the Cao position, and that one, and that one can be confirmed before many of these substantial changes occur. 

[3:08:18 PM]

Lastly, I understand the subcommittee held a similar hearing in January of 2024, though neither I nor the chairman were on the subcommittee at that point in that hearing. Data privacy was an intrinsic part of the discussion. I hope that it still is the case today, as we become more interconnected through technology advancements like artificial intelligence, we must become increasingly aware of the concerns about the privacy of users data, especially in healthcare, since since this last hearing, the department has been entangled in multiple cybersecurity incidents which have potentially placed veterans data at risk. Though many of these breaches have been targeted at va contracts have been targeted at va contractors, veterans data has still been implicated, and va maintains some responsibility for its safety. Though I do feel that this hearing is perhaps too early, considering va has yet 

[3:09:19 PM]

to develop and release some of its policies and plans to align its efforts with the administration's. I hope to hear from our va witnesses today about how data privacy and security, as well as the views of va employees and patients, will be integrated into such plans. Thank you. And I yield back, Mr. Chairman. 
>> Thank you. Ranking member Basinski and I join you in making sure that we have adequate ethics guardrails around this. And certainly privacy is paramount in that, uh, as well. Um, and now I want to introduce our witnesses. And again, thank you for joining us today from the department of veteran affairs. We have Mr. Charles Worthington, the chief technology officer and chief artificial intelligence officer. Thank you for being here. Accompanying Mr. Worthington is doctor Evan Carey, the acting director over the national artificial intelligence institute at the va. We also have Mr. Sid gothic. Did I say that correctly? Thank you. The 

[3:10:19 PM]

chief technical advisor from the national artificial intelligence association and doctor Mohammed ghassemi, an assistant professor at Michigan state university. Go green, thank you for being here today as well. Um, and finally, from the government accountability office, we have miss Carol Harris, a familiar face to all of us on this committee. Thank you again for being here and joining us. Um, and she's also the director of it and cybersecurity at the GAO. And, uh, again, thank you all for being here at this time. I ask the witnesses to please stand and raise your right hand. Do you solemnly swear, under penalty of perjury, that the testimony you're about to provide is the truth, the whole truth, and nothing but the truth? Thank you. And let the record reflect that. All witnesses have answered in the affirmative. Mr. Charles Worthington, you are now recognized for five minutes to deliver your opening statement on behalf of va. 
>> Chairman Barrett, ranking member Basinski, and distinguished members of the subcommittee, thank you for the opportunity to discuss the 

[3:11:20 PM]

department of veterans affairs use of artificial intelligence to enhance healthcare and services for veterans. Your steadfast support of the veterans and their families is invaluable. I'm joined today by doctor Evan Carey, acting director of the national eye institute in the digital health office of the veterans health administration. While ai is not new to va, recent advancements in ai systems present a tremendous opportunity to improve va services. When used effectively, ai can improve the efficiency and accuracy of many time consuming and error prone tasks that create burdens for va staff and veterans alike. That's why va is rapidly working to capitalize on this technology. Our strategic vision is to make va a leader in ai, providing faster services, higher quality care and more cost effective operations. We will aggressively deploy this new technology while remaining committed to strong controls that ensure security, privacy and effectiveness of our technology systems. We have distilled this vision into five key priorities. First, we are aggressively expanding ai access across our workforce. 

[3:12:22 PM]

Second, we are reimagining high impact workflows through ai and automation. Third, we're prioritizing investment in data and infrastructure that supports those high potential use cases. Fourth, we are cultivating an ai ready workforce. And finally, we're executing transparent and effective governance, an essential requirement to maintain veterans trust. Va is already bringing this strategy to life, making significant investments in ai driven tools. In 2020, for our ai, inventory had 227 use cases in it, which was nearly 100 more than the previous year. And we expect this growth to continue in 2025 as we prepare for our December update to this inventory. These investments are delivering tangible results. I'm pleased to report that all va employees now have access to secure generative ai tool to assist them with their work, and in surveys, users of this tool are reporting that it's saving them over two hours per week. Additionally, over 2000 va staff and contract software developers are using an ai software development copilot tool, enabling faster delivery 

[3:13:23 PM]

of features that help veterans. Ai is also revolutionizing clinical care. In fact, 82% of va's I use cases come from the veterans health administration va stratification tool for opioid risk mitigation uses machine learning to identify veterans at high risk of overdose and suicide, enabling healthcare teams to review and intervene effectively. Since 2017, the reach vet program, as you mentioned, has used ai algorithms to identify over 130,000 veterans at elevated risk, improving outpatient care and reducing suicide attempts. Ai assisted colonoscopy devices have increased adenoma detection rates by 21%, reducing late stage cancer incidence and mortality. And thanks to groundbreaking, groundbreaking research by folks like doctor Rafi Hagopian and doctor Evan Carey, va is exploring how ai could help providers detect heart disease earlier by reviewing the millions of ct scans that are not currently evaluated for cardiovascular disease risk at all. As we advance our ai deployments, protecting veterans data remains paramount. All ai systems approved for use 

[3:14:25 PM]

at va must meet va's rigorous security and privacy standards before receiving an authority to operate. Additionally, consistent with omb policy, we conduct a thorough agency level review of each ai use case to ensure that it meets the government's standards. We will publish the results of this review in our annual ai inventory, positioning us as one of the most transparent healthcare systems in the country with regards to our use of artificial intelligence. Despite our progress, adopting ai tools does present challenges. As you mentioned, integrating new ai solutions with a complex system architecture and balancing innovation with stringent security compliance is crucial. Recruiting and retaining ai talent remains difficult, and scaling commercial ai tools incurs additional costs. This underscores the importance of full congressional funding for va to continue this critical work. In conclusion, the department of veterans affairs is committed to harnessing ai to improve the lives of veterans through strategic investments in ai tools and workforce capabilities. We strive to deliver faster, higher quality, and more cost 

[3:15:27 PM]

effective services. Your continued support is vital for va to lead in ai innovation and set a benchmark for responsible ai use in government. Thank you for the opportunity to discuss our strategy and we look forward to your questions. 
>> Thank you, Mr. Worthington. The written statement. Mr. Worthington will be entered into the hearing record. Mr. Tech, you are now recognized for five minutes to deliver your opening statement. 
>> Thank you very much, chairman. 
>> Is your microphone on, sir? There you go. 
>> My name is sid Gottschalk, and for almost three decades, I've designed and deployed artificial intelligence and forecasting systems across finance, healthcare, pharmaceuticals, media and government. I currently serve as the chief technology officer, chief technology advisor for the national artificial intelligence association, the premier organization representing 1500 businesses in the advancement of ai. And I'm also the founder and chief executive officer of increase alpha, where we use artificial 

[3:16:27 PM]

intelligence to predict stock prices. And we licensed these predictions to hedge funds in the federal government. I served in the general services administration for four years, where I was the director of the data and analytics center of excellence. In that role, I coauthored the federal ai maturity model, uh, three years before I took the world by storm. I also contributed previous executive orders on the critical issues of data privacy and data security. At increase alpha, I increased a predict. I architected a predictive ai model that generates alpha once thought impossible. A deep learning system that exceptionally accurate at predicting equity prices increased alpha far exceeds multiple industry benchmarks, including accuracy, Sharpe ratio, and alpha generation. The solution itself is not based on large, large language models at all, but is purpose built designed for this specific need. I want to emphasize that this company and our solution is completely unrelated to the department of veterans affairs, and has no bearing on today's testimony. I mentioned it only as an example of how ai, when carefully designed with a clear purpose, 

[3:17:27 PM]

can achieve exceptional effectiveness. Taken together, this diverse background spanning academia, government, and industry has given me the rare opportunity to actually build ai systems that work well in the real world. Because I've spent my career outside the orthodox world of academia, venture capital, and big tech, I'm also not beholden to herd mentality. Instead, I bring an expert, independent perspective, which is especially valuable now when much of the world is caught up in the art of the possible. With ai, then what is most urgently needed is a sober understanding of what is safe, practical and ready to serve the public. Llms like chatgpt and gemini are a powerful subset of ai, but they come with their own set of problems, specifically in healthcare, where hallucinations and sycophancy on the part of chatbots can lead to susceptible users down psychological rabbit holes, which is why it's important to clarify that ai is bigger than just chatgpt and its competitors. To use an analogy, the steam engine transforms society, fueling the industrial revolution. While steam power still exists today, it gave way 

[3:18:29 PM]

to other forms of power over time until steam engines were used to create the first railroads. No human had ever traveled faster than a horse. This new form of transportation opened the world's eyes to what is possible. Just as chatgpt has shown the world the art of the possible with artificial intelligence. But early train travel was dangerously unreliable, accidents were frequent, derailments common, and thousands of lives were lost before rail systems matured into safe networks. We know today the lesson is clear revolutionary technologies will evolve and improve over time when the private sector and government work in collaboration. The same applies to artificial intelligence, as a committee gathers information on how to modernize technology at the va, I'd like to offer a few pieces of advice from my many decades of frontlines at building and implementing advanced analytical solutions. As I mentioned, for the last several years, the world has been consumed with llms to the point where ai has become synonymous with it. However, that is not the case. Many other types of ai may have 

[3:19:29 PM]

similarities to these models, but function very differently. Technologies that specialize in interpreting and understanding images, video and audio, for example, or technologies that are better suited to working with numbers and symbols instead of words. A new technology that has yet to be invented. There's an old adage that when you are a hammer, everything looks like a nail. The world has become so enamored with llms, and rightfully so. Interacting with them can feel magical, giving you the sense that they are real people, but they are not. This may be why little to no investment is being made in these other areas. At increase alpha, we demonstrated clearly what can be done with other forms of artificial intelligence. I began building our models at the same time as the research underlying chatgpt was was published. I'd also encountered the same compute, cost, energy, and reliance on nvidia. We still we see today, but I took a different approach to conserve resources and focus on simplification using predictive intelligence, which led to lean ai models that use a minuscule amount of data compared to llms, and which are small enough to run on a cell 

[3:20:31 PM]

phone. What does all this mean for the va and the well-being and care of our veterans? I can't claim to know. No one really does, but I want to leave you with a prediction. I believe that we truly are on the verge of a scale of a revolution, on the scale of the industrial revolution. So if I could leave you with one idea today, it would be this ai is much bigger than today's llms, and it is these technologies, many of which have yet to be invented, that will enable the va to execute on its mission. Thank you. 
>> Thank you. Uh, Mr. Gatwick, the written statement of Mr. Gatwick will be entered into the hearing record. And, uh, appreciate your remarks. I think if we all use chatgpt for cat memes, it will not be meeting its full potential and leaving a lot of things behind. So thank you. Um, doctor ghassemi, you're now recognized for five minutes to deliver your opening statement. 
>> Chairman, ranking member, 

[3:21:31 PM]

and members of the subcommittee, thank you for the opportunity to speak today. I am a scientist and an entrepreneur that's focused on artificial intelligence, but especially its applications to healthcare. The views I'm going to share today are my own, but they're informed by roles I've played as a professor at Michigan state university, where I direct a research laboratory on ai and its applications to the health sciences. I'm also going to bring a perspective, as the founder of an ai consultancy, gamut corporation, which has helped large pharmaceutical companies, insurance companies, as well as health systems plan and execute their ai strategy. I want to be clear, I'm not a veteran health specialist. My perspective is on how artificial intelligence can broadly advance care in ways 

[3:22:32 PM]

directly relevant to the needs of patients. And this very critically includes our veterans. The subcommittee has identified in their invitation letter three priorities for ai and health. These were transforming health care delivery, streamlining services and improving outcomes. So I'm going to frame my remarks around three roles that ai can play to help with these three priorities. The three roles are automation, which is reducing low value work through the use of machines, augmentation, which is having a machine assist a human in a task. So to strengthen clinical decision making, as an example and insights, which is allowing us to extract complex patterns from data patterns far too complex for us to discern just with our human intuitions alone. 

[3:23:33 PM]

So let's talk about these three. First, ai can can transform what happens during care itself. Clinicians today spend hours on paperwork, but ai scribes can generate notes automatically so they can focus more fully on patients. We've heard that from more than one person in the conversation today in emergency room. Decision tools powered by ai can help identify the sickest patients sooner and get them treated faster. And continuous monitoring systems can pick up on the early signs of decline, like sepsis, long before they would be obvious to our human eyes. These tools make the encounter safer, timelier, and more patient centered. Second, ai can not only streamline what happens during care, it can streamline the plumbing of health care itself. Missed appointments, 

[3:24:36 PM]

waste, scarce clinician time, automated reminder systems which don't have to use a large language model or a sophisticated tool like chatgpt, can reduce these no shows and save that time. Patients also too often fall through the cracks between primary care and specialist visits. Ai can flag missing referral information, track follow ups and prevent all these gaps. And when imaging or labs reveal unexpected findings like, god forbid, a lung nodule discovered by chance, eye tracking systems can ensure these findings are followed up on so that the treatable conditions don't get overlooked. This is how we reduce wasted effort and ensure smoother, more reliable care. In conclusion, artificial intelligence is not a silver bullet. I say this as a person 

[3:25:39 PM]

who's been working on developing the methods for several years, but it can already help with the subcommittee's three priorities. It works best when it reduces low value work, strengthens rather than replaces clinical judgment, and turns complex data into actionable insights. To succeed, we need disciplined pilots, clear metrics and safeguards for safety, equity, and privacy. If deployed with Claire with care, I can return time from paperwork to patients. Ensure that critical findings are not missed, and support clinicians in their hardest decisions. I look forward to our conversation and am grateful for the invitation to be here with you today. 
>> Thank you. Doc. Uh, the, uh, written statement of doctor ghassemi will be entered into the hearing record. And, miss Harris, you're now recognized for five minutes to deliver your opening statement on behalf of GAO. 
>> Chairman Barrett, ranking member Basinski, and members of the subcommittee, thank you for 

[3:26:39 PM]

inviting us to testify today on the use of artificial intelligence at va develops in generative ai, which is a subset of ai which can create text, images, video and other content when prompted by a user have revolutionized how the technology can be used in many industries, including healthcare and at va and other federal agencies. Ai holds substantial promise for improving the operations of government agencies. However, it can increase risk for agencies and poses unique oversight challenges. Because the source of information used by ai is not always clear or accurate, given the fast pace at which ai is evolving, the government must be proactive in understanding its complexities, risks, and societal consequences. It should also be noted that va has experienced long standing challenges in managing its ai projects and programs, raising questions about the efficiency and effectiveness of its operations and its ability to deliver intended capabilities. As requested. I'll briefly 

[3:27:39 PM]

summarize our prior work on the department's ai use and challenges, as well as principles and key practices for federal agencies, including va, that are considering and implementing ai systems. In July 2025, we reported that va's I use cases increased from 40 and 2023 to 229 and 2024. For example, va's developing a generative ai use to automate various medical imaging processes. This use may enhance va's ability to analyze medical images, integrate existing and new data workflows, and create summary diagnostic reports. In the health and medical sector. Agencies have adopted generative ai to advance medical research and improve public health outcomes, including at va. It's also worth noting that of the 229 use cases, 64% were considered to be high impact ai, meaning that their capabilities impact the rights and or safety of individuals or entities. And looking at just vha, that 

[3:28:42 PM]

percentage increases to 72%. The department also reported to us a number of challenges they face in using and managing generative ai. The full list is noted in my written statement, so I'll only highlight a few here. Challenge one complying with existing federal policies and guidance, va officials shared that the existing federal ai policy could present obstacles to the adoption of generative ai, including in the areas of cyber security, data privacy, and it acquisitions. Challenge number two having sufficient technical resources and budget. Gen ai can require infrastructure with significant computational and technical resources, and va noted challenges in obtaining or accessing the needed technical resources, and also in having the funding necessary to establish those resources and support desired ai initiatives. And the last challenge hiring and developing an ai workforce. Among other things. Va reported difficulties in establishing and providing ongoing education 

[3:29:43 PM]

and technical skills development for their current workforce. Va officials told us they are working towards implementing the new ai requirements in omb April 2025 memorandum, and doing so will provide opportunities to develop and publicly release ai strategies for identifying and removing barriers and addressing the challenges I noted. Additionally, GAO has identified a framework of key practices to help ensure accountability and responsible ai use in the design, development, deployment, and continuous monitoring of ai systems. Our framework is organized around four complementary principles that address governance, data performance and monitoring. Consideration of the key practices in this framework can help va as it considers, selects, and implements ai systems. Lastly, I'll mention that we have 26 open recommendations to va concerning the management of its it resources. If the department implements these recommendations effectively, it will be better positioned to 

[3:30:44 PM]

overcome its longstanding challenges in managing its it resources and will improve its ability to address the rapidly changing ai landscape. That concludes my statement. I look forward to addressing your questions. 
>> Thank you, miss Harris, and the written statement of miss Harris will be entered into the hearing record. And again, thank you to all of our witnesses. And we'll now proceed to, um, questioning. Um, I'll recognize myself for five minutes to begin questioning. Um, I'm going to start with Mr. Worthington. Um, the va. I know we've got a lot of concerns, obviously, about data security, data privacy, what can be used, what can be modeled off of veteran information. But the va requires vendors to sign contracts directly, stipulating that it will prevent secondary use of veteran data. And number one, can you kind of walk us through how that works, and how are you making sure that companies actually follow that rule? 
>> Thank you for the question, chairman Barrett. And I think it's extremely important that 

[3:31:45 PM]

everyone understands that there's there's not a second set of rules for ai systems. Uh, in the va, we have a very clear and stringent set of rules around both security and privacy for any technology system. And so before we bring a system into production, we have to review that system for its compliance with those requirements and ensure that the partners that are working with us on those systems, uh, attest to and agree with those requirements. And so ai systems receive an authority to operate just like any other system would before we would put, uh, veteran data into the system. 
>> Okay. So, um, I appreciate that. Um, for example, though I know, um, the large language model, kind of most stereotypical use of ai, we're going to be looking at, you know, the the millions of record that the va has and then modeling patient outcomes from that, and then looking kind of retrospectively to see where people are at on that spectrum today and say, well, if if we 

[3:32:47 PM]

know this condition led to ten years later, a worse condition over here, how can we stem that off? Uh, earlier? Um, if we allow a, a ai vendor to have access to that, to cultivate that knowledge, is that something that could be then used as an outgrowth in another way for like another, um, like as a research tool for other things. For example, if a person has a predisposition to kidney disease or diabetes or something like that, and we can look retrospectively at their health record to show that they had certain indicators ahead of time, wouldn't we want that to be to the benefit of all medicine and not just within the va? 
>> Uh, yes. I think that, as you're mentioning in the training phase of models, which va does occasionally do that, uh, if we work with a vendor, we make sure that the agreements say that any protected health information can only be used for that specific purpose that we have contracted with. And often 

[3:33:47 PM]

that's taking place in environments that va already runs in controls. Now, when we're talking about using a large language model, uh, those are provided typically via one of the big cloud service providers. And those environments are, uh, set aside in a va boundary that, uh, basically, the vendor has to attest that they already meet va security requirements. So when we're sending information to a large language model to get feedback back from that model, we're using a version of that model that has been made secure to meet government standards. 
>> Okay. And, um, I will fully confess that I'm not an expert on this, but I would a large, large language model allow a practitioner to say I have a veteran presenting with these conditions. What are the risk factors that I ought to look for to maybe run tests that wouldn't ordinarily be otherwise? Um, top of mind. 
>> There could be a variety of ai approaches for a use case like that. And, uh, doctor Kerry may just quickly provide a couple of examples of those sorts of decision support type use cases. 

[3:34:50 PM]

>> Absolutely. Thank you. And it's a fantastic question. I think there's two versions of that. As you note, there are tools where a provider can get general advice, and they might specifically articulate the needs of the veteran and sort of the conditions that they're looking for to point out, to make sure they follow the different procedures that are recommended and identify the guidelines. Those tools are available within the va. 
>> Okay. So, um, after the passage of the pact act, you know, we have this burn pit registry and everything, and they're supposed to track veterans and conditions that arose from that. Um, obviously, the specific information about a particular veteran we want to have protected and not revealed. But if there are, um, outcomes of that, that could be useful to, um, to, you know, human medicine in total. Is there a way for that to be, um, revealed? 
>> Yeah. Thank you for the question. And va does have, as you note, a very large amount of health data. And we have a robust. 
>> More than anybody in. 
>> The world. That's right. Um, we have a robust tradition of 

[3:35:51 PM]

research to advance, not just va health care, but health care overall. And we are seeing an increasing interest in using that data for ai driven research papers, like the one that doctor Kerry recently wrote. 
>> Okay. And that's the like the benefit. But also the concern is we obviously have a large repository of medical data, but if that is being used or to the benefit of a a curator of artificial intelligence, should the va be, you know, should that be brought into account for the cost of services and other things like that? What I don't want is a provider to come in and leech that information out solely for their benefit. Um, while not providing a benefit to the va and to the veterans as well. 
>> We agree. 
>> Okay. Thank you. Uh, ranking member Burzynski. 
>> Thank you, Mr. Chairman. Um, doctor Kerry and Mr. Worthington, thank you so much for both being here. Um, I understand that several of va's I use cases like the ambient 

[3:36:52 PM]

dictation pilot intend to use an opt in practice for consent, uh, for systems that are perhaps less directly veteran facing, like the use of ai and benefits determinations or medical assessments. How is the department educating veterans on these use cases to ensure for their awareness. 
>> At a very high level? And thank you for the question. Uh, we are using our ai use case inventory as the way to catalog all of the uses of ai and make sure that that's publicly available. And so when there is not, as you mentioned, a like a 1 to 1 interaction that provides the opportunity to explain directly what's happening as there is in many health care settings, uh, what we're relying on is our publishing of the overall ai strategy and use case to explain how the department is using ai in various, uh, products and services. 
>> Okay, so other than just that, general awareness is there for veterans. Is there any way to kind of draw their attention to this so that they know that, you know, what their situation might be using to 

[3:37:55 PM]

inform an ai model? 
>> We're always listening for veterans feedback through a variety of mechanisms and reacting to that. And that's true of ai situations and non ai situations. But we certainly want to monitor this for ai in particular because I think maintaining veterans trust in the va as we introduce these new technologies is going to be critical. 
>> Okay. Um, and then Mr. Worthington, I'm glad that you and your teams are committed to transparency in ai use cases at the department. Um, that is commendable. However, there have been reports that certain employees had access to certain data sets and systems within va's enclave, um, which may have been used for ai related operations. So I have some specific employees I want to mention by name. And then I have some questions for you. Um, I'm going to ask about these employees, Justin Fulcher. Sahil Levin, Lavinia, um, Christopher Roussos, Peyton Rawlings, Carrie Volpert or John Koval. So I'm just looking for, like, a yes or no to these 

[3:38:56 PM]

questions. Did you ever work with any of those individuals? 
>> Uh, yes, I've come across several of them. 
>> Okay. Are or were these individuals affiliated with the department of government efficiency? 
>> I am not exactly clear on the relationship. I believe they're va employees. And, um, at points, they were introduced as also being part of the the doge movement. 
>> Okay. Um, did any of these employees access data sets that included va patient medical records or other personally identifiable information? 
>> I am not aware. 
>> Okay. Um, were you or anyone you know ever asked to duplicate data sets by these employees? 
>> Uh, no, I was not. 
>> Okay. And can you commit to me that no veterans data was removed from the department of veterans affairs? 
>> As far as I understand, all the va employees follow all the va it security processes and procedures, and that was a key 

[3:39:58 PM]

priority for all of us and always as a key priority. 
>> Okay, okay. Um, Mr. Worthington, um, almost two weeks ago, the acting director of the us digital service noted that the federal government needs more tech employees to and to hire and empower great talent. Do you believe that va shares that sentiment? 
>> Uh, yeah, I do. I think having technologists in government is critically important, as is having great researchers and doctors. 
>> Okay. Uh, secretary Collins has often noted the importance of va employees in direct care roles, disregarding the importance of what he might call support employees in the provision of this work. Do you believe that this type of rhetoric has helped the department to recruit and retain tech talent? 
>> I think the good thing about working at the va is our mission is so clear, and the mission of serving veterans is the most important one that I've worked on in my tech career. And I think there's many technologists across the country that are willing to sign up for that mission. Uh, and I love trying to recruit those people to my team. 
>> Okay, um, miss Harris, real 

[3:40:59 PM]

quick on a follow up, uh, gaze, artificial intelligence accountability framework notes, the workforce is a key component to ensuring effective ai application. How does a highly skilled technical workforce ensure adequate scalability of ai applications and protection of veteran data? 
>> Well, while there is great excitement. Around ai because. 
>> Of the potential to improve va operations, there's also significant concerns. The ones that I articulated earlier about cybersecurity, intellectual property as well, built in bias in the ai system, um, as well as environmental and other concerns. So we want to make sure that we have a workforce that understands both the potential of these systems, but also understands the risks in ai as well. So having those two are vital. 
>> Okay. Thank you. And I yield back. 
>> Thank you. Uh, Mr. Latrelle. 
>> Thank you, Mr. Chairman. 
>> Mr. Kazemi. 
>> You laid out a very well articulated plan of attack on how the va could tackle this healthcare artificial intelligence kind of combining 

[3:42:02 PM]

of forces. Um, the problem is you've. Sounds like you've never worked with the united States government, because that is what kills this effort. Is the United States government. And miss Harris, you your opening statement was very well articulated and you hit every single point precisely. And the problem is, we have such an issue with the va because it's a big machine and we're trying to compound or we're trying to bring in artificial intelligence to streamline the process. And you have 172 different va facilities plus satellite campuses, and that's that's 172 different silos. And they don't work together. They don't communicate very well with each other. We spent almost $16 billion trying to push electronic healthcare records across multiple, uh, facilities. And now we're going to try to tackle artificial intelligence as well. And in 

[3:43:04 PM]

2024, we had 229 ai actions. Correct, Mr. Worthington? 
>> Yes. 
>> Approximately what site if did that come from? Because I would dare say that that didn't come from all or every single va installation. I that sounds like that sounds to me that's collected from like a few. Is that correct? 
>> We did attempt to have a pretty comprehensive review process to gather all of the uses of ai across the country, so we. 
>> Didn't get anything out of that. It was almost a yes or no question. But go ahead again. 
>> Yes, I believe that the ai is being used at facilities across the country, and this inventory covers those uses. 
>> Because the conversations I have with multiple sites is they don't have artificial intelligence capabilities because their sites aren't. Ready, or they don't have the infrastructure in place to do that, because we keep compounding software on top of software, and some sites can't function at all with new software they're trying to 

[3:44:04 PM]

implement. That's a pretty fair statement, correct? 
>> I would agree that having standardized systems is a challenge at the va. And so there is a bit of a difference in different facilities, although I do think many of them are starting to use ai assisted medical devices, for example. And a number of those are covered in this inventory. 
>> So how do we fix the problem? Again, I'm going to ask you, sir, because I usually ask everyone that's sit in front of me from the va is how would we fix this problem? So Mr. And Mr. Ghassemi have probably thought about this quite a bit before they showed up in front of us, but again, they haven't actually, I don't know this for certain. I may be throwing this at you can course correct me if you'd like, but I don't think they've had to deal with the United States government, ai and also the va. Now, how long have you been in this position, sir? Uh, I've. 
>> Been at the va nearly ten years in this position for about two years as chief ai officer. 
>> Okay, so what comes first? The communication between the sites and the ability to ask that information questions, which we don't do that or we don't have the ability to do 

[3:45:05 PM]

that. Do we run the implementation of artificial intelligence in parallel with that, or do we have to do one before the other? 
>> In my personal opinion, we can't wait because ai is here whether we're ready or not. And increasingly, every solution we buy from our partners in the private sector is going to have it embedded inside of it. So I think our challenge is we need to come up with a very good standard templates that every site can use and allow those standard tools to be deployed. Things like the va gpt tool that I mentioned, which is now available to every va employee in a standard way since. 
>> The since the department of veterans affairs houses the most important data set on the planet, arguably. And everyone wants to touch it, including doctor ghassemi at Michigan state. I would have to guess, especially when you were at mit and Cambridge, I'm sure. Pretty impressive resume, sir. Everybody's trying to touch it. Everybody wants to be a part of it, and you have to deal with every single subject matter 

[3:46:06 PM]

expert that walks through your door that says, I'm the best. And I can assure you, every one of those corporations and companies walks into our office as well. So the question is, who is it? Who do you vet and who's going to touch it? Because it can't be everybody. We don't have an in my personal opinion that I don't I'm not aware of. We don't have an enclave that can house all of our information where everybody can get in there and not steal it. So information of implementation of artificial intelligence, which we don't have the ability to regulate. So the question is who will do that? Or do you have the ai system itself regulate itself? 
>> I think it's a great observation and concern. It's one we share. And the reason why we are putting every, every ai use case through that review process is to ensure that if it's being used with real veteran data, that it meets va's stringent security requirements. 
>> Thank you. Thank you, Mr. Chairman. Thank you, sir, I yield back. 
>> All right. Thank you. Um, 

[3:47:06 PM]

Mr. Rich Mccormick. 
>> Thank you so much. Thank you so much. I wanted to kind of piggyback off of some of representative Luttrell's questions. You mentioned standardization, and we know now from doing this for years that standardization in the va has not been our strong suit. Are there any things that you've learned from our lack of standardization for all of our, uh, electronic medical records? We've been consistently having an issue there with standardization. So I have two questions for you. First, are you confident that you can actually have standardization mechanism that will be able to have a smooth transition and implementation? 
>> And thank you for the question. And it is a critical topic for us. And I do think that the investments this committee has helped make over the past years have helped with that. We do have, for example, in the space of decision support, we have an investment that allows ai assisted decision support tools to be, uh, purchased or built, uh, and then deployed to every vista site and also to every Oracle. 
>> I guess my question really 

[3:48:07 PM]

is because, you know, like I said, we've been trying to be successful here and it hasn't been. So how confident are you now and what are the missing links for standardization when it comes to ai? Because ai has some complexities that I think we can all acknowledge, especially when it comes to biases. And if we're going to implement ai into our system, we want to make sure that we have precise implementation. And we're also taking into consideration responsible implementation of ai, which actually addresses the biases immediately that deals with security immediately. So I was going to go into those questions first, but I said I can't even go there if we don't deal with standardization. So what have we learned? How confident are you or should we really be taking some time to step back and look at standardization again, but through a magnifying glass to make sure we get it right? 
>> I do feel confident that we are approaching this in a enterprise approach. And so that's why partnerships with the vha and our colleagues, like doctor Kerry, is so critical. So ai is both a new area. It's one we need to be 

[3:49:07 PM]

able to experiment in before we commit to that enterprise solution. But then once we commit, we don't want to have, uh, you know, every medical center buying its own, its own version of the same product. And so we've got a pretty careful balance of that innovation. But we are doing structured pilots to help us decide what to purchase and what to deploy to the enterprise. 
>> So I wanted to talk more about the implementation and development, because we know that most of the biases will be during the development phase and also the implementation phase. What are you doing specifically to make sure that these biases aren't being inherently put into the system, to make sure that all of our veterans actually have access to equitable care? 
>> Yeah, that is a great question. And it's a concern that is of critical importance for us as we adopt ai, the office of management and budget and their policy has determined or defined high impact use cases. So those would be things involved in health care or benefits. And they provided a set of requirements that any ai needs to meet before they're used. And so some of the highlights of those are pre-deployment testing to make sure that the model performs 

[3:50:07 PM]

well across different different demographic groups, but not just pre-deployment testing, also ongoing monitoring so that we can make sure that the models perform well over time. 
>> Could you tell me how you're doing that? Because we've been reading, I've been loving this ai conversation. I've been looking at it through all spectrums. And one of the articles that I'm going to actually ask to put into the record, it talks about the clinical decision making for in the implementations. And I also want to hear from miss Harris about, um, are we matching the need right now to identify bias? 
>> I do believe that we, through the ai control process and the governments that we put in place with our partners in vha, that we do have commitment from all the use case owners to meet those standards in the omb requirements. 
>> And, miss Harris, what would you like to see when it comes to actually, um, being vigilant on making sure that we're not utilizing a system that is has inherent biases in it? 
>> Yeah, for sure. So one thing to note, um, you know, Mr. Worthington talked about these high impact systems. Vha has 

[3:51:08 PM]

72% of their ai use cases as being high impact. So meaning that they, um, they affect people and entities and their rights. And so that's, that's quite a number, a high number of systems, um, that have that implication. And so, yes, you have to go through additional hoops, as he had mentioned, with pre-deployment and during monitoring to make sure that, you know, rights aren't compromised. Um, but the va has told us that there is a need for more privacy officers to handle increased data security demands. So we would like to see more of those positions being filled to ensure that privacy is really taken care of as it relates to these high impact use cases. 
>> And I only have a few seconds left, but I did want to ask, um, doctor Kissimmee, are there any cases that you've seen in public usage or private usage where they've done an excellent job in actually removing the biases, identifying them? Um, immediately. 
>> There's a really active domain of researchers who are 

[3:52:09 PM]

trying to solve exactly that problem. A lot of the studies are happening with, uh, for example, the mimic database, which is based out of the Boston area, something that I actually contributed to. Um, to summarize, I think the the broader domain of that research activity in a few words is it's possible to do it, but it requires a thoughtful approach and each data set is different. So what you have in the va and de-biasing that will be different than if you're doing it in the context of a data set in Boston and somewhere else. 
>> Thank you, I yield back. Thank you for your time. 
>> Thank you. And I'll recognize myself for five minutes again. And, um, doctor ghassemi, I wanted to come back to you. And, um, you've listened to some of the back and forth testimony and some of the responses, both from the va, from members here. Um, you're outside of the va, so you have the benefit of being removed from some of this internal stuff. And I'm curious, you know, kind of what your thoughts are to me and to Mr. 

[3:53:10 PM]

Luttrell's point is, we're trying to upgrade this legacy health record system on a, I guess, parallel track to to use the term you used. We're trying to modernize some of the easy lift items that can be that can be done through assistive technology or augmented. I think somebody said in their in their testimony as well, um, do you think that's achievable? Number one? And, you know, how do you think that the va can do this responsibly? Um, to make sure that it's done in the appropriate way? 
>> So the short answer is I think it's achievable. Um, how can it be done responsibly? It has to start first and foremost with unification of the data. I heard in earlier conversations that. 
>> In unification of data, are you talking about having a 

[3:54:11 PM]

singular system, or are you talking about the the data itself not being fragmented across all these different va facilities? 
>> What I mean is that you need a singular way to represent the data, so that an ai system that operates in one system can move and operate in another. Now, actually, the good news is that artificial intelligence can be used to help with that unification process itself. So I'll speak about some of my external experiences here and say why I think there's room to be hopeful. Um, it's it's a common problem in industry for corporations to deal with. They have they have a large database of customers or health systems, have a large database of patients, and they want to enrich that with some data from outside of their ecosystem. That's a common problem. And so there's reconciliation of two complex data sets where column names in these data sets don't match representations of values 

[3:55:12 PM]

inside these data sets don't match. There's so many things that are misaligned here. But the same, instead of thinking of ai's role as coming in after you've done a very heavy duty and costly and inglorious task of aligning that data, you can use the ai tools to perform alignment of that data, right? To ask how you do the combination of the information, the debiasing considerations that were brought up earlier, and so on. 
>> Thank you, I appreciate that. And, um, how do you think, um, balancing, you know, the access to this and the benefit that comes from that with keeping the paramount interest of, you know, veterans consent and, you know, privacy and all of those, um, all those things that we can't miss the mark on, uh, as well. Um, yeah. I'd be interested in your thoughts on that. 
>> Yeah. I think I think disclosure is really important. Transparency. So, you know, 

[3:56:13 PM]

when we go to a supermarket and we turn around an item that's on the shelf on the back is disclosed to us through the nutrition label. What are what are the contents inside of the food that we purchase. And in a similar way, if you think of if you think of care that we receive as an item, then we need a similar way to inspect what components, what which parts of the ingredients in that care came from, which sources did they come from? A a model that Oracle trained on their corner ecosystem. Did they come from an academic paper? Did they come from a clinician's judgment? So the traceability of that decision and making it transparent back to the end consumer of the care, which is the veteran, that's really important because they have a right to know how care is being derived prior to consenting to receive it. So I 

[3:57:14 PM]

think that transparency sits at the beating heart of doing this correctly. And the reason there's trepidation, as far as I understand it, behind the use of ai, not just in healthcare, by the way, but in a large number of industries is because the transparency is an issue, right? It could tell you, um, hallucinations. Right. I think maybe some of you have heard of this concept. If you haven't, I'll quickly define it is when a model basically confidently tells you the wrong answer. There are ways to overcome this there. They require some expertise, but it is solvable. 
>> Thank you. Appreciate it. I am out of time. Uh, ranking member Basinski, I recognize you for five minutes. 
>> Thank you very much. Um, so September is suicide. 
>> Prevention month, and, um, our full committee hasn't had, um, a hearing for many years on suicide prevention, which I think is something that is a 

[3:58:16 PM]

very big missed opportunity and something I'm hoping we can be getting to. But I can use this opportunity at this subcommittee hearing to ask the va some questions around suicide prevention, and then the connection with ai and how ai might be a useful tool, um, in suicide prevention, like the reach vet algorithm model in particular. So my question is for actually, doctor Kerry, can you speak to how va is planning to use its ai inventory to build on this success? 
>> Yeah, absolutely. Thank you so much for the question. So as you note, it's incredibly important that we take care of our veterans, especially in this context of mental health needs. So we have been operating the reach vet model for a number of years. As Mr. Worthington noted, since 2017 successfully, we have updated that model recently to ensure it has ongoing high performance of identifying identification of veterans at the highest risk 

[3:59:17 PM]

quartiles. And then we implement that model as part of a multi-pronged strategy to ensure veterans get the care they need. So their receipt of the care they need does not depend only on identification of an ai tool or being flagged as being at high risk. It's just one of many strategies we use to ensure that veterans are regularly screened. And as you noted in the opening statement, if anybody falls through the cracks that they have an opportunity to still receive the care they need. 
>> And one. 
>> Of my concerns is just we don't want to prevent human involvement from being a part of suicide prevention. We can use ai as a tool. But how does the va look at, you know, working to ensure that human involvement isn't, um, eliminated as a part of the critical nature of the of the care that we want to be able to provide to a veteran, uh, with suicide prevention efforts. 
>> Thank you. That's a fantastic question. And we completely agree. I want to make it absolutely clear that va clinicians deliver care to veterans. Uh, va clinicians are 

[4:00:17 PM]

in control of the care that veterans receive. So while we do use ai tools to surface risks and ensure that all veterans are flagged to get the care they need, what happens next is that a human at the va reaches out to that veteran or first reviews the information and decides if outreach is necessary. 
>> Okay. Um, and so can you. Could you commit for me that the va will never use ai, including chat bots, as a substitute for frontline staff responders for mental health crisis intervention? 
>> We do not currently have any plans that I'm aware of to use ai as a treatment device instead of providers, and I've personally been a part of many conversations where we ensure that continues to be the case. 
>> Okay. Thank you. Um, miss Harris, could I ask what risks are posed by utilizing ai tools for use cases other than their intended purpose, like the use of chat bots that were developed for programs like va or home loans and crisis intervention support? 
>> Well, I think that there would be significant risk in a 

[4:01:18 PM]

tool that's not being performed as as intended. So, for example, if you're using an ai chatbot for one program, um, and but, you know, obviously if you use that same bot for another program, it's going to produce poor results. And so that's because the data that was used to teach that tool, um, would not be relevant to the expected role for that other program. So we would certainly think that there's significant risk. In doing what what you've asked. 
>> Okay. 
>> Um. 
>> And then I just va's office of inspector general reported in April that va's automated decision support tool was ineffective in helping claims processes assign the correct effective date for packed act claims. This resulted in at least $7 billion in improper payments. I worry that vha rushed to expand automation will lead to similar errors that could put patients at risk. Um, so shifting gears, Mr. Worthington, how do you plan to measure accuracy of implemented and piloted ai tools? 
>> Well, that's a great question. And I think by having 

[4:02:21 PM]

all of the use cases documented, along with the owner of each, I use case will have the consistency plans available to us so that then our colleagues in va can be regularly following up to see what they've found. Because we agree that continuous monitoring of ai in production is very important. I do think our healthcare system is particularly well designed to monitor for those sorts of things, because that's part of what they do in a non ai context as well. 
>> Okay. Just a quick follow up. Um, at the hearing on this topic, Mr. Worthington, last year, you mentioned that the key to understanding how any particular ai may introduce biases is to understand the data that was trained on and the outputs it provides, considering the efforts of this administration to limit what kind of data may be available in research data sets or in a veterans medical file, do you believe that this will impact the efficacy of va's ai tools? 
>> I would have to get into the specifics of any given case. I think at a high level, it's very important to understand what data went into the training and do the 

[4:03:21 PM]

pre-deployment testing before we use something in production. 
>> Okay. 
>> Okay, I yield back. 
>> Thank you. Um, I will now recognize Mr. Luttrell. 
>> Thank you, Mr. Chairman. Mr. Garcia fascinated, but with your previous statement. So clean data, dirty data, retrospective prospective data. The transfer of information is very challenging. I'm not going to say impossible. I'll never say that. Um, currently, the va doesn't house all of veterans data. It sits in different silos of of the of the different hospitals. I think the death records lives in one spot, but everyone else is disseminated that. Martin. That's correct. Correct. 
>> There's definitely siloed systems. Although our health data is pretty consolidated. 
>> Consolidated? It makes sense to me and I don't know the price tag on this, if this is even possible, that if all the data lived in one enclave, the entire veterans space lived under, say, just the va data center, which I don't even know what that would look like. But then the va can control access to anybody, including all the 

[4:04:23 PM]

sites, plus every single university and research student, whomever that wants to touch it. And they could prevent the ability for data theft. Is that a fair statement? Anybody? 
>> I do think that consolidating data into secure platforms can be a good enabler of this sort of technology. 
>> We even having that discussion inside the va, you can say no. 
>> Yes, we are, we are actively working and in fact have done a number of data consolidations to make that possible. 
>> I've been here for about three years now, and the word actively working, it doesn't really resonate in this place. Are we really wanting to do this, or is this just something that you're that's just something you're throwing at me? 
>> Uh, no, I think like an example, like the reach model that we just described is a model that was created based on that consolidated data set that draws on data from all the different medical centers, as well as other data into one central data warehouse. 
>> Everybody can touch it. So if somebody in Conroe, Texas, the va facility that I have says, hey, look, I have a 

[4:05:24 PM]

veteran here that has this, they can reach out to that data center, populate from tens of trillions of data points and send back, hey, most likely this is what we're looking at. 
>> Well, when you're using it, uh, it gets complicated quickly, as you know. So, uh, different use cases have different degrees of connectedness. But in terms of building places where we can create those models that we just went through, like reach that we do already have investments that help with that. 
>> Okay. So if we do have the willingness to do this, it's in some ways going to have to have the software in place to do it. Mr. Gadek, I'm not going to let you out of here without getting something to saying something. Okay? Who can handle something like this? Company wise, industry whomever. And don't say Michigan state because he's sitting in a room with me. 
>> No, sir. I would say someone from university of Michigan where I went to school, they could probably. 
>> Take pretty good, too. Okay. Yeah. Strike that. 
>> Um, sir, I, I spent four years in the federal government. I worked in the general services administration under rts, and, um, had the 

[4:06:24 PM]

opportunity to work with a lot of different agencies in that capacity. Um, what I saw there was what I had seen throughout my commercial career, which is that as I as I put in my written statement, um, organizations have way more data than they realize, and that data exists in more locations than they're aware of. And that data means different things in different places, that the fundamental root level in terms of where the data exists and the number one reasons that projects fail. If it's an ai project or any other technology project, it's because of the data. If the data isn't there, then the then no matter what position, what solution you have, it'll never really work. It's sort of like what we call putting lipstick on a pig, in other words. So you have to solve that problem. Now who solves that problem? That's an enterprise wide problem. That's an enterprise wide acknowledgment that the problem exists, and an enterprise wide effort to make the investment in solving that problem, um, from a. 
>> Multiple agencies are going to have to come in on top of this. 
>> I would say multiple departments within an agency have to be have would report up through a business leader, a chief data officer reporting up, um, at the highest level to 

[4:07:25 PM]

make that investment and to solve that problem at the fundamental level. Because if it's not solved fundamentally, then the underlying structure of any solution will not work. 
>> I'm going to make the assumption, which I probably should, that this is what's going to have to happen. Yes, I think. 
>> We need to find ways to get the exact right piece of data from everything that va and dod have access to, to the person that needs it at the right time. And I actually think that search and summarization capability is actually one of the things that we are excited about. I maybe being able to help with. 
>> This is what I will do for us. 
>> I think it could help with those sorts of things to sift through all those. 
>> The human brain can process that many data sets. 
>> That's right. So this is one of the areas we're actively investing. 
>> I shouldn't say. 
>> That the human brain can absolutely do anything a human being cannot it? 
>> I think it gives an opportunity to empower people to act on more information than they would be able to do manually. 
>> That's something that kind of downstream. I'd like to to, you know, I'd like to see the how we're laying this out. Um, because at the end of the day, as appropriators in congress, we're going to have to put a 

[4:08:25 PM]

dollar sign on that. And since the Ehr is really giving us a great time, can I see where I'm going with this? Thank you, Mr. Chairman, I yield back. 
>> Yeah. Thank you, Mr. Chairman. I recognize myself for five minutes. Um, Mr. Gadek, um, you, mentioned your testimony. You kind of compared ai to the early days of the railroad, right? And, you know, this was a great advancement, but it was fraught with all these problems and challenges. And, um, uh, you know, over time was perfected and I guess never truly perfected, but certainly perfected to the degree that we can reasonably get to, um, I think we when it comes to artificial intelligence, there's a greater risk than the occupants of a train rolling down a railroad track. This could have catastrophic outcome if left, you know, unguarded or breach of information or, you know, who knows what. It could be truly problematic. What are the guardrails that you think are 

[4:09:27 PM]

appropriate, necessary right now to make sure that that doesn't happen with ai? Like, how are we going to look over the horizon at what could happen and prevent it from happening on the front end? 
>> Thank you. Um, it's a great question. And I think it's a very, uh, it's sort of a fundamental question in terms of, uh, of ai and what it is and what it is not. As I said in my statement, it when you interact with ai tools today, it feels like you're talking to a human being, but it is not a human being. It has no moral conscience. It doesn't really understand the words that's actually being given to it or the words that are it's producing. So there are a number of ways to to really address this issue. One of those, um, is really understanding the difference between correlation and causation. Without getting into great statistical detail. Um, there's nearly a perfect correlation. Um, as I, uh, put in my testimony in terms of the number of Google searches for the word Nintendo and the number of librarians in the state of Michigan, most statistical models will rely on this, this this using correlation to identify patterns and then reproduce 

[4:10:28 PM]

those patterns in its output. What is really needed is an emphasis on causation, understanding the inputs that a model uses, how those inputs relate to each other, and how those relate to the outputs. There is very little effort being placed on that type of technology, that type of investment, because the dollars are already chasing correlation. Correlation is a lot easier to do than causation. Um, so that's where a lot of the investment goes. So I would say one of the fundamental areas is and I don't know if it can be mandated, but I would think, I would hope that the scientific research community would realize that's the power, um, of ai is to, to unlock. The true potential of it is to really mimic how a human mind works, which is it sees something, it reacts to it and then produces something else. So to mimic that with the technology would be great. The other thing that I did want to want to say is that is going back to the data itself. Um, a model is trained. Uh, I think the question was around bias, right? The, the data that the model is given, if it's not inherently biased, if it's not, 

[4:11:28 PM]

if it's if a lot of thought isn't given to the data itself that the model is model receives, then the output will be inherently biased. It could be biased because of the way it's engineered. It could be biased because of the data that it's given. But because these models are so complex and so little work has been done to understand how they work, you'll never know if it's the model that's biased or the data that was biased. So again, a principle, a development principle, a research principle, a standardization that's adopted industry to address all of those would be would be very helpful. 
>> Yeah. Thank you. And that correlation causation thing is really important. I would I would bet or guess that a lot of information at the beginning is correlation information. Then over time maybe it can be perfected or improved into the causative and causative, you know, parts of that. But at the beginning it's if this then that correlation. We may not know why or how. But these things, especially when you're dealing with medical information over a long period 

[4:12:30 PM]

of time and, you know, if if enough people come in with a correlating condition enough times, we begin to believe it's causative for a risk factor for something else. Um, so I guess how do we like, how do we make good decisions based on that? Um, you know, because we may not even understand the causative nature of it, but if it's enough correlation data there, maybe it it does tell us something. 
>> Absolutely. I think correlation as a, as a purpose and in terms of identifying patterns and identifying things that are outside of the norm. Absolutely. It's it's a wonderful tool and it's a critical tool. I my position would be that it just can't be used in a vacuum. That coupled with causing understanding, causation and investing more in those types of tools to help understand the true relationship between two things and why one is causing the other. Um, as I mentioned, there's no obvious relationship between Google searches and the number of librarians, but the problem is correlation models don't know that, right? They just use that number and run 

[4:13:31 PM]

with it. So, um, there are lots of crazy examples that I could give, but that's a that's a good one and relevant. But that emphasis on causation, I think is really one that is not been invested in as much as it should be. Um, and something that we've found is really helpful and powerful, that helps us understand our models and why they behave that way. Also, when they fail, we understand why they fail. Um, it's likely because something broke in that relationship or did not work in that relationship. 
>> Thank you. I'm out of time. I'm going to yield to ranking member Brzezinski for five minutes. 
>> Thank you. Thank you, Mr. Chairman. Um, I wanted to ask miss Harris, um, some follow up questions. Um, just as ranking member, I have spent now a lot of time, um, asking the va how it plans to juggle all of these different, numerous modernization efforts. The department is pursuing, like Ehr, of course, supply chain hr modernization. And now I, um, I was wondering if you could speak to the types of resources that the va will need. Um, considering to consider having at its disposal as it deploys 

[4:14:31 PM]

these systems? 
>> Uh, yes. Thank you for the question. I mean, first and foremost, I think it's hugely problematic that va does not have a permanent Cao in place. I know you mentioned in your opening statement, um, that's because under his or her leadership, that's where these, you know, various it modernizations get prioritized, you know, um, and plus, our work has shown that, you know, when you have that steady leadership over, you know, 3 to 4 year time period, that's essential for any successful major it initiative, including all the ai initiatives, zero trust, Ehr, all those things. But the second point, um, oit is obviously going through a major restructuring right now. You know, they they've requested almost $300 million less, um, in fiscal year 26 than the previous year. They've also reduced staff by 931 staff. Um, now more than ever, va needs to fully understand, um, have a comprehensive grasp on the the skills and inventories that they have in their it workforce. And at this time, 

[4:15:33 PM]

they don't know that. So they're not in a position to effectively assess what they need if they don't know what they have. And that's an open recommendation that we have. So that's first and foremost something that they need to do in order to answer your question. 
>> Okay. Thank you. Um, Mr. Worthington, in GAO's review from July, va noted that it faced challenges with implementing generative ai use cases due to a lack of sufficient technical resources and budget. Your testimony highlights this issue of cost as well. Um, as it is currently funded and staffed, do you believe that va is capable of implementing additional ai use cases on top of these other modernization efforts that I've mentioned? 
>> Thank you for the question, ranking member. And I do think that we have the resources to implement high impact ai, but it is a tough environment. Everything is competing for resources with each other. Um, and so it's a matter of prioritizing those things that are going to have the most amount of impact with the resources that we have. 

[4:16:33 PM]

>> Okay. I guess I'd just go back to what miss Harris has recommendation. Getting a Cao, I think, is really critical to helping to prioritize all of these different, really important initiatives. Um, and, Mr. Worthington, do you believe the va's challenges with retaining challenges with retaining ai experts and other technical employees may impact va's ability to scale ai tools and other modernization efforts? 
>> I definitely think having ai experts on the va side, uh, will help make us a better purchaser of these solutions, and it's it's an important thing for us to do. We've invested a lot in trying to build this team, especially through partnerships with things like the United States digital corps and the presidential innovation fellows program. We want to lean into those sorts of partnerships to help us bring ai experts in, in addition to those that we can recruit ourselves. 
>> Okay, great. Um, Mr. Worthington, we're hearing reports of va's ambient listening pilot will be rolled out across ten facilities by the end of this year. Um, what is the department determining, 

[4:17:34 PM]

um, the success for this pilot? 
>> I thank you for the question. I'll have doctor Carey give you some details on that. Okay. 
>> Thank you for the question. Um, we have established a series of criteria and evaluation as we roll this out that's focused on user acceptance, testing veterans perceptions of the tool as it's used in their ongoing trust in the care they receive. And just overall performance of the tool. We'll continue to monitor that during the pilot. 
>> Okay. And are you measuring clinician burden and and what are your targets? 
>> We are um I can take that for the record to get back to you with the specifics. In general, we are measuring clinician burden and getting clinician feedback both synchronously and through survey mechanisms to understand the impacts. 
>> One thing I would love to add is the users of our generative ai tool that's deployed to the workforce as a whole. In a survey, 73% of the users of that tool reported that they were able to spend more time fully using their professional skills skills, and 68% reported increased job 

[4:18:35 PM]

satisfaction. So I do think that these tools are going to be value adds to our workforce to help them do more to serve veterans. 
>> Okay. Um, well, it seems to me that we are placing a massive burden on providers. That's a concern from being an ambassador to the tool for veterans, ensuring the tool's accuracy, and then reporting and mediating issues as they arise. Um, how is the department working to to be proactive about receiving feedback from providers on issues with this tool? 
>> Thank you. That's a great question. And just briefly want to recognize it's so important to balance that survey response burden and burden on the clinicians that are also providing care. We've been partnered with clinicians on day one designing this as they're the end users. Uh, and so we just have ongoing conversations with them about the best way to balance those competing things. 
>> Okay. Thank you I yield back. 
>> Thank you. Um, I will um, we're going to close here momentarily. I just have one quick question on that. Um, 

[4:19:37 PM]

listening and automation, uh, transcribing is that file of that recording, is that deleted after it is transcribed? Is there some protection there to make sure that it is not archived or, or held someplace? 
>> We do have procedures on that. And be happy to get that back to you. For the record, I don't have the details in front of me, but yes, we've got that accounted for. 
>> Thank you. I will now yield to ranking member Burzynski for closing statement. 
>> Okay. Thank you. I just want to thank the panelists for being here today to have this conversation. I do very much appreciate it. I do want to go back, though, Mr. Worthington, to a conversation we had earlier about, um, the six va employees that had been working with doge and a letter that ranking member Takano had written to the va back in June. We haven't gotten a response. We just want some more transparency around access to the data that those six employees had. Um, that's veterans data. Just want transparency and some additional information on that. So anything you can do to help us get a response back for 

[4:20:38 PM]

ranking member Takano would be very appreciated. Thank you. 
>> Thank you, ranking member Brzezinski. Appreciate it. And I want to thank our panelists and the members today for joining us for this important hearing. Um, this hearing has made clear that va is both made a tremendous, uh, we have both a tremendous opportunity as well as a serious responsibility when it comes to using artificial intelligence within the va. Va has access to some of the best data and research assets in the world. And I know Mr. Luttrell pointed that out in some of his questioning, too. If you use the right way, I could help doctors detect cancer earlier, prevent heart disease, cut down on paperwork, and most importantly, save veterans lives and hopefully prevent veteran suicides in the process. Programs like reach vet show us it's possible when technology is focused on the mission and we can improve outcomes. Let's be clear ai is a tool, not a replacement for doctors, nurses, and care teams. And I appreciate the va stipulating that we're not trying to 

[4:21:40 PM]

replace practitioners with ai tools can help identify risks earlier and provide clinical clinical pathways, but it cannot and must not replace treatment or human judgment. The reason we send doctors to college, right, because we want them to be experts on what they're doing. Veterans deserve both cutting edge technology and a strong medical team working together on their behalf. That means vigilance and self-responsibility are still, in a sense of responsibility are still required if va fails to safeguard veterans data or or to maintain transparency, trust will be lost and progress is going to stall. This subcommittee will continue to hold the va accountable to ensure that ai enhances care, reduces red tape and strengthens, not substitutes the human touch needed in medicine. I ask unanimous consent that all members have five legislative days to revise and extend their remarks to include extraneous material without objection. So ordered, and this hearing is adjourned. 

[4:22:47 PM]

>> Thanks a lot. All right, I gotta run, I think. 