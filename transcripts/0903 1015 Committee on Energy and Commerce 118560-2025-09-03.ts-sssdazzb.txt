Title: 0903 1015 Committee on Energy and Commerce 118560
Description: Examining Opportunities to Advance American Health Care through the Use of Artificial Intelligence Technologies
Channel: 9 - EC 2123
Recorded On: 9/3/2025 10:00:00 AM
Original Air Date: 9/3/2025
Transcript Generated by SnapStream
==================================

Speaker 1 [10:16:24 AM]
All right,

Speaker 3 [10:16:26 AM]
if

Speaker 4 [10:16:26 AM]
everybody will take their

Speaker 2 [10:16:27 AM]
seats.

Speaker 4 [10:16:30 AM]
Subcommittee will come to order. The chair now recognizes himself for 5 minutes for an opening statement. Today's hearing gives us the opportunity to continue the Energy and Commerce Committee's leadership on artificial intelligence or AI by examining current applications of AI across the healthcare sector. Last Congress, the subcommittee held a similar hearing on AI and machine learning. It is critical that we continue these types of educational hearings to understand the evolving health AI landscape and ensure that Congress keeps up with the many advances in this space, applications of AI and machine learning have increased across the healthcare sector in recent years and will only play a more pronounced role in the daily lives of all Americans moving forward. In the healthcare space today, AI is being deployed by innovators to empower patients along their personal healthcare journey. Support healthcare providers and reduce unnecessary administrative burdens. I look forward to learning more about these real world applications from our panel of experts today. I also believe this AI applications advance. It is critical that Congress continues to examine this landscape to ensure proper safety and proper oversight. These AI applications could be hugely beneficial to patients and providers, but they are to

Speaker 2 [10:17:45 AM]
assist

Speaker 4 [10:17:46 AM]
they are to assist and not to replace the clinical workforce today. I want to briefly highlight a few examples of how AI is being used to improve patient experiences and outcomes in the market today. Pharmaceutical companies are using AI to help improve core scientific research functions and develop life saving treatments and cures, as well as using AI to expedite clinical trials to bring safe and effective medicines to market quicker. Insurance companies are using AI to process claims in order to get care to patients quicker. But this is an area where oversight is needed to make sure that the AI is not being used in an inappropriate way. Uh, and we've seen that on occasion. So we've got to be careful. Physicians in hospitals who've been dealing with documentation burdens or using AI to assist in writing up and consolidating post visits records, which has helped reduce documentation time by roughly 1/3 in some cases and allowed for doctors to spend more time. That's right, you get to spend more time with their patients. What a novel idea. Companies who develop medical devices are using machine learning to better understand certain diseases and help advance innovations to deliver more clinically appropriate and effective care interventions. The Trump administration has also been forward leaning on advancing AI in the health space and streamlining a regulations to increase its application. I applaud the work of the current administration to incorporate AI in a responsible manner that can help improve care. To date, the CMS Innovation Center is working to utilize AI and machine learning to identify waste, fraud, and abuse in federal healthcare systems and to root out improper taxpayer spending. The FDA has incorporated the use of AI to drastically shorten the time needed to complete some tasks in their review process. Researchers at NIH have developed an AI algorithm that modernizes the process of matching potential clinical trial volunteers to suitable trials, cutting down administrative time by 40% while maintaining the same level of placement accuracy, and one would hope that would even get to be a better placement accuracy. These are only a few examples of the many ways the administration is integrating AI and streamlining the way our American healthcare system operates with all these innovative advancements being leveraged across the American healthcare ecosystem, it is paramount that we ensure proper oversight is being applied. because the application of AI and machine learning is only going to increase. We must ensure that these tools continue to empower and not replace the providers that serve our communities across the

Speaker 2 [10:20:23 AM]
nation.

Speaker 4 [10:20:24 AM]
These tools should help improve the patient experience and ultimately access to care, particularly in rural areas like the one that I represent in Virginia's 9th congressional district. I hope we have a constructive conversation today about the opportunities and the risks that come with AI and how our committee should be thinking about the role we can play in helping shape the future of AI and healthcare. I'm looking forward to hearing more from our witnesses and the members on this subcommittee on the application of AI in healthcare. With that, I yield back and I now recognize the subcommittee's ranking member, my friend Diana DeGette for her 5 minutes for an opening statement.

Speaker 5 [10:21:03 AM]
Thank you so much, Mr. Chairman, and welcome back. If you judge from this subcommittee schedule, um, you'd think that nothing pressing has happened in the healthcare arena in the last 5 weeks and certainly I think it's important and all of us think it's important that we look at the role of AI in healthcare, and I hope at some point when we're not in a crisis mode, we can do a thorough investigation cause it's certainly a concern of mine. But my friends right now, Rome is burning Rome is burning. More important than this is the peril that the Trump administration's policies have put my constituents and the constituents of every single person on this panel and uh into all of our constituents are at risk because of the risky and dangerous and unscientifically based principles of RFK Junior and, and, and his and his advisors. Last week Mr. Chairman, President Trump and Secretary Kennedy fired Susan Moorez, the new CDC director who had taken her post just a month before

Speaker 2 [10:22:15 AM]
Her

Speaker 5 [10:22:15 AM]
offense was refusing to rubber stamp Secretary Kennedy's evidence-free vaccine policies and fire seasoned, respected, senior CDC

Speaker 2 [10:22:25 AM]
staff,

Speaker 5 [10:22:26 AM]
as CDC doctors and scientists are removed for following science and telling the truth. The rank and file people who defend America against disease are no longer going to trust the CDC and in addition, ever since Donald Trump became president, an estimated 20,000 people have been fired from HHS, Critical research into cancer into pediatric, um, uh, uh, diseases and many other diseases have been put on hold or shelved. My constituents, your constituents, and everyday Americans across the country are going to suffer. Secretary Kennedy's dereliction of duty and incompetence are underscored by over 1000 and growing HHS employees who signed a letter demanding his resignation today, Mr. Chairman, I'd ask unanimous consent to put that letter into the record.

Speaker 4 [10:23:21 AM]
Without objection, so ordered.

Speaker 5 [10:23:22 AM]
I agree with those 1000 professional researchers. Secretary Kennedy must resign immediately. and if he does not, President Trump should fire him for doing such damage to the institutions that have up until now been the paragons of research in the world and have kept Americans healthy and safe, and Mister Chairman, we need to do our jobs. This subcommittee must bring RFK Junior, Dr. Monterres, and others in to shed light on this administration's unprecedented interference in public health and science. Mr. Chairman, I looked at the cal end ar I think we have time in this subcommittee next week, and I would urge that we bring this up. Let's use it to get the answers that our constituents deserve. The Democrats on this panel and I have been asking for months for this committee to do its job and provide rigorous oversight of HHS under this administration. We've been asking to move critical legislation that we all agreed on at the end of the last year, a number of extensions of critical programs that are bipartisan. Elon Musk killed those pro programs with a tweet when we were doing the continuing resolution and those bills still have not come up to this day. and we've been asking for this committee to rediscover its sense of duty and initiative. Congress, us, we are not a cold bra equal branch of government. We're the first branch of government. Article One. The American people's most direct expression of their will and where the Constitution that vast by far the most power up until now, and we're languishing between asking the president for permission to take the smallest action and refusing to ensure that the executive is faithfully executing the laws passed by this Congress. Everybody in this room, on both sides of the aisle should be embarrassed about Congress's work. I know I am and we've only had just one hearing, a budget hearing with a presidential appointee of this administration during this entire Congress. Inaction in the face of incompetence and malice, that is complicit complicity, and we've got to stop

Speaker 2 [10:25:44 AM]
that.

Speaker 5 [10:25:45 AM]
We've got to investigate the misdeeds of this administration. We've got to follow the investigations where they lead. We have to insulate scientific judgment from politics and ideology. And as the health subcommittee of Energy and Commerce, we must base our decisions on science. Mr. Chairman, I hope we can start doing that as of today, as you can tell, this issue is important to the American people and our constituents. We're not going to stop talking about it until we restore these important protections for our constituents' health. I yield back.

Speaker 2 [10:26:24 AM]
Heck,

Speaker 4 [10:26:24 AM]
I got it, gently yields back and now recognize the chairman of the full committee, Mr. Guthrie for his 5 minutes. Thank

Speaker 2 [10:26:32 AM]
you. Thank you, Chairman Griffith, and thanks all of our witnesses for being here today. We're here today to

Speaker 6 [10:26:37 AM]
continue the discussion surrounding artificial intelligence and specifically the meaningful impacts this innovative technology has had on American healthcare, uh, the American healthcare system as well as AI as a whole. This committee has been a leading voice in the discussion on how to leverage AI across all of our subcommittees focused on unleashing innovation innovation while safeguarding consumers to improve health of all Americans while ensuring it's used safely and responsibly. I would also like to commend the administration for their leadership on these issues. We support the administration's national AI action plan that will accelerate AI innovation, build American AI infrastructure in both and bolster US leadership in AI development and deployment. I've also been encouraged by progress across HH S and maximize these new technologies, and I look forward to continuing to work with CMS, FDA, and everyone else, uh, as that work continues to evolve. Today we're here just a few examples of uh AI technologies are being applied across the healthcare system. I want to emphasize that AI in no way is intended to overtake the jobs of hardworking Americans. It is instead an opportunity to enhance the work conducted by humans across our healthcare system, improving the quality and efficiency of care, reducing time consuming and calls the administrative task in birds enhancing the provider-patient relationship and expediting the discovery of new treatments and cures. Recent news stories have also highlighted potential safety concerns with improper personal use of AI. And the committee is working towards stronger guardrails to prevent tragic events from occurring in the future, especially in healthcare. It is important to understand where AI technologies are creating significant positive impacts on efficiency and research and development of health products along with the overall delivery of care, but not to forget the importance of appropriate safety precautions. The committee remains steadfast in its efforts to improve the use of AI technologies while ensuring AI is used in a human-centric responsible and safe manner. I think all of our witnesses for being here today, and your participation in today's hearing, and I look forward to how we can all work together to have the most optimal use of AI in the healthcare field. Thank you, uh, Mr. Chair, and I yield back.

Speaker 4 [10:28:57 AM]
Gentleman yields back now recognize the ranking member of the full committee, Mr. Pallone, for his five-minute opening

Speaker 2 [10:29:02 AM]
statement.

Speaker 7 [10:29:03 AM]
Thank you so much. Today, the Committee Republicans are holding this hearing on AI technologies and healthcare. But unfortunately, this is happening at the same time that the Trump administration and Health and Human Services Secretary Robert Kennedy Junior. are dismantling the Department of Health and Human Services and waging a war on public health. For 9 months now, the Trump administration and Secretary Kennedy have created chaos in our nation's healthcare system. Last week, it had a breaking point when the administration fired the director of the Centers for Disease Control and Prevention, and 3 key scientific leaders resigned after refusing to sign off on watered down and misleading and unscientific recommendations on vaccines. The Trump administration's reckless actions lead the CDC with a critical leadership vacuum as we head into the fall and the flu season, coupled with the mass layoffs of over 25% of the CDC's workforce, this administration's path of destruction threatens America's health. The CDC must be guided by leaders who govern above politics and remain focused on the agency's core purpose, which is safeguarding and improving the health of our communities, preventing infectious and chronic diseases and protecting all Americans. I'd like to submit for the record, the powerful resignation letter of Doctor Descolaki, the former director of the CDC's National Center for Immunization and Respiratory Diseases, which details the widespread deception at HHS over changes to the vaccination schedule. Last week's actions follow the Trump administration's decision to restrict access to COVID-19 vaccines for millions of Americans. This unprecedented action by the FDA means that healthy adults under 64 will no longer be able to receive the COVID vaccine. Americans will die as a result of Secretary Kennedy's actions. And that's why it's well past time for this committee to finally begin demanding answers. In April, we called on Chairman Guthrie to schedule a hearing with Secretary Kennedy, specifically on his illegal layoffs and reorganization. Then in June, I called for Chair Guthrie to join me in conducting a bipartisan investigation of Secretary Kennedy's actions to restrict access to vaccines. I've also called for this committee to examine the administration's devastating cuts to the NIH and the administration's dangerously inadequate response to the growing measles epidemic. These requests have been met with silence. Republicans would rather sit on the sidelines as Kennedy moves ahead with advancing his dangerous pseudoscience agenda. Secretary Kennedy must testify before this committee. To answer questions and be held accountable for threatening public health by abusing his authority, propagating disinformation and politicizing science. It's time that Republicans take these threats seriously and join us in holding Secretary Kennedy accountable. Turning to today's hearing, AI has the potential, if used appropriately to provide innovative approaches and efficiencies in healthcare. The goal in using this technologies should be to provide better direct patient care and health outcomes. But I'm concerned that the expanded use of AI and healthcare has generated significant risks that we simply cannot ignore. Congress must recognize and address the complex ethical, legal, economic, and social concerns raised by using AI in our healthcare system. Without adequate oversight, these new technologies can lead to devastating consequences for patients. Medical care could be delayed and insurance coverage denied, preventing Americans from getting the care they need to live. There's also the threat of personal health information and data privacy breaches. While AI tools can support healthcare providers, their advice and recommendations should not serve as a substitute for the nuanced judgment of healthcare professionals and should not come at the expense of patient's safety. And I'm very concerned about the impact of AI on mental health. The tragic stories of teens interacting with AI chatbots that encourage them to take their own lives is devastating. The speed at which AI technologies have been incorporated into healthcare has so far outpaced the regulation and oversight. That's why it's concerning the Trump administration rescinded a 2023 executive order aiming to strengthen AI governance and high risk domains and issued a separate executive order to remove barriers and revoke policies that they view as hindering AI innovation. I'm also extremely concerned by the administration's announcement to implement a pilot program in New Jersey and 5 other states that will allow for nonprofit companies to utilize AI to review prior authorization requests for seniors in Medicare. I also believe it's critical that safeguards are in place to protect the privacy and security of patient data. AA cannot, AI cannot function without large quantities of data, and we must ensure that the increased data which AI relies on does not come at the expense of consumers' right to privacy. Again, this is a very important hearing, but we have to think about the consequences of what's going on with AI, uh, which can be positive, but often can be negative without proper regulation. Thank you Mr. Chara Yar.

Speaker 4 [10:34:04 AM]
Chairman Yields back, that concludes member opening statements. The chair would like to remind members that pursuant to the committee rules, all members' opening statements will be made a part of the

Speaker 2 [10:34:12 AM]
record.

Speaker 4 [10:34:12 AM]
We want to thank our witnesses for taking their time to testify before the subcommittee today, although it is not the practice of this subcommittee to swear and witnesses, I would remind our witnesses that knowingly and willfully making materially false statements to the legislative branches against the law under Title 18 Section 1001 of the United States Code, you will have the opportunity to give an opening statement, followed by questions from members, our witnesses for today are uh, Mr. TJ Parker, lead investor in general medicine. Andrew Toy, Chief Executive Officer, Clover Health, Doctor Ibraham, uh, chief clinical Officer, uh, at, at this AI if I said viz.AI, I guess I'm, I'm getting that

Speaker 2 [10:34:56 AM]
right.

Speaker 4 [10:34:57 AM]
Doctor Michelle Mello,

Speaker 2 [10:34:58 AM]
um,

Speaker 4 [10:35:00 AM]
uh, professor of law at Stanford Law School and professor of health policy at Stanford University School of Medicine. And Doctor C. Vaile Wright, a senior director of Healthcare innovation, American Psychological Association. Per committee custom, each witness will have the opportunity for a five-minute opening statement followed by a round of questions from members. The light on the timer in front of you will turn from green to yellow when you have one minute left, and I will now recognize Mr. TJ Parker for 5 minutes to give his opening statement.

Speaker 7 [10:35:30 AM]
Thank you, Chairman Guthrie, ranking member Palone Chairman Griffiths, ranking member to get,

Speaker 8 [10:35:35 AM]
and distinguished members of the subcommittee. I'm TJ Parker, a 2nd generation pharmacist and the founder of general medicine. which is a brand new healthcare store and a partner in Matrix, a 50 year old venture capital firm. It's an honor to be here today to discuss the important role AI is playing in general medicine's ability to offer price transparency and a better customer experience. Previously I was the founder of PillPack, a pharmacy that made it easy for customers to get and take medications as prescribed. I sold that company to Amazon in 2018 and spent four years building Amazon pharmacy,

Speaker 2 [10:36:08 AM]
and

Speaker 8 [10:36:08 AM]
Amazon clinic and putting Amazon on a path to expand broadly into healthcare. As an investor, I see Myriad new healthcare AI startups. Most, including some I'm involved in, are building administrative tools, AI scribes, prior authorization, automation, AI phone calls, and other administrative tasks

Speaker 2 [10:36:28 AM]
It's

Speaker 8 [10:36:28 AM]
important work that it will have a downstream impact on customers. However, today, I want to talk about improving the customer experience in healthcare. Americans are frustrated. They want healthcare to be easier. At general medicine, we're using AI to directly improve the customer experience across all care. From basic needs to complex cases. General medicine is a healthcare store, a one-stop shop for telemedicine, prescriptions, imaging, labs, specialists, or anything you need. We've made it as easy to shop for healthcare as it is to shop for anything else. This means a clear choice of providers, upfront price, with or without insurance, and a simple way to actually book the care they need right on our platform. We take insurance or customers can pay with cash. This approach eliminates the opacity and quagmire of complexity customers experience while trying and often failing to access healthcare today. Our mission is to get every customer the best care for their needs. So far, customers love it and it wouldn't have been possible without AI. Let me give you two examples of how we've used AI to reinvent the experience. The first is pricing In healthcare, people rarely know what care will cost in the end. They can't possibly shop without a clear

Speaker 2 [10:37:36 AM]
price.

Speaker 8 [10:37:37 AM]
We set out to change

Speaker 2 [10:37:38 AM]
that

Speaker 8 [10:37:39 AM]
Behind the scenes of General Medicine, we analyzed the customer's insurance information, including the 80 to 100 page coverage of benefits. We use large language models to turn these PDFs into structured data, then combine that with the open pricing files and other sources to give customers a clear, upfront price for any service, including procedures, labs, imaging referrals, and pharmacy at any location. This is the first time comprehensive pricing has actually been available in US healthcare. Another example, proactive care plans. When you go to a doctor today, it's almost always for an isolated reason. You leave with a prescription or one follow-up

Speaker 2 [10:38:13 AM]
task.

Speaker 8 [10:38:14 AM]
It's all our current system is current is set up to handle. Today, General Medicine is using AI so that patients after their visit have a comprehensive, personalized, actionable plan cover, and not just what brought them in, but all their conditions and any overdue preventative care. With patient permission, we use AI to pull together their medical history, labs, and prescriptions, then flag what's missing. Maybe a colonoscopy, a cholesterol check, or a follow-up lab for blood sugar. The doctor reviews it and the customer sees it all in one place so they can easily take action on each step via general medicine. It's the equivalent of adding to cart and checking out, truly making healthcare as intelligent and easy to shop as everything

Speaker 2 [10:38:49 AM]
else.

Speaker 8 [10:38:50 AM]
Looking ahead, we're building the ability for patients to directly request these insights themselves. People can ask questions back and forth with the AI to clarify the recommendations based on their needs and preferences, then seamlessly book with a provider to discuss and take action. This innovation allows patients in collaboration with providers to take informed control of their health. At Pilpeck and Amazon, we learned that when customers feel in control and actually enjoy using a service, they are more likely to take the right steps for their health. The same pattern is proving true at general medicine. In closing, I also want to sincerely thank the members and staffers who have worked diligently over the past decade plus to enable broadly available price transparency files, improved provider directories and enable data interoperability between providers. Without these efforts, very little of what we do today will be possible. By combining this infrastructure with AI, we can offer a vastly better healthcare experience for every American regardless of location, insurance, or background. Thank you all for the opportunity to share the story of general medicine, and I welcome any questions you may have.

Speaker 2 [10:39:54 AM]
I

Speaker 4 [10:39:54 AM]
appreciate your testimony. Thank you so much and we'll now, uh, go to Mr. Toyi for his 5 minutes.

Speaker 2 [10:40:00 AM]
Thank you.

Speaker 3 [10:40:01 AM]
Sherman Griffith, ranking member of the get, and members of the subcommittee. Thank you for the opportunity to testify today. My name is Andrew Toi, and I'm the CEO of Clover Health. We're an AI technology company, offering Medicare Advantage plans and helping doctors take better care of seniors. We serve over 100,000 seniors, many of whom live on fixed incomes or in underserved communities. I'm not your typical health plan CEO. I have both a bachelor's and master's degree in computer science from Stanford University. I built a startup that was acquired by Google and later worked on Android and Google Cloud. I'm also a patient with Marfan syndrome, a rare genetic condition that took my father's life. As he was diagnosed too late for his condition to be managed. His death may have been prevented if his doctors had the right data and coordinated care. That drives my mission, using technology so no patient slips through the cracks the way he did. So how can AI

Speaker 2 [10:41:03 AM]
help? Doctors

Speaker 3 [10:41:04 AM]
today are asked to do the impossible. Care for patients while juggling mountains of data across disconnected systems. This is where AI can make a difference. It can pull together information from labs, pharmacies, hospitals, and electronic records then highlight what matters most, right at the point of care and in the doctor's existing workflow. Our tool, Clover Assistant, does exactly that. Now, let me be clear, AI should never be used to deny care or replace physicians. It should be used to empower physicians, helping doctors identify diseases earlier, personalized treatments, and spend more time with their patients. I see 3 big healthcare AI opportunities. Number one, bringing sophisticated care to every community. Number 2, making care truly personal. And number 3, reducing inefficiencies and

Speaker 2 [10:42:01 AM]
costs.

Speaker 3 [10:42:02 AM]
So starting with bringing care everywhere, for too long, advanced data systems have only been available inside large hospital networks, independent doctors, especially in rural and underserved areas haven't had

Speaker 2 [10:42:15 AM]
access.

Speaker 3 [10:42:16 AM]
That has a real consequences. Misdiagnoses and opportunities for care, duplicate or incorrect tests, and dangerous delays. It's what happened with my father.

Speaker 2 [10:42:27 AM]
With

Speaker 3 [10:42:27 AM]
the AI powered capabilities in Clover Assistant, a solo physician in Iowa or a small clinic in urban New Jersey has the same data-driven insights as a major academic center. By integrating records from national networks, geography and practice size no longer determine care quality. Turning to personalizing care, every patient is unique.

Speaker 2 [10:42:51 AM]
As

Speaker 3 [10:42:51 AM]
someone with a rare condition, I know I'm not a statistic. I'm an end of one. AI helps doctors move beyond generic population management to truly personalizing care. And the results are real. For example, doctors using Clover Assistant start diabetes patients on treatment 3 years earlier on average. The identified kidney disease 1.5 years earlier. Preventive screenings also go up. 11% more colorectal cancer screenings and nearly 5% more breast cancer screenings. Among heart failure patients, Kluver's AI-enabled care has been tied to 18% fewer hospital stays and 25% fewer readmissions. And because of this, doctors using Clover Assistant have significantly lower cost ratios. Over 10% better. We use those superior economics to help patients afford care and lower out of pocket costs, with $0 premiums, the lowest copays for specialist visits, and $0 copay access to both in-network and out of network primary care. AI is powerful, but must be used responsibly. Three things matter most, I think. Number one, empowering providers. AI should empower, not replace clinicians. It should make their jobs easier and their time with patients more meaningful. Number 2, ensuring interoperability. AI is most effective when patient data is accessible and secure. We must protect patient privacy without creating burdensome mandates. And number 3, accelerating care.

Speaker 2 [10:44:30 AM]
AI

Speaker 3 [10:44:30 AM]
should make it easier and faster for patients to be diagnosed, receive personalized treatment and get that care paid for. AI is here, it's helping doctors identify diseases earlier, deliver more personalized care and lower costs. Used responsibly, AI can give every senior in America, the personalized and effective healthcare they deserve. Thank you, and I look forward to your

Speaker 2 [10:44:58 AM]
questions.

Speaker 4 [10:44:59 AM]
Appreciate the gentlemen yielding back and now recognize Doctor Ibraham for his 5

Speaker 2 [10:45:03 AM]
minutes. Cameron Griffith, ranking member to get, and members of the committee, thank you for the opportunity to testify. My name is Andrew Brahem. I'm the chief clinical officer at VisAI, a practicing general surgeon

Speaker 7 [10:45:13 AM]
at the University of Michigan and a research scientist with over 200 publications focus on how we improve the delivery

Speaker 2 [10:45:19 AM]
of care. Over nearly

Speaker 7 [10:45:21 AM]
two decades, I've seen firsthand how workforce shortages, rising costs, and mounting complexity are pushing our healthcare system to the breaking point. Doctors are asked to see more patients in less time with information scattered across multiple systems and logins. Patients may need to make 3 or 4

Speaker 9 [10:45:36 AM]
calls just to schedule a single appointment, only to sometimes be sent to the wrong clinic or lost to follow up altogether. And the heavy documentation burden takes away from doctors what matters most, caring for their patients Artificial intelligence offers one of the most viable paths forward to save US healthcare and reverse these trends. There are many types of artificial intelligence, including machine learning, deep learning, and large language models. But the technical distinctions are not what matter most. In healthcare, what matters most is not the algorithm in isolation, but how these tools are integrated into real clinical workflows to solve real high stakes problems. At VisAI, that has been our approach. BAI is a healthcare technology company that uses artificial intelligence to empower clinicians with actionable information within seconds so they can make

Speaker 2 [10:46:21 AM]
timely.

Speaker 9 [10:46:22 AM]
decisions to provide high-quality care. By getting the right information to the right doctor at the right time. PhysAI helps hospitals treat patients faster, save lives, and reduce costs. Importantly, it offloads burdens from busy clinicians and improves diagnostic accuracy. We began tackling one of the most devastating conditions in medicine, stroke. These events are often caused by a blood clot to the brain. Every minute untreated, constipation, nearly 2 million neurons. Without immediate action, a stroke can leave patients permanently disabled or even lead to death. Approximately 800,000 Americans from all walks of life, urban and rural, suffer a stroke each

Speaker 2 [10:46:59 AM]
year.

Speaker 9 [10:47:00 AM]
This reality is personal to me. When I was in medical training, my father, a university professor, called me from his office and he was experiencing vision changes and trouble finding words. I immediately recognized it may be a stroke, and I called campus security on him. They went to his office and facilitated getting him to the hospital, and while he was en route, I called ahead to the emergency room. I also called in personal favors to make sure that the neurologist and interventionists were available. Because of these extraordinary steps, he got timely treatment, and days later walked out on his own feet, able to speak and see clearly. But not everybody has a medically trained son ready to coordinate their emergency care. We need systems that ensure patients get the right treatment without relying on luck or personal connections. That is why I joined VisAI, our AI platform helps coordinate timely care for patients, just like my dad. It automatically analyzes CTs to identify those with life-threatening conditions, a lurks a stroke team in real time and assembles a relevant clinical information to support urgent decisions. Independent studies show that this reduces treatment time by more than 30 minutes. Insurance hospital stays by as much as 3

Speaker 2 [10:48:06 AM]
days.

Speaker 9 [10:48:07 AM]
The result is simple but profound. Patients walk out of the hospital who otherwise may never return

Speaker 2 [10:48:12 AM]
home.

Speaker 9 [10:48:13 AM]
Our platform is scaled to more than 1800 hospitals nationwide, every 5 seconds, a patient's care in this country is supported by our platform. From leading academic centers like the Cleveland Clinic to Critical Access hospitals in rural America, where AI helps identify who needs to be transferred quickly for emergency care, and stroke is just one example. We've applied the same model to other serious conditions, such as hypertrophic cardiomyopathy, a disease where the heart muscle becomes abnormally thick and makes it harder to pump blood. Left undiag no s ed it can lead to sudden cardiac death, particularly in younger adults. It affects 1 in 500 Americans, yet most don't know they have it. A Cleveland Clinic studies showed that our AI tool cut time the diagnosis from years to just 3

Speaker 2 [10:48:56 AM]
months.

Speaker 9 [10:48:57 AM]
Pulmonary embolism is another time-sensitive condition where a blood clot can go to the lung, resulting in straining to the heart. It affects 900,000 Americans each year and is responsible for over 100,000 deaths annually. A TriHealth study used our platform reduce time to treatment. from hours to just 6 minutes with a measurable reduction in in hospital deaths. Finally, brain aneurysms affect nearly 1 in 50 Americans, which would be at least 1 or 2 people in this room, um, but most don't know they have it, left untreated, it also can lead to life-threatening consequences. We've expanded these approaches to other areas, including oncology, cardiology, vascular medicine, and trauma. I mention all these to underscore that the real world potential of AI and healthcare is not hyper theoretical For us, it's been a decade of hard work that's translated into FDA cleared, CMS reimbursed tools embedded in frontline care today. But the road has not been easy and we face barriers common to many innovators, including regulatory challenges, reimbursement, and data accessibility. I'm deeply optimistic about what AI can do for American patients and clinicians, and I believe the United States can lead the world in this space with the right policies, incentives, and commitment. We can ensure that every patient, whether in San Francisco or rural Mont ana receives timely life saving care, and we can restore doctors to what they entered medicine to do, care for patients. Thank you.

Speaker 4 [10:50:22 AM]
Jama yields back now recognized Doctor Mello for her 5 minutes of questions, or excuse me, a statement. Thank you, Mr.

Speaker 10 [10:50:29 AM]
Chairman. I appreciate the opportunity, Chairman Griffith, ranking member togue, and others in the subcommittee to speak with you today. I'm part of a group of data scientists, physicians, and ethicists at Stanford University that helps govern how AI tools are used in healthcare at our Stanford facilities. And I would like to share some of the learnings that we've had at Stanford and my own professional experiences over two decades studying patient safety and health policy. I'm enthusiastic about Healthcare AI. There are so many intractable problems that it will help solve. But AI presents both a historic opportunity and a serious risk. And although properly, uh, improperly designed regulation may hinder innovation. There is a critical role for the government in ensuring the conditions for innovation to translate into AI adoption. The key problem isn't that there is a lack of innovation in the AI space as you've heard today, there is much to be proud

Speaker 2 [10:51:31 AM]
of,

Speaker 5 [10:51:32 AM]
but

Speaker 10 [10:51:33 AM]
the uptake of these innovations is relatively low, and the major reason for that is what experts call a foundational trust deficit. There are 4 areas where I think experts agree that policy interventions could help build trust in healthcare AI and spread innovation and adoption system-wide. First, policymakers can help ensure that the entities that develop and use AI adequately assess, disclose, and mitigate the risks of these tools. Surprisingly, most healthcare organizations and insurers really don't do that much vetting of AI tools before they use them or monitor them after they deploy them. Nothing requires them to do more. AI developers aren't required to make any particular disclosures to customers when they pitch their products. And the law also permits them to disclaim liabilities and warranties. As a result, developers have little incentive to reveal weaknesses of their AI tools and little consequence when things go wrong. This rule-free space has left hospitals, clinicians, and patients. Apprehensive about the risks of AI. And that fear is chilling adoption. It's no coincidence that the largest area of AI implementation today isn't the amazing, exciting life saving tools that are being developed. It's tools that perform simple administrative tasks like taking notes during clinic

Speaker 2 [10:53:05 AM]
visits.

Speaker 10 [10:53:06 AM]
We need a supportive infrastructure to build trust in AI tools. For starters, healthcare organizations and insurers should be required to show they have a governance process in place that meets certain standards. Fortunately, there are many good models for institutional governance to draw on at Stanford, for instance, a C-suite level committee decides which tools will be deployed in the hospitals, drawing on an evaluation of the tool's clinical utility, its financial sustainability, its fairness and ethical considerations that's done by an interdisciplinary team. And we have found that with just a modest of investment of effort, we can spot and address risks, mismatched assumptions and unfounded expectations. The federal government already requires research organizations to prove that they monitor human subjects research and protect participants using institutional review boards. Such a concept could be exported to the AI realm. requiring that participants in federal health programs have a process for vetting any AI tool that affects patient care and a plan for deploying and monitoring it. The Joint commission, which accredits hospitals for Medicare, is already developing voluntary certification standards for facilities use of AI. But institutional governance is only effective if developers feed information into it. And that's why developers should be required to disclose information about AI design and performance. Work on model cards is a great place to draw from

Speaker 2 [10:54:38 AM]
here.

Speaker 10 [10:54:39 AM]
A second step the government can take is to support independent research on how AI tools perform in practice. That can provide critical information about benefits and risks of the tools once they're in the hands of clinicians and insurance companies, and it can ensure that that information disseminates out to the public. Third, healthcare reimbursement policies should support adoption and monitoring of effective AI solution. Many AI tools don't enhance revenue for healthcare organizations and won't generate significant cost savings, and they're costly to monitor. Adapting Medicare and Medicaid reimbursement to help cover costs would bring the benefits of these tools to a wider spectrum of hospitals, including those in underserved communities. Finally, the FDA should be empowered to be a more constructive partner in AI development and deployment. There's only so much the agency can do with a substructure that dates to the Ford administration. Many tools aren't subject to FDA jurisdiction at

Speaker 2 [10:55:35 AM]
all,

Speaker 10 [10:55:36 AM]
and many of those that are are faced with cumbersome processes that weren't designed for software evaluations. Modernizing the FDA authority could help build confidence in AI. while fixing areas where current regulation makes it hard to bring products to

Speaker 2 [10:55:51 AM]
market.

Speaker 10 [10:55:52 AM]
With these steps, Congress can help close the trust deficit that hinders innovation from reaching the bedside. Thank you.

Speaker 4 [10:55:59 AM]
Thank you very much. And now recognize Dr. Wright for her 5

Speaker 2 [10:56:02 AM]
minutes.

Speaker 5 [10:56:04 AM]
Good morning, Chairman Griffiths, Ranking member to get and distinguished members of the subcommittee. My name is Doctor Val Wright. I'm a licensed psychologist and I serve as the senior director for healthcare innovation at the American Psychological

Speaker 2 [10:56:16 AM]
Association.

Speaker 5 [10:56:18 AM]
On behalf of the APA and our 173,000 members. Thank you for the opportunity to testify

Speaker 2 [10:56:23 AM]
today.

Speaker 5 [10:56:25 AM]
I'm here to discuss the critical role of psychological science and researchers in shaping the oversight of artificial intelligence and

Speaker 1 [10:56:32 AM]
healthcare, and the role psychology can play in the ethical and safe development and deployment of AI technologies. AI is not just a technology. It's a tool built by humans to be used in human systems. Therefore, a deep understanding of human cognition, behavior, and emotion. must be central to its employment, to ensure it serves people effectively, ethically, and equitably. The APA recognizes A AI's immense potential to revolutionize healthcare. For consumers and patients, it can enhance diagnostic precision and expand access to treatment and preventative care. especially in behavioral health where we know that there is a huge workforce shortage. for providers, AI can alleviate administrative burdens that can lead to burnout. For example, AI AI-powered ambient scribes, as we've heard today, are already being used to automate progress notes, which frees up clinicians to focus on direct patient

Speaker 2 [10:57:37 AM]
care.

Speaker 1 [10:57:38 AM]
We are also seeing the rise of digital therapeutics, software-based interventions that deliver evidence-based psychological treatments under the oversight of a licensed provider. These regulated tools represent a responsible pathway. for innovations to address the mental health crisis. However, this promise is matched by significant uncertainty. Public trust is fragile, with polls reporting that the majority of Americans are uncomfortable with AI being used in their own healthcare. Currently, this discomfort is not unfounded. First, AI risks amplify existing health inequities. For example, one deployed algorithm determined a patient's level of illness, based in part on their total healthcare cost, but we know that certain patient populations have historically spent less on health care as a result of systemic

Speaker 2 [10:58:31 AM]
issues

Speaker 1 [10:58:33 AM]
So what this leads to is unfairly concluding that they were healthier, making them less likely to be identified for high-risk care management

Speaker 2 [10:58:41 AM]
programs.

Speaker 1 [10:58:42 AM]
This problem can impact patients based on their gender, age, race, ethnicity, and socioeconomic status. Second, the direct to consumer market is flooded with unregulated chatbots, making deceptive and dangerous

Speaker 2 [10:58:56 AM]
claims.

Speaker 1 [10:58:57 AM]
One entertainment chatbot presenting itself as a psychologist. engaged in millions of chats, and in another documented case, the chatbot appeared to validate a user's violent thoughts toward his family

Speaker 2 [10:59:11 AM]
members.

Speaker 1 [10:59:12 AM]
This is unacceptable The APA is formally requested investigations by the FTC and the consumer Product Safety Commission to address these potentially harmful products. To realize AI's promise, while protecting patients, the APA urges the subcommittee to advance legislation and oversight built on the foundation of ethics, equity, and

Speaker 2 [10:59:35 AM]
evidence.

Speaker 1 [10:59:36 AM]
The core mission of healthcare to help and do no harm must be our guiding principle. We recommend 5 key actions. The first, established clear regulatory guardrails. We need a robust federal framework that prohibits the misrepresentation of AI as licensed professionals and mandates transparency and human oversight over clinical decisions. Second, we need to prioritize equitable access to care and mitigate harm. We must require that AI models undergo rigorous independent testing for harms across diverse populations before they are deployed in the marketplace. Third, we must protect vulnerable populations, especially our youth. Adolescents are in a critical developmental period. As outlined in APA's recent health advisory, we must require age-appropriate safeguards and robust data protections to support their healthy development. Fourth, we need to invest in research and AI literacy. AI development is far outpacing the research. We need a significant federal investment in independent research with psychological scientists and developers in the same room to understand ape eye's impacts paired with comprehensive AI literary education for the public and for

Speaker 2 [11:00:57 AM]
providers.

Speaker 1 [11:00:58 AM]
Last, we must enact comprehensive data privacy legislation. A strong federal privacy law is essential. We must establish a right to mental privacy by safeguarding biometric and neural information, like data from wearables that can be used to infer an individual's mental state without their consent. Ultimately, we must ensure that a human remains in the

Speaker 2 [11:01:20 AM]
loop.

Speaker 1 [11:01:20 AM]
AI should be seen as a tool to augment, not replace the clinical judgment and therapeutic relationship that are the benchmark of quality healthcare. The APA believes AI holds the potential to create a more accessible and equitable healthcare system, but only if we intentionally embed psychological science into its entire life cycle. We are eager to collaborate with the subcommittee to develop and act legislation that advances these principles. Thank you so much and I look forward to your

Speaker 2 [11:01:47 AM]
questions.

Speaker 4 [11:01:48 AM]
Thank you very much for committee custom. Each witness will have uh, hang on, did your opening statement. We'll now move on to questions with, and uh I will ask members not to begin a new question

Speaker 2 [11:01:59 AM]
to

Speaker 4 [11:01:59 AM]
our witnesses as their 5 minutes expires and would encourage members to submit written questions for the record. I now recognize myself for 5 minutes of questions. Let's go back to you, Doctor Wright. I thought you made some really good points and, and so let's make this clear for everybody at

Speaker 2 [11:02:14 AM]
home. You

Speaker 4 [11:02:16 AM]
need to have somebody in whatever you're looking at, whatever you think your disease might be or condition. If you're just online and you're using AI online, you need a healthcare professional to help you interpret that to make sure that you haven't gotten a hold of some rogue, untested AIs that basically part of what you said. I know it's not the whole 5 minutes, but you took about 1 minute on that. Is that correct?

Speaker 1 [11:02:37 AM]
Yes, that's correct.

Speaker 4 [11:02:38 AM]
And so we need to make sure that we have the clinicians involved because and, and, uh, originally I was going to ask Doctor Ibrahim this, but uh, I have a uh uh uh article I read a couple of years ago coming out of the London uh Times related to um AI diagnosis of lung disease from X-rays and the radiologist actually did better than the AI because there were so many different factors that had to be looked at and in a different study, part of the problem that, that was identified was they had gotten a lot of the input data from sub-Saharan Africa, where the conditions were very different than the conditions in Europe, and they were given a lot of false positives. And so what we have to do is we have to figure out how much data has to go in before it's effective. And if you could tell us if you haven't, and I know there's no magic bullet, but roughly, I mean, how much data has to go in and I guess the more complicated it is, the more data you need, but you need a fair amount of data in order to make the AI work correctly. Isn't that a fair statement? Thank

Speaker 9 [11:03:36 AM]
you, Chairman Griffith. Um, I agree with your point and maybe would add to it that it's not just the amount of data, but it's the correct data. And ideally to get these models to function correctly, you want to train them on a population that's similar to the one you're treating, and our experience with stroke a lot of our initial data came from the Southeast United States because that's where the stroke belt was and so training our models there was relevant. Um, and that's been a learning curve of the field to know to do that. Um, so I appreciate you raising that point. It's incredibly

Speaker 2 [11:04:06 AM]
important.

Speaker 4 [11:04:06 AM]
Yeah, I appreciate that. I am excited about the potential of AA, uh, uh, Mr. Toy, you raised the issue and, uh, Mara Vans, if I said it correctly and I hope I did, uh, but I have two cases at home that I know about. One was a a friend of mine who, uh, had a form of ALS but apparently there 4 or 5 different types and to get the proper treatment, it took them several years to figure out, uh, exactly what version of the disease he had, and wouldn't AI, I mean, I, I grant you got to get a lot of data in but wouldn't AI help shorten the time period to eliminate or to uh identify which type that he might have had. He's since passed away, uh, the treatments just weren't there and, and by the time they diagnosed it, it was, it was not possible to get him what he needed, but, uh, wouldn't AI help with making that identification shorter. Mike,

Speaker 3 [11:04:59 AM]
absolutely, thank you. Um, I've definitely, obviously we look after a lot of ALS people in our population and within Marfan, I have type 4, and there's like many, many, many different types, exactly as you just said, which uh standard protocols of care are treated actually very similarly. I think with AI you can match symptoms, you can match genotypes, you can match phenotypes, much more precisely in that end of one personalization. I was talking about so that you can then match care uh protocols, drug pro to c ol s directly to the kind of uh disease that your friend, unfortunately.

Speaker 4 [11:05:33 AM]
Yeah, and this can also help in the uh population that doesn't have a family history. Uh, I know of a case where an individual who was adopted had no clue that, that they, uh, might suffer from Huntington's. Uh, they turns out that's what they had, but for, but they spent a year or more looking at MS and other muscle diseases before they, they said, wait a minute, maybe it's something we haven't looked at and A I might help identify based on the symptoms, it might help quicker identify and that's not to say that doctors were doing anything wrong. It's just that they've got hundreds of options and AI can help cut through those options, can it not?

Speaker 3 [11:06:09 AM]
I think absolutely when we talk about earlier identification. This is a huge area that we're seeing already happening with AI, where a doctor will be doing the right thing and looking at this set of symptoms, but then not thinking as much about something that's a little bit rarer or not obvious, and AI can notice something there in the symptom set, and bring it to the doctor's attention. And the doctor then says, oh, yes, I should consider that. And that's a big, big area we see that doctors are saying is helpful uh to have from AI.

Speaker 4 [11:06:35 AM]
Yeah. All right. Last but not least, my district is very rural and economically stressed. Most of my hospitals and community health centers run on very thin margins. What type of upstart software is needed for rural health entities to use advanced AI and machine learning and is it expensive?

Speaker 3 [11:06:52 AM]
Uh, that's a great question. I think that what's really exciting is that the infrastructure we're building on AI and the infrastructure of the country is built on cloud, means that we can deliver these capabilities very quickly to more rural areas, to smaller towns, and they can enjoy the same benefits that a larger, more dense urban center would have, and the same coordinated care as well between different sites of care. So that local independent pharmacist in the small town would be coordinated with the local family doctor in a way that they've never seen, uh, been able to before.

Speaker 4 [11:07:22 AM]
I appreciate it very much. I yield back and now recognize Ms. DeGette, ranking member, for her 5 minutes

Speaker 5 [11:07:27 AM]
questions. Thank you so much, Mr. Chairman, and thanks to all of our witnesses for their very um uh illuminating testimony. There's been tremendous innovation in the machine learning and generative AI spaces in recent years, and the healthcare sector really can see the potential benefit of this innovation, um, and, and, um, all of you gave excellent examples of how this can happen. Uh, one thing that struck me Mr. Toy said that AI should assist doctors, not substitute for them, and I think all of you are nodding, so I think none of you disagrees with this statement, and we all agree with that. Um, so Doctor Mallow, I, I wanna ask you, um, you testified that the uptake of the innovative tools is low, in part because of a foundational trust deficit, is that right?

Speaker 10 [11:08:17 AM]
Yes, Congressman,

Speaker 5 [11:08:18 AM]
so in general, how would you characterize the evidence base supporting the use of novel AI tools.

Speaker 10 [11:08:25 AM]
It's thin, you know, and what we have predominantly comes from the people selling the technology.

Speaker 5 [11:08:31 AM]
And I also suspect there are not well established industry-wide best practices for the use of AI tools in the health space.

Speaker 10 [11:08:38 AM]
We have best practices emerging. The difficulty is why adopt them if there's no incentive or reason to do that to

Speaker 5 [11:08:45 AM]
use them. And at present, which types of institutions are able to measure the impact of AI tools and to optimize their use.

Speaker 10 [11:08:53 AM]
The ones in the best position to do that are the ones with the most money and the most scientific expertise,

Speaker 5 [11:08:58 AM]
right? So is it likely that institutions with fewer resources are going to be able to pull off that sort of robust evaluation and thoughtful implementation in the current environment.

Speaker 10 [11:09:10 AM]
I don't believe so. Certainly not with help from the reimbursement improvements that would enable them to staff up and gain that capacity,

Speaker 5 [11:09:17 AM]
right? So those organizations with the fewer resources that we're talking about like rural hospitals, community health centers, and other healthcare providers, they all serve our constituents. They're facing tighter and tighter resources to do their jobs, and as, as all of you know, and of course my colleagues here know earlier this summer, HR1, which I call the Big Bad Bell was signed into law. What that bill will do, it will kick 15 million people off of their insurance. That's so that's 15 million fewer people who are going to benefit from an AI rev revolution in healthcare and hospitals who need resources to care for our constituents and to work on improving care, including with new AI tools, are facing an additional $400 billion in uncompensated care over the next 10 years. So all told, HR one is slashing over $1 trillion from our constituents care. I've got to say, this is what what I meant when I said in my opening statement that we're fiddling while Rome burns. All of us agree AI can really work. It should be used. We should use best practices, but when we're taking away the money to treat our constituents, then the idea that somehow they're going to find a way to do a a a robust and appropriate AI system is, is it a dream at best. Impoverishing the healthcare system, it's just not gonna help these improvements, and there's no, as we all agree, there's no AI solution that can replace the doctors and nurses that hospitals which will serve the poorest Americans can no longer to afford to employ. And I, I want to say this committee just simply has to stop acting like it's business as usual and ignoring the real problems that are facing our healthcare system and our constituents. If we really want to use AI as a good tool, we're going to have to reverse the cuts to Medicaid before they take effect and devastate millions of Americans, and we're gonna have to stop the administration's damage to our public health system before the emergency lays open our v vulnerabilities. I, I, I, I, I mean, this is really serious. I would like to be able to find a way to, to, um, do some innovation at the FDA. I did that in 2016 with Congressman Fred Upton, then congressman from Michigan. We did 21st century cures which which restructured a lot of things we do at the FDA and the NIH and the CDC and it enabled us to have Operation Warp Speed, which I guess now the president doesn't like, but which saved millions of lives with the COVID vaccine. So, so I would like to be able to help spearhead a bipartisan effort to put the protocols in place and the funding in place at the FDA to do it, to do, to do, um, artificial intelligence folks, that's not where we are right now, and people better know that. I yield back.

Speaker 4 [11:12:30 AM]
Generally yields back now recognize the uh chairman of the full committee, Mr. Guthrie of Kentucky for his 5 minutes. Thank

Speaker 2 [11:12:38 AM]
you, and I

Speaker 6 [11:12:39 AM]
thank you all for being here today. So for Mr. Troy and Doctor Abraham, uh, Clover and Vis AI have both launched successful ad technologies in healthcare. Speaking from your company's own experience. So I'll start with Mr. Toy and then Mr. speaking from your company's experience, how can AI tools be leveraged to empower and not replace providers in ways that can help them better manage and deliver care.

Speaker 3 [11:13:04 AM]
Thank you for the question. I think the key here is, as we've all said, that the physicians in question need to be able to feel like that they are able to do their jobs better than they were before, that the friction is being lowered, and that they are feeling uh effectively empowered to do a better job. There should be a force multiplier that comes from AI. So what they were going to do, perhaps anyway, they can do faster, quicker and easier, including getting reimbursed for that, that, that treatment. So I think that AI we're showing in our own plan is already doing that with our tool Clover assistant. We're putting that in the hands of primary care physicians who are diagnosing diabetes earlier who are managing chronic kidney disease earlier, and that's by synthesizing that data and putting at their fingertips.

Speaker 6 [11:13:49 AM]
Thank you, Doctor

Speaker 2 [11:13:50 AM]
Abraham

Speaker 9 [11:13:51 AM]
And I'll just add to that, and I'll maybe just give perspective for my own practice. I have a clinic every Tuesday afternoon, um, where I may see a dozen new patients, and Monday night I spend 2 or 3 hours to read about them, because to get the 3 or 4 data points that I need to make a decision about their care. I log into 3 or 4 different places. I read through scanned PDFs from an outside hospital to try to piece the whole story together. I know many of my colleagues do the same thing, including for time sensitive things in the hospital to harness our technology, and it's one of the things we've done in our company to help find that information quicker so that the physician can get to what they want to do is make a treatment plan for that patient, maybe one of the most valuable contributions of

Speaker 2 [11:14:31 AM]
AI.

Speaker 6 [11:14:32 AM]
OK, so follow up for the two of you as well. How should policymakers think about ensuring more of these innovations can reach patients and clinicians without overburdensome regulations getting in the way. And we balance the need. How do we balance the need between the appropriate guardrails and patient safety and getting these deployed.

Speaker 3 [11:14:52 AM]
I, I'll take that first. I thank you that question as well. I think that the way we consider it is by having that clinician looking, being accelerated by the AI, knowing that that collision is available to review its recommendations. That serves as an important guard rail in and of itself. And so that we are accelerating what's in their own mind. We are relying on the training that they have. We're just making their job easier. So anytime we're making that uh expanding the possibilities of how we do that with a clinician, a physician. We feel like we're in a pretty good place from a God will perspective.

Speaker 9 [11:15:26 AM]
Thank you, Chairman, and I'll maybe connect my answer to the ranking member to get's previous comment. Um, I have a lot of empathy and sympathy for the FDA at the moment, where they're being asked to evaluate a new technology that they're not really designed to evaluate right now. They're using laws that are decades old or statutes or authorities or frameworks that don't really fit the pace or the way that AI is being used. So support from Congress that would help FDA modernize, whether it's another version of 2 1 s t Century Cures or something similar would be helpful so that the FDA can efficiently figure out which of these products are snake oil and should not be approved, and which of these are approved and once they're approved, they can then be um supported through reimbursement. So I think there's some tangible policy there that would be incredibly helpful.

Speaker 6 [11:16:13 AM]
OK, thank you. And so, Mr. Parker, this committee in the Trump administration has made healthcare price transparency, a top priority? Is that bipartisan? How are price transparency and reporting policies enabling your company to empower American patients in their healthcare journey. And can you discuss the role AI plays enabling general medicine to do this work.

Speaker 8 [11:16:36 AM]
Yeah, I should state very clearly that the work we're doing to show consumers' prices upfront for procedures, labs, imaging, anything that they need would not be possible without all of that work. Um, we are using the open pricing files to figure out the, the sort of reimbursement and their specific pricing for the consumer, but the, it really also wouldn't be possible without AI, you know, the example I shared in the testimony is we're literally taking down your full 100 page coverage of benefits and using AI to read those coverage and benefit s and turn it into useful data. Um, and then munging that together with the open pricing files to give patients a clear out of pocket price. So it really is a byproduct of all the work that's been done over the last decade to uh to require providers to disclose these, these pricing

Speaker 2 [11:17:21 AM]
files.

Speaker 6 [11:17:22 AM]
And, and, and so it the providers, insurance companies, whatever PBMs, you have to have the price data publicly available for AI to be able to call out and give people the best answer.

Speaker 8 [11:17:33 AM]
That is correct,

Speaker 6 [11:17:34 AM]
because if it's hidden data then AI is not going to find it. Right. Thank you, and I, you're back.

Speaker 4 [11:17:41 AM]
Gentleman yields back and I recognize the ranking member of the full committee, Mr. Boone, for his 5 minutes of

Speaker 2 [11:17:46 AM]
questions.

Speaker 7 [11:17:47 AM]
Thank you, Mr. Chairman. I'm trying to get in two questions to Doctor Mellow and one to Doctor Wright. So, bear with me here. Doctor Mela, we're witnessing a significant increase in AI-driven medical product development, given the rapidly expanding technologies, we must ensure that we also better understand and evaluate how these AI enabled devices function so they don't put patients at

Speaker 2 [11:18:09 AM]
risk.

Speaker 7 [11:18:10 AM]
So my question or first question, to achieve this, do we have the appropriate regulatory framework in place, and does the FDA's current statutory authority allowed the agency to be nimble in its oversight of AI enabled devices, if you will.

Speaker 10 [11:18:25 AM]
Thank you for the question. I'll answer the second part first. I think the agency has been remarkably nimble given what they have to work with. But what they have to work with does not allow a great deal of maneuvering room. So absolutely, there needs to be modernization to solve two problems. One is that they can't do enough. And one is that the statutory framework requires them to, to do too much or the wrong things given the type of technology that they've confronted now, as Dr. Ibrahim has said.

Speaker 2 [11:18:52 AM]
OK.

Speaker 7 [11:18:53 AM]
And I'm also concerned that there are insufficient guardrails in place to protect patients from bias in AI and coverage denials for necessary care. In July, the Trump administration announced the wasteful and inappropriate service reduction model, which would impose prior authorization and traditional Medicare and allow for profit companies to use AI to perform prior authorization reviews, and I'm concerned that this AI model will result in denials of life saving care and incentivize companies to restrict care. So my question is, how can we ensure that these algorithms are not being misused to delay and deny life saving care for patients, if

Speaker 2 [11:19:31 AM]
you will.

Speaker 10 [11:19:32 AM]
Right. So, the WIr program really raises two questions. One is, when we take a process that is fundamentally and for a long period of time slot and put it into traditional Medicare, what would we expect to happen? And then the second is when you take that process, prior authorization and amp it up with AI, what will

Speaker 2 [11:19:48 AM]
change?

Speaker 10 [11:19:49 AM]
Uh, I think we have pretty good evidence that prior authorization as a process itself is, is fraught, uh, that there are high rates of wrongful denials, low rates of appeal, high rates of overturn on appeal. So we should have some concern about any effort to expand its use, while at the same time recognizing that in some areas, including, I will say the areas that Weiser currently targets, it is a necessary cost control. The question is how you do it. And then the second issue is what happens when you bring AI into the game. And there, we don't know. We don't know because there are no public ly available information that would enable somebody like me to be able to tell you, does using AI make prior authorization better for patients or worse? I think both outcomes are very possible.

Speaker 7 [11:20:34 AM]
All right. Let me go to Doctor Wright. Another area of concern is the intersection of mental health and AI, um, if I could, Mr. Chairman, I'd request that the Washington Post article titled What is AI Psychosis and how can CAGPT affect your mental health, be submit ted into the record, if you will, Mr. Chairman. Yeah

Speaker 4 [11:20:53 AM]
the date on that.

Speaker 7 [11:20:55 AM]
What's that? We've been, I think we have it? OK,

Speaker 4 [11:20:59 AM]
without objection. All right, thank you

Speaker 2 [11:21:01 AM]
ordered

Speaker 7 [11:21:02 AM]
So Doctor Wright, the question is, the American Psychological Association issued a health advisory on AI and adolescent well-being in June, calling for robust protections for young people interacting with AI, urging developers to implement safety features and for educators and parents to foster comprehensive AI literacy. So, can you share information on what prompted APA to issue this advisory and what your members are seeing in their practices that would relate to that?

Speaker 1 [11:21:31 AM]
Thank you for the question. Yeah, APA really felt a sense of urgency to look at what the psychological science has to say in this space, because um as we've said, AI development is just outpacing the research and the guardrails, and we've been hearing from both clinicians who are seeing patients that are coming in with their chat GBT advice and we've heard the public stories like The Washington Post story you just mentioned about the harms that seemingly are happening in part because to

Speaker 2 [11:22:03 AM]
uh

Speaker 1 [11:22:04 AM]
Mr. De Goett's point, we have a broken mental health system, and so people are seeking out help wherever they can find it. Um, and that, while very human, might not be a best idea. And so I see a future where, you know, we will have um mental health options that are more appropriate that do utilize AI, but that's just not what's on the commercial market right now, um, and so helping parents, uh, teachers, educators, technologists understand what is the psychological science say about how to do this well and what are the considerations that need to be factored in, is is a huge part of why we put out that advisory and why we're also standing up a second advisory more specific to the use of these wellness chatbots and these general chatbots.

Speaker 7 [11:22:49 AM]
Thank you. Thank you, Mr. Chairman.

Speaker 4 [11:22:53 AM]
Demon yields back now recognized the vice chair of the subcommittee,

Speaker 2 [11:22:58 AM]
Ms. Harshchberger.

Speaker 5 [11:23:00 AM]
Thank you, Mr. Chairman, and thank you to the witnesses for being here today. Uh, I'm excited about this line of questions and I hope you are too, um,

Speaker 2 [11:23:08 AM]
I'll

Speaker 10 [11:23:08 AM]
start with Mr. Parker,

Speaker 2 [11:23:09 AM]
uh, you know, I'm

Speaker 5 [11:23:12 AM]
excited about the fact you, you've got a one stop shop

Speaker 2 [11:23:14 AM]
for

Speaker 5 [11:23:15 AM]
telehealth, basically telemedicine. If you can do the labs, the prescription, give them the price and do all that and bill insurance or let them do a cash

Speaker 11 [11:23:24 AM]
model, kind of like a concierge service, you know, when you walk into a brick and mortar, uh, I guess, uh, enhancing the role of the clinician is a key win for technology and it's part of the expansion of the over the counter drug class, the FDA promoted something called additional conditions for non-prescription use. And what this essentially means is consumers can answer some questions on the phone app or another, uh, technology platform to determine if a drug is right for them and then access a prescription drug therapy. Uh, so how do you see technology and automation as a platform to expand and reinvigorate the practice of community pharmacy since that's what I am a compounding pharmacist, and I have a community pharmacy.

Speaker 8 [11:24:07 AM]
Yeah, it's a great question, and I think as we all acknowledge, pharmacists are, are underutilized compared to their capacity. Um, and I do think if, if you take some of the work that we've done at General Medicine where we've worked really hard to codify these intakes for specific medications. So it's very, the the clinician, which in this case could be a pharmacist has all the information they need to make a judgment on whether it's appropriate for the patient in that moment would apply very well in that setting. I think it wouldn't just be constrained to a traditional c lin ical setting. And so I think a lot of the, the logic infrastructure and work we're doing would be a, would be a great opportunity for pharmacists to participate more in that.

Speaker 11 [11:24:46 AM]
Absolutely, thank you for that. We need to practice at the top of our lessons, which is something I'm working on too. uh, Mr. Toi, you, you mentioned that as far as utilizing your, uh, community provider in rural areas in your pharmacist, can you, what do you think about this?

Speaker 3 [11:25:02 AM]
Absolutely. I think that and and you probably see this in your own practice, but um there's not a lot of coordination right now between the actual pharmacist and the physician, oftentimes a physician uses their mind, they think about things, they write a script, and then they're like, OK, where would you like that filmed, right? Um, that's the question they asked the patient. And so what we want to make sure is that there's coordination there. I make it very easy for the pharmacist to have the same information that was available. And the thing that AI can do also is take that same information and customize it, not just to the patient, but customize it to the clinician in question. So it'll show a certain version of that to the PCP and it'll show up a more pharmacist relevant version of that to the pharmacist, but they're seeing the same data, but two different facets of that same data, so they can then apply their clinical.

Speaker 11 [11:25:46 AM]
Oh, you work with collaborative agreements between a physician and a pharmacist is, is how you would do that in every state's different. So, you know, that's why I'm looking at a kneecap spill and some other things associated with that. So, yes, sir. I, I got it. I'm glad you're on my team.

Speaker 2 [11:26:02 AM]
Thank you.

Speaker 11 [11:26:03 AM]
Uh, Doctor Ibraham, uh, while some applications of AI and healthcare such as basic chatbot uh may appear relatively low risk. Uh, others carry higher, um, stakes, including tools targeting mental health, minors, or caring coverage of determinations, uh, should Congress begin to define high-risk categories of generative AI and healthcare, and if so, what safeguards like, uh, such as independent validation of clinical claims or patient safety protocols for sensitive use cases may be labeling and disclosures for consumers and what would best protect that um patient without stopping that innovation.

Speaker 9 [11:26:41 AM]
Thank you, Congresswoman. innovation moves at the speed of trust. That is something we've all sort of been trained and brought up in, in our practice, anything that we've tried to bring to patients requires a partnership with Hospitals first, where we map out what do we have the capabilities to do? What are their needs? We pilot things several times in historic data before even trying it in real clinical practice and then have rigorous milestones to meet before it actually gets scaled to any other um settings, and that's been our practice in part because that is necessary for our business if we do not establish that trust and maintain it, um, we will lose our clients, so it's required for us to to do that fundamentally. Um, the FDA has some precedent for devices, which is what much of this has been mirrored on, and there likely is a similar tiering of class 123 devices that would mirror an AI technology. Um, I think that would be welcome guidance to help create some road maps so we understand where we need to spend a lot of time and be methodical and rigorous, and wear things that we can accelerate

Speaker 11 [11:27:48 AM]
faster. Yeah, output's only as good as the input and it better be correct, right? OK, thank you, sir, and Mr. Chairman, I you back, lady

Speaker 4 [11:27:55 AM]
yields back now recognized gentleman of California, Doctor Rees for his time of questioning.

Speaker 2 [11:28:00 AM]
Thank you, Mr. Chairman.

Speaker 9 [11:28:02 AM]
Artificial intelligence has potential for expanding access to healthcare and improving patient care.

Speaker 2 [11:28:08 AM]
However,

Speaker 9 [11:28:09 AM]
as with any new or developing technology, we need to make sure that we

Speaker 12 [11:28:13 AM]
are evaluating any potential harms and ensuring appropriate safeguards as the technology continues to expand. It is crucial to directly address the risks, including mental health risks that AI tools may pose for our

Speaker 2 [11:28:28 AM]
children.

Speaker 12 [11:28:29 AM]
Doctor Wright in your testimony, you discussed the need to protect vulnerable populations like youth. You stated that quote AI systems designed for adults are not necessarily appropriate for youth. Could you please explain what specific dangers and potential harms AI technology used for healthcare can have on children and their development.

Speaker 1 [11:28:49 AM]
Thank you so much for the question. Um, so I think when we think about the model, right, it's really about representativeness and ensuring that whatever training model we're employing has been um trained on the data that's appropriate is critical because you do end up seeing these harms when you've got systems that were developed for adults and children are not just little adults. They have very different developmental trajectories. What is um helpful for one child may not be helpful to somebody else, uh, not, not just based on their age, but based on their temperament and um how they have been raised. So, you

Speaker 2 [11:29:25 AM]
know,

Speaker 1 [11:29:26 AM]
at worst, some of the harms we're seeing have been, you know,

Speaker 2 [11:29:30 AM]
uh

Speaker 1 [11:29:31 AM]
alleged completed suicides and also suicide attempts and much of and suicidology discussions with different types of chatbots. Um, you've seen, as I mentioned in my testimony, there is a case in uh

Speaker 2 [11:29:45 AM]
in Texas,

Speaker 1 [11:29:46 AM]
where a young individual, um, following the validation and advice from a chatbot attacked his family and had to be hospitalized. Um, so the harms are real. Um, we also have you, uh, positive use cases on top of it, right? So I hear stories of children who use a chatbot to practice their social skills so that they can make a new friend at school. It's not an all good or an all bad thing. It's about how we use the tool appropriately, how we safeguard it, how we test its effectiveness, um, to ensure that children who are going to continue to use these AI tools because they're not going away, we'll be protected.

Speaker 12 [11:30:23 AM]
You know, I too, I'm alarmed at stories of individuals turning to AI chatbox as a source for therapy, including the tragic story of teenager, uh, California teenager Adam Raine. Chat GPT provided mental health resources when Adam shared his suicidal ideaations. Maybe a pop-up or something which is inappropriate in a clinical setting. Imagine you're admitting your suicidal thoughts and the clinician just holds up a, a poster board with a hotline number and then continues with more deep conversations about how to actually complete suicide. So it's, it's completely not clinically appropriate, uh, or or that helpful. Um, Doctor Wright, if AI systems can behave unpredictably, what enforceable guardrails are needed to ensure that they do not worsen crisis or harm individuals, especially those seeking mental health resources and what benchmarks must be met before AI can be responsibly scaled as a tool for mental health support, especially for

Speaker 2 [11:31:27 AM]
youth. Well,

Speaker 1 [11:31:29 AM]
I think at first, we have to ensure that these tools do not misrepresent themselves as licensed professionals, that they cannot call themselves psychologists or psychiatrists or social workers, because that gives a sense of credibility that doesn't exist. I think on the back, the real

Speaker 2 [11:31:44 AM]
um

Speaker 1 [11:31:46 AM]
expertise for these products are on the back end. They're how they're being coded and we could encourage companies to make them less addictive in their coding tactics and make it so that user engagement isn't the sole outcome that they are trying to achieve. Um, I

Speaker 2 [11:32:01 AM]
think

Speaker 1 [11:32:02 AM]
some of those things would also help. We could also ask ask for specific audit and reporting requirements where these companies had to actually disclose anytime they detected suicidology or uh attempted or completed uh suicides. We could have better age verifications and age restrictions. Um, I, I think there are some pretty low level things that we could do that would actually ensure that these tools are used better. We also just need better tools.

Speaker 12 [11:32:27 AM]
And what can we do for uh to educate clinicians on how to use these.

Speaker 1 [11:32:33 AM]
Well, I think for sure clinicians need a lot of education on how to use these. Um, I think part of why you haven't seen adoption is the anxiety and the fear that these tools bring, um, and, and the lack of understanding of how they work. Um, so I

Speaker 2 [11:32:48 AM]
think

Speaker 1 [11:32:49 AM]
helping providers know what works, with the limitations of these tools are, um, is the first step towards helping them decide whether or not they want to choose to implement them in their practices.

Speaker 12 [11:33:01 AM]
Thank you, I yield

Speaker 2 [11:33:01 AM]
back.

Speaker 4 [11:33:03 AM]
gentleman yields back now recognized the gentleman from Florida, Mr. Billarakas, for his 5 minutes. Thank you. I

Speaker 7 [11:33:08 AM]
appreciate it, Mr. Chairman

Speaker 12 [11:33:10 AM]
All right, this is a great hearing. I thank the witnesses. One area that I'm interested in is the role of AI and drug development, particularly in the rare disease space. Scientists have developed AI models to identify drug candidates from existing medicines that could be applied for rare diseases with unmet needs. Uh, the innovation is just the beginning, and we should continue to explore similar applications to improve our healthcare

Speaker 2 [11:33:39 AM]
system. Most

Speaker 7 [11:33:40 AM]
people agree with that. The question is

Speaker 4 [11:33:42 AM]
from, uh,

Speaker 12 [11:33:43 AM]
mister, this is for Mr. Troy, Mr. Troy, uh, your testimony discusses your personal experience as a rare disease patient Thank you so much for sharing your story. It really means a lot to the community. Can you share further how AAI will continue to accelerate the patient diagnosis journey, please.

Speaker 3 [11:34:05 AM]
Absolutely and thank and thank you for talking about rare disease here among the committee. Um, so speaking as someone there, I'm also serve on the board of the Marfan Foundation. Um, it's a rare disease. It's a genetic-based disease, and so it's something I would point to is rare diseases are uh rare individually, but across like the entire country, many people have a family member who has at least one form of rare disease. So they're not rare in collection. The other thing I would say, and we discussed it here, and we're talking about clinicians. I think the key thing is most clinicians are in their training, they, they, the, the chance of having a clinician who has the training, the CME, the continuing medical education on your rare disease. It's actually quite low because they can't take training on everything there. What AI can do is help them, uh, learn more about the condition, also help them identify practitioners in the area who have more expertise in those and collaborate with those practitioners and get a given uh patient closer to a site of excellence for that rare disease.

Speaker 12 [11:35:05 AM]
Very good. Excellent. Appreciate that information. Uh, Doctor Wright, uh, and again, uh, I'm just following up with uh Doctor Ruiz on, on this particular subject. Uh, Doctor Wright is chair of the conference, uh, the Commerce Manufacturing trade at subcommittee. I'm very interested in protecting children and teens online as we all are. And that space, there's a lot of talk about the how children and teens using online services may face greater risk of suicide, self-harm, and other dangers. One discomforting, uh, new trend is the rise of AI chatbots, which we've been discussing, which I'm concerned may exacerbate existing problems of loneliness and social isolation among young people. While still early days, the prospect of children and teens socializing, primarily with chatbots and and building supposed re relationships and even romantic relationships, uh, with these new online services is troubling to many parents. Uh, can you speak to how loneliness and social isolation impacts children and teens' development. and what could the long term impacts be of children and teens interacting primarily with AI chatbots instead of their peers.

Speaker 1 [11:36:39 AM]
Thank you for the question. Yeah, um, obviously, we are very concerned as well on the world that all emerging technologies will have on our children and adolescences. In our recent Stress in America

Speaker 2 [11:36:51 AM]
survey.

Speaker 1 [11:36:52 AM]
the majority of all adults that included children, so that they feel like they can't talk to people about their stress cause they don't want to burden them. We also have a study that says that adolescents would prefer to speak with an ambient source like a chatbot, then a person because they fear being

Speaker 2 [11:37:08 AM]
judged.

Speaker 1 [11:37:10 AM]
This is a real challenge in our culture, and yes, it is spurring increased loneliness and isolation. So what do we need to do as a culture to help people understand that coming together and having empathy and so and having social connections is actually the better solution than turning to these technologies as a replacement for

Speaker 2 [11:37:31 AM]
people.

Speaker 1 [11:37:32 AM]
They can be a huge tool. As long as you use them and then go back to the people that you're trying to connect with. And so if we as parents need to model good use of these technologies for kids. We need to help them understand what the risks of them are. what the business models are, and how that influences how they interact with them. And part of that's going to have to be how we teach this in schools, to kids, because again, this AI is not going away But how do we help people remember that it's personal connection that makes us the people that we are.

Speaker 12 [11:38:08 AM]
Absolutely. Thank you very much. I appreciate you're back, Mr. Turman.

Speaker 4 [11:38:12 AM]
Jim and yields

Speaker 2 [11:38:13 AM]
back

Speaker 4 [11:38:14 AM]
and now recognize the gentle lady from Michigan. Ms. Dingle for her five minutes.

Speaker 5 [11:38:21 AM]
Thank you, Mr. Chair, and thank, uh, you and our ranking for holding this hearing on the use of artificial intelligence and healthcare systems. Look, AI is transforming every sector. And we've seen that this emerging technology has the potential to transform lives and improve healthcare incomes, but let's be

Speaker 2 [11:38:45 AM]
honest

Speaker 5 [11:38:46 AM]
with rapid advancements come serious challenges as well. Any potential AI related legislation must consider potential data privacy which I worry about deeply.

Speaker 13 [11:38:59 AM]
uh, a bias, displacement of jobs, and in the case of healthcare, misdiagnoseses, and as our witness also said, the humanness of patients and you need compassion and empathy. It's also important to highlight the context in which we are having this conversation

Speaker 2 [11:39:18 AM]
Um,

Speaker 13 [11:39:19 AM]
my Republican colleagues in Congress and the Trump administration have already enacted and seek to advance further reductions in staff and funding of our healthcare system. Adequate resources are critical to ensuring that the usage of AI technology in the healthcare space is subject to guardrails that protect the safety of the providers, the patients and their loved ones. So Doctor Mellow, as providers grapple with the increasing presence of AI in their workplace. Many worry that this technology jeopardizes patients' right to high quality care and displaces our talented doctors and nurses. How can we ensure that AI serves as a tool that physicians use to enhance care, not one that replaces person to person

Speaker 2 [11:40:08 AM]
care.

Speaker 10 [11:40:09 AM]
It's an important question in the context that you specifically raise of cuts in Medicaid reimbursement, just intensifies both the need for AI to augment capacity in rural and low-income hospitals, and also the constraints around their ability to monitor it properly. Uh, I think there is a lot of promise in use of AI to address the needs of populations in those facilities, especially those with complex needs, but they will need help and assuming as many organizations do, that simply because there's a human in the loop, we don't need to provide support, training, and institutional level monitoring is a grave mistake. Let's not forget the whole reason that organizations are implementing many of these technologies like scribes and, and note summarizations is the burnout that afflicts those facilities. So these people in the loop, this is not Superman. They need support and it has to be at the institutional level.

Speaker 13 [11:41:04 AM]
So let me take that one more step down. Many patients, particularly senior s individuals with disabilities and children, as we're talking about, have unique needs that require knowledge and care of a human provider. What specific considerations are necessary to preserve the level of patient care for those with complex health conditions as AI plays a larger role in their

Speaker 2 [11:41:29 AM]
care.

Speaker 10 [11:41:30 AM]
Well, as I think about that question, I have to start from where we are now, which is that those patients are in many ways really poorly served by the system we have in its extreme fragmentation of both care and information. So I actually think to, to some of the testimony that other witnesses have given here that those are some of the best opportunities for AI to make things better, but there are reservations that I have as well, in part because patients in that position are not themselves positioned to be good overseers of the AI that's being used in their care. For example, whereas I might be inclined to review an after visit summary that I know an ambient scribe generated, somebody who's dealing with multiple complex posi conditions will not. And so we need to be extra careful about monitoring for them.

Speaker 13 [11:42:15 AM]
I have some thoughts, but I'll put them in another question. I'm gonna have time for one more. I want to turn to the potential mental health impacts of AI, particularly young women and girls. We know that the victims of abusive AI generated content such as Steve Bakes feel isolated and distrustful around them. We've already talked about depression, anxiety, suicide, etc. I was one of the proudly leads of the Take It Down Act, but Doctor Wright, because I'm almost ahead of time, how can our mental health care system be bolstered to better respond to the impact of AI enabled abuse.

Speaker 1 [11:42:53 AM]
Well, thank you for the question. I, I think in part it starts with helping providers, clinicians, and others, um, really know how to evaluate the tools and what they should be looking for if they're going to incorporate these tools into um any kind of setting that they're doing. Um, and I think it's about helping clinicians and providers know what questions to ask of their patients about their AI use.

Speaker 2 [11:43:15 AM]
I,

Speaker 1 [11:43:15 AM]
I, I think,

Speaker 12 [11:43:16 AM]
uh, a

Speaker 1 [11:43:17 AM]
lot of providers have no idea where to even start to ask that question. And so you can't even sift out whether abuse is happening if you don't know the right question to ask. And so it's these sorts of things, these, whether they're continuing education trainings that that providers get or we think about how do we train individuals within the school settings so our future providers because they're the ones who are really going to be up against it.

Speaker 13 [11:43:41 AM]
Thank you, Mr. Chair. I'm out of time, so

Speaker 4 [11:43:44 AM]
I'll yes ma'am, gentle lady yields back now recognize a gentleman from Florida. Doctor Dunn for his 5

Speaker 2 [11:43:54 AM]
minutes.

Speaker 7 [11:43:55 AM]
Thank you very much, Mr. Chairman, and, uh, and thank the witnesses for being with us here today.

Speaker 14 [11:44:00 AM]
As a medical doctor, I'm certainly excited to see the advances today AI can make possible in healthcare, uh, from improving efficiency at the administrative level to assisting providers in clinical practice. I'm sure it's uh it's gonna be great for all of us. You know, we clinicians are drowning in paperwork, and I think that that could be the low hanging fruit for, uh, for, uh, AI frankly. It's essential that the United States remain at the forefront of AI, and I firmly believe the FDA should be continuing to work with pioneering companies to ensure that patients benefit from the full scope of AIchnologies. Uh, it can also be, you know, valuable and complementing the work done by physicians to provide better healthcare outcomes. Uh, but by reducing the administrative burdens and costs. I think it can give us far more time to focus on our patients and save money. And by assisting in clinical decisions, AI can bolster the human expertise, uh, in, in medicine. Doctor Ibrahim, a patients know that uh physicians are essentially irreplaceable. The system at this point. We are the linchpin of human responsibility. You and I are both physicians. We know we can be more efficient. Uh, how do you see the earliest applications of AI and clinical medicine as increasing the efficiency of frontline conditions

Speaker 2 [11:45:30 AM]
or

Speaker 14 [11:45:31 AM]
replacing your administrative burdens.

Speaker 9 [11:45:35 AM]
Thank you, Doctor and Congressman. I appreciate your question and that strikes personally close home to me. Um, I think if I could go home to my family and say instead of reading charts Monday night for 2 hours. All that information would be ready for me in clinic, and I could just spend time with my family. I think that would be great. There are a number of things that we need to do in the hospital that require a significant amount of manual abstraction, whether it's quality reporting, whether it's documentation or billing. Many of those things require very highly trained people to spend hours of time literally sometimes checking boxes for information that we could readily extract. So I think there's enormous potential to get people actually doing the things that they want to do, um, and doing less of the things that we could probably automate now. Um, it certainly would require, as mentioned by the panel, that we have the right safeguards in place and the right checks to make sure it's being done appropriately, but I think there's a lot of potential there.

Speaker 14 [11:46:30 AM]
Couldn't agree with you more to that end, Doctor Abraham. Uh, can you envision a world where most imaging studies, pathology slides, radiology, pattern recognitions, whatnot are pre-read by software.

Speaker 9 [11:46:46 AM]
Uh, thank you again for that question. I think pre-red is challenging. I think the idea that it could triage and identify high risk conditions to say this imaging likely stro shows high risk stroke, or this shows a life threatening heart condition, still needs a human to really um solidify that from our own data. We know it's not near perfect yet, but it helps identify the highest risk ones. Um, I don't know, it'd be too hard to speculate if we would get to a time in my career where that could be entirely automated.

Speaker 2 [11:47:19 AM]
Well,

Speaker 14 [11:47:19 AM]
I, I agree with you, by the way, on that, but I, I think that there, we may need some updates on the CMS payments model to make that world possible. Can you see uh how that might happen?

Speaker 9 [11:47:33 AM]
Um, CMS currently does have an opportunity um through NTAP for new technologies, um, are able to be temporarily reimbursed for 3 to 5 years. That assist with either EKG reads or radiology reads. I think it would be great to have that a more permanent pathway to reimbursement, um, but that would still, um, be in the assistance category.

Speaker 14 [11:47:54 AM]
Thank you. Thank you very much for your thoughtful answers, and I look forward to working with my colleagues to ensure that AI and healthcare is utilized to its maximum potential and ensuring patient safety remains at the forefront. With that, Mr. Chairman, I yield back.

Speaker 11 [11:48:11 AM]
Gentleman yields back and now I recognize uh Representative Kelly for her five minutes of questions.

Speaker 2 [11:48:18 AM]
Thank you, Madam Chair, and ranking member to Getford holding today's hearing and thank you to all the witnesses. It is important that we do not ignore how in this last week Secretary Robert F. Kennedy Jr. and others in the Trump administration continue to

Speaker 15 [11:48:31 AM]
undermine Congress and the public health system's ability to function cohesively with the firing of senior staff and experts. Secretary Kennedy is putting Americans' health and well-being at risk by actively disseminating HHS. Unfortunately, too many of my dismantling, excuse me, HHS. Unfortunately, too many of my colleagues remained silent on this devastating public health issue and other harmful policies caused by the big ugly bill, but I work continues, and that's why I'm proud to co-chair the bipartisan d Digital Health caucus with my colleague Rep Troy Balderson. I encourage my colleagues on both sides to join us as we aim to educate and learn more about these issues. The integration of AI in the healthcare system offers a potential to be a transformative solution to address long-standing disparities and access issues as I have talked about. Many in both the healthcare and technology fields have promoted AI to create a more accessible and equitable healthcare landscape, particularly in minority undeserved, and rural communities. However, we must remain vigilant of the promises, as well as the limitations. Doctor Mello, AI tools are only as good as a data they're built on. When the data is incomplete or skewed, the results may lead to inaccurate suppositions. We've already seen examples where algorithms underestimated the needs of black patients because healthcare costs were used as a stand-in for health status and where dermatology tools trained mostly on lighter skin tones, misdiagnosed conditions on darker skin. These cases show how quickly AI can replicate inequities already in our healthcare system. What steps should developers health system then federal regulators take to make sure AI tools are tested on and validated for diverse populations before they're deployed.

Speaker 10 [11:50:26 AM]
It's such an important question and I know you've heard already about the need for large data sets that include sufficient representation from a variety of subgroups, including all a subgroups that are not usually on the map for anti-discrimination worries, like kids, people in rural areas, people with rare conditions. Um, and FDA of course, should be doing more in the area of performance testing. But let me add a wrinkle that I think doesn't get talked about enough. And that is that even when you have a well-performing algorithm that performs well for all of those subgroups. bias and inequities arise at the point of care because of the way that it's deployed, and I'll give this a simple example. We've got tons of algorithms at Stanford that screen our patients using information in their medical record to identify people who would benefit from additional services, but our ability to get those patients in the door is dramatically different depending on what those patients look like and where they live. So unless we're willing to spend more money doing outreach and creating more capacity in our clinics for those patients. They can benefit in theory, but not in reality.

Speaker 15 [11:51:29 AM]
Interesting you say that. As chair of the digital digital Health caucus, a co-chair, one of the things I'm looking to better understand is how AI and data science can help with efforts such as clinical trial recruitment and retention. I'm also chair of the Congressional Black Caucus, Hell Brain Trust. What are some ways AI can be used to get more people into clinical trials, and what ethical or policy Garriel should Congress consider as we support this responsible

Speaker 2 [11:51:57 AM]
use.

Speaker 10 [11:51:58 AM]
Well, I think the main area where AI can help is in the identification of potentially eligible patients. We heard already about the NIH initiative at Stanford, we have a new tool being deployed across our system now that enables a researcher to to query the medical record to find all patients who have a particular health condition and meet other inclusion criteria for the trial, and that could be hugely helpful. I will say though that the major, a major reason why we don't have representation in clinical trials is not that we can't identify the patients, it's that we can't convince them to enroll. and AI is never gonna get us there. That's where we really need the human touch, reaching out to those communities and explain the benefits of trial participation along with the

Speaker 2 [11:52:37 AM]
risks.

Speaker 15 [11:52:38 AM]
In my office has been doing a lot of work around that because we know all the past issues that people have and the, the lack of trust, but we know there's still a lot more work to do. Thank all of you so much and I go back.

Speaker 11 [11:52:51 AM]
gentlewoman yells back and I now recognize my friend Doctor John Joyce for 5 minutes of questions.

Speaker 4 [11:52:59 AM]
Thank you, Madam

Speaker 2 [11:52:59 AM]
Chair

Speaker 7 [11:53:01 AM]
Much like other industries, the growth rate that we're seeing in AI within healthcare over the last few years has dramatically expanded,

Speaker 12 [11:53:10 AM]
offering the potential to fundamentally alter how care is developed and

Speaker 2 [11:53:15 AM]
delivered.

Speaker 4 [11:53:16 AM]
A key area of this growth is in the FDA approved AI-enabled medical devices. Just over a decade ago, there were just 6

Speaker 2 [11:53:26 AM]
approvals

Speaker 4 [11:53:27 AM]
by the FDA for

Speaker 12 [11:53:28 AM]
AI-enabled medical devices. Today that number exceeds

Speaker 2 [11:53:33 AM]
600.

Speaker 4 [11:53:34 AM]
CMS has begun to offer some level of coverage for software-based technologies to support clinicians and is currently seeking input as part of the proposed CY 26 physician fee schedule and outpatient payment rolls.

Speaker 2 [11:53:50 AM]
However,

Speaker 4 [11:53:51 AM]
I believe that more can be done here to

Speaker 7 [11:53:53 AM]
provide a sustainable and consistent pathway for these devices

Speaker 4 [11:53:57 AM]
under Medicare. This is why I've been working with senators Round and Heinrich on introducing a House version of the health tech Investment

Speaker 2 [11:54:05 AM]
Act,

Speaker 4 [11:54:06 AM]
which would do just

Speaker 2 [11:54:07 AM]
that.

Speaker 4 [11:54:08 AM]
Doctor Mello and then Doctor Abraham. Do you feel that the lack of a stable environment for reimbursement for these new devices, makes it much more challenging for rural and small hospitals like those

Speaker 7 [11:54:22 AM]
that I represent in Pennsylvania's 13th congressional district to invest and ensure that rural patients and communities

Speaker 4 [11:54:30 AM]
have access to the latest innovation. First, Dr. Mello.

Speaker 10 [11:54:34 AM]
I do. There's no question that when you're trying to just get through the day, thinking about innovation and staying on the cutting edge of future care is not possible in the thought space and resources that you have. So there are many things we can do to provide direct assistance to rural hospitals both in the academic sector but also in the policy sector and the reimbursement piece, as you said, is critical. I think the, uh, you know, the FDA example that you, you began with is really illustrative because uh that is an area where, despite regulation, despite clearance processes, we've gotten a lot of those innovations out broadly to hospitals. These are overwhelmingly radiological tools, uh, of the nearly 1000 applications approved by the FDA um overwhelmingly. These are radiology tools, and we've done a good job getting him out into practice.

Speaker 4 [11:55:20 AM]
And you see that mostly those are in major metropolitan areas and not in rural areas.

Speaker 10 [11:55:25 AM]
You know, again, it depends on whether there's a mechanism for billing for that extra. And, and it's really critical to remember the extra is not just the cost of buying the thing The extra is the cost of training radiologists on how to use it and making sure that it's working well for everybody. And that's where a rural hospital might be willing to adopt, but not do the work of keeping people as safe as they could be.

Speaker 4 [11:55:45 AM]
Dr. Ibraham, could you please comment?

Speaker 9 [11:55:48 AM]
Thank you so much for the thoughtful question, doctor, and I appreciate you bringing up rural Health. Some of the most impressive improvements we've seen in stroke care from our technology have been in rural work, um, that one of the references in interventional neuroradiology in my testimony, uh, was from Texas, sharing that in deep rural Texas, we were able to improve some of the time to treatment by 80 minutes in stroke patients. You are correct to identify the tension there that when hospitals make a decision about whether or not to adopt the technology, the ability to get reimbursed for it is front of mind. If we are able to identify ways to reassure hospitals that there will not only be temporary payment, but sustained payment for technologies that have already gone through the rigor of the FDA and gotten approved as safe and effective. Um, that would do a lot to help improve the adoption of these technologies.

Speaker 4 [11:56:38 AM]
Thank you. In my remaining time, I want to pivot to Doctor Toy. Um, we recognize the opportunities that AI has provided. It is loose ly regulated usage in prior

Speaker 14 [11:56:49 AM]
authorization, that is my concern.

Speaker 4 [11:56:52 AM]
In fact, in March of 2025, the AMA uncovered that over 60% of physicians are concerned that the expanded use of AI in prior auth is exacerbating the rate of incorrect care denials. Over 60% of doctors. Given this concern of from physicians, do you feel that AI should be leveraged in the AI author prior author ization decision making process. And if that answer is

Speaker 8 [11:57:21 AM]
yes, what

Speaker 12 [11:57:22 AM]
guardrails should be put up?

Speaker 3 [11:57:24 AM]
Thank you for the question there. So definitely in the case of prior au, I think that right now at Clover ourselves, we do not use AI in any form within the prior authorization process.

Speaker 4 [11:57:33 AM]
But are you aware that many men, many burial care advantage plans utilize and Medicaid managed care plans do as well.

Speaker 3 [11:57:40 AM]
Absolutely, and I think that from our position, they should not be used in any kind. AI should not be used to review, to deny in any case. Like that is not a good use of AI. I do not think AI is ready to do that right now, which is, I think is the problem you're addressing. There are use cases where it can reduce burden, accelerate getting to yes faster. Those are good you places you can use AI but not to deny care. Do you

Speaker 4 [11:58:02 AM]
feel that if AI does cause a denial or refusal of care that there should be a person to person, a physician to physician evaluation.

Speaker 3 [11:58:10 AM]
Absolutely, a peer to peer is always appropriate, and that should be in all cases, maybe not even in denial if requested or if appropriate, a human clinician should always be the one making those decisions.

Speaker 4 [11:58:20 AM]
Thank you for your comments, Madam Chair, my time has expired and I yield back

Speaker 11 [11:58:26 AM]
Yeoman yields back and I recognize uh Representative Beragon from California for her five minutes of questions.

Speaker 16 [11:58:33 AM]
Uh, thank you, Madam Chair. Um, this is a a great conversation to be having, although to do it in a context of what's going on in this country is to turn a blind eye, you know, the Trump administration has caused chaos at the Centers for Disease Control, Under Secretary Kennedy's leadership, thousands of dedicated public health workers have been fired. Scientific experts like uh former CDC director, um, have been forced out and hundreds of millions of dollars in critical research funds have been canceled. This week, 8 former CDC directors who served under presidents from Jimmy Carter to Donald Trump, took the extraordinary step of sounding the alarm in an op ed. Now, this is it. The title says it all. It says we ran the CDC. Kennedy is endangering every American's health. Think about that for a moment, that the Secretary of HHS is endangering the health of every American. They write that the administration has done is quote, unlike anything we've ever seen at the agency and unlike anything our country had ever experienced, end quote. They warned that Americans are now less protected from cancer, heart disease, and infectious disease. They note the CDC is being directed to downplay vaccines and pursue unproven treatments. I wanna to ask for unanimous consent to enter uh the former CDC's director's op ed into the

Speaker 1 [12:00:02 PM]
record.

Speaker 11 [12:00:03 PM]
With that objection, so ordered.

Speaker 16 [12:00:04 PM]
I think we should be taking up legislation to protect workers at the CDC. My colleague Representative McClellan has a bill to prevent mass firings at HHS, um, and I recently introduced a bill that would protect our public health workforce Act to bring back the CDC staff that Trump has fired. Instead of oversight hearings or legislative action to hold this administrative administration accountable, Republicans continue to pretend that nothing has happened. And so, you can't go on without saying something um at this hearing. Doctor Ibraham, I want to turn your attention to AI and the topic at hand today. AI has shown real promise in healthcare, such as helping doctors catch devastating diseases. like cancer earlier. But as of last year, over 600 AI applications approved by the FDA out of over 600 applications approved by the FDA. Less than 10 were eligible for reimbursement from the centers for Medicare and Medicaid Services. That's less than 2%. Does that number concern you or is that a good thing?

Speaker 9 [12:01:13 PM]
Thank you so much for raising that, that point, and it has some historical context that the um role of the FDA and the way it's been statutorily designed has disproportionately focused on safety and effectiveness and deferred the decision of reimbursement to CMS, which unfortunately creates almost reinventing the wheel because a lot of the material they have to review and evaluate ends up being redundant. There have been some efforts to address that in parallel path reviews. Um, ultimately, I think what would be more efficient is if we focused the rigorous evaluation upfront by the FDA and if it got FDA approval, that it would then be reimbursed by CMS.

Speaker 2 [12:01:52 PM]
Well,

Speaker 16 [12:01:52 PM]
thank you. You know, first when you look at the number, you think like, oh geez, people are not getting access to these AI tools that could be, you know, life

Speaker 2 [12:02:00 PM]
saving.

Speaker 16 [12:02:01 PM]
But of course we've heard today about other concerns about trust and regulation and whether um it's helpful or whether you need to have a plan in place. Um, so, um, Doctor Mello what can Congress do to make sure AI healthcare tools are accessible to more people.

Speaker 10 [12:02:20 PM]
Yeah, so both of the things that you just said are true at once, right? That we are concerned that there's not enough access, and that there are real, uh, you know, policy barriers to getting there. Uh, again, where I land is, if I am a hospital, I'm doing, you know, radiological scans, what's gonna move me to spend more on AI if there's no reimbursement. Maybe it's a substantial improvement in quality of care, but that sometimes is not documented. Maybe my radiologists are clamoring it for it, but they know they're on the hook. if anything goes wrong. So this trust deficit really matters, and the steps that I've outlined, including both modifications of FDA review, modifications to reimbursement, but also institutional governance. That's the pathway forward.

Speaker 16 [12:03:03 PM]
Thank you, Dr. Mallow. The use of AI can reduce workloads and improve efficiency in our health care system, but it can also make mistakes. Earlier this year, uh, HH Secretary Kennedy released a report that was based on incorrect information and made up sources because of AI. How can we ensure that AI is used responsibly and with full accountability in the healthcare system, especially when it affects people's trust in science and their

Speaker 2 [12:03:28 PM]
health.

Speaker 10 [12:03:29 PM]
I think it only begins by saying there's a human in the loop that's supposed to be reading that stuff. You have to create the conditions to make it possible for him or her to do that job in the setting where they're working. And right now hospitals are not doing that.

Speaker 16 [12:03:42 PM]
Great. Thank you all with Teao

Speaker 2 [12:03:44 PM]
back.

Speaker 11 [12:03:45 PM]
gentlewoman, yields back and I now recognize my friend from Ohio, Representative Balderson for his 5 minute questions.

Speaker 4 [12:03:53 PM]
Thank you, Madam Chair, and thank you all for being here today. My first question, uh, today is to Mr. Toy, uh, in your testimony, you mentioned that AI platforms like Clover Assistant can very quickly bring together fragmented patient data and interrogate it into existing clinical workflows, even in practices that are still paper-based.

Speaker 2 [12:04:14 PM]
From your

Speaker 12 [12:04:14 PM]
experience, what steps do you believe Congress can do can take to support a wider adoption of AI enabled tools like yours, especially in rural areas where providers may lack access to modern EHR

Speaker 4 [12:04:26 PM]
systems.

Speaker 3 [12:04:27 PM]
Uh, thank you for the question there. I think the most important thing I noticed discussed at the congressional at that in Congress is making sure that there is uh connectivity to the internet within any practice within America. Like I know that's a focus already, but once we can connect physicians to the internet, we can then connect them to cloud-based AI and then we can also connect them to the vast amounts of data that we will bring online via interoperability. So I think those things all chained together and uh if we'll solve the connectivity problem, um, today by giving out devices to people, like a connected iPads will help them work with their local telcos to connect, but if that could be solved, we can pretty much get rid, uh, fix the

Speaker 2 [12:05:06 PM]
rest.

Speaker 4 [12:05:07 PM]
Thank you. I'll follow up Mr. Toy. In your testimony, you also provided a good example

Speaker 2 [12:05:12 PM]
as to

Speaker 12 [12:05:13 PM]
how a lack of coordinated care can lead to missed warning signs. Much of my district is rural Ohio, and so many of my constituents have complained about fragmented care. How can Congress help accelerate connectivity and data sharing, especially between independent specialists and primary care providers.

Speaker 2 [12:05:29 PM]
So that AI tools

Speaker 4 [12:05:30 PM]
can deliver the full picture of patient's health in real-time, regardless of where care is delivered.

Speaker 3 [12:05:37 PM]
Yes, thank you for that. I think that a huge part of what we can do here is that connect connectivity to the internet, and then within the healthcare ecosystem, making sure that the interoperability rules that are being passed right now, and future rules are all being uh accelerated and enforced. We want more EHRs talking to each other. We want to collect the lab system to that data stream. We want the pharmacies connect to that data stream, and all of that can come together. And once we have that, and I think we're very close to that. We want to make that to be physician media ted which it is right now, but I also encourage us to consider making it member, uh, the patient mediated as well. A lot of the networks right now are for physicians to request data, and we also should allow patients to request their own data off those same networks.

Speaker 4 [12:06:21 PM]
Great. Thank you very much. Uh, my next question, uh, is for Doctor Ibraham.

Speaker 12 [12:06:27 PM]
Um, thank you for being here today. Um, Doctor Ibrahim, um, Vis AI platform, Intergate, integrates AI

Speaker 4 [12:06:35 PM]
to speed up diagnosis and enhanced care coordination across specialties and physicians, given your background in both clinical practice and healthcare delivery. How do you see this benefiting both physicians and patients, especially in rural and critical access hospitals.

Speaker 9 [12:06:51 PM]
Thank you for that question. One of our, um, important studies around improvement in care for rural patients comes from TriHealth in the Cincinnati area, um, in Ohio. Um, one thing I've noticed in my own practice, we often have rural patients that may have a concerning sign on one of their imaging studies, and they get transferred 3 to 4 hours to a big academic center, we may not have the imaging, we end up re-scanning them, or if we have the imaging, we can look at it and say, actually reassure them and tell them it's OK. It's hard to estimate the number of patients who've been transferred only to give them reassurance and have them drive back home, um, at no small burden. So the ability for us to leverage this technology to share information readily get expertise, eyes on some of this imaging before asking a patient to take on the travel burden would be significant. Um, there are also many conditions where the care can stay local, but if the expertise can be disseminated by sharing information, it could also help maintain the volume of care that stays local in rural communities. Thank

Speaker 2 [12:07:54 PM]
you

Speaker 4 [12:07:54 PM]
Is there any concern for air in using these technologies for patient care?

Speaker 9 [12:08:00 PM]
I think we need to be incredibly humble that all of us here, including the people on the front line of doing this are always learning something new about it, and that as good as our models get, as we get more experience, they get better and we learn. Um, we try to put several safeguards in place to try to mitigate and anticipate that. You've heard multiple times today about having humans in the loop. We also have additional monitoring safeguards that also alert us that if there's some signal change in how many things we're detecting, we start to go back to the providers and say is there's something different about the patients you're screening. So there's something different about the information you're giving us, because the signal started to look different acutely. So we try to put multiple safeguards in place to prevent

Speaker 2 [12:08:40 PM]
that. OK.

Speaker 4 [12:08:41 PM]
Thank you all very much,

Speaker 12 [12:08:43 PM]
Mr. Parker. I apologize. I was gonna have you next, but I'm out of time,

Speaker 2 [12:08:45 PM]
so, Madam Chair, I yield back.

Speaker 11 [12:08:48 PM]
Hey, the gentleman, yields back and I recognize Dr. Schreier from Washington for her 5 minute questions.

Speaker 2 [12:08:56 PM]
Thank you, Madam

Speaker 15 [12:08:56 PM]
Chair.

Speaker 2 [12:08:57 PM]
Uh, as a

Speaker 16 [12:08:58 PM]
pediatrician, I

Speaker 10 [12:08:59 PM]
have

Speaker 15 [12:08:59 PM]
always relied on trusted experts at FDA and CDC to help me make the best decisions possible when I am taking care of my patients, and they are being purged. Uh, Madam Chair, that is why I'm joining all my Democratic colleagues in calling on

Speaker 1 [12:09:18 PM]
this

Speaker 15 [12:09:19 PM]
committee to hold an oversight hearing to investigate the firing of CDC Director Menarez and the subsequent de par ture of several CDC officials who were unwilling to abandon science and bend a knee to our conspiracy theory driven HHS secretary RFK Junior. We have in this committee oversight jurisdiction, and we cannot stand by while Secretary

Speaker 10 [12:09:43 PM]
Kennedy discards

Speaker 15 [12:09:45 PM]
decades of American medical advancement and jeopardizes all of our health for the sake of his own fringe

Speaker 1 [12:09:52 PM]
anti-vaccine agenda, and a very profitable anti-vaccine industry. Our children deserve better, we deserve better, and we have jurisdiction and a

Speaker 15 [12:10:03 PM]
responsibility for oversight. Speaking of children

Speaker 2 [12:10:08 PM]
I'd like to discuss

Speaker 15 [12:10:09 PM]
AI tools that are currently used on children, according to the American College of Radiy, over 200 FDA approved AI tools are used for medical imaging, but only 6 are actually marketed for pediatric use after review by the FDA. That is a staggering disparity and innovation between adult and pediatric care. And partly that's because it's much

Speaker 1 [12:10:33 PM]
easier to develop AI imaging software for adults. It's trickier to do it for kids

Speaker 15 [12:10:38 PM]
because they're not just little adults, as you said, um, bone, heart, thymus images look different in infants, children, teens and adults, and normal lab results are also different ranges when, uh, when you look at different ages. So we need just a lot more data to generate the volume of age-specific uh uh data that we'll need to generate this.

Speaker 1 [12:11:04 PM]
Uh, Doctor

Speaker 15 [12:11:04 PM]
Mello, I, you know that Packard children's where I trained is connected by a hallway to Stanford Medical Center, and that kids and adults go to the exact same emergency department. And I just believe that children in that ER should not get the short end of the stick. And, uh, we not only need more tools, uh, for pediatric use, but we also need the existing tools to be clearly labeled so that providers know if the software they're using is actually intended and safe for kids. Uh, Doctor Ibrahim. given the variability and complexities of pediatric care, um, but also acknowledging that we need this cutting edge technology that makes doctors better and the doctors make AI better. Um, what can be done to incentivize and increase the development of AI tools for pediatric

Speaker 2 [12:11:58 PM]
patients.

Speaker 9 [12:12:00 PM]
Thank you so much, uh, Doctor and Congresswoman, for your question and um highlighting the differences between pediatric and adult patients are current product has been only on adult patients recognizing that it is an entirely different specialty to be able to apply those tools, underscoring much of it is the sharing of data. Um, I'm encouraged that the field of AI development has progressed in this space where we're able to share, not the actual individual data, but the weighting of our algorithms from our data across institutions. in a way that we can benefit from sharing the data without actually exchanging the individual patient's data. Pediatrics, that's particularly important because just the sample size is much smaller. So incentives, um and even national efforts that would help institutions aggregate this information that they could share it in a way that maintains privacy without the individual records being dispersed, but being able to share the weights of the algorithms would be incredibly helpful for adults, in fact, as well.

Speaker 15 [12:12:58 PM]
And, and do you have ways of not only incorporating the, the pediatric radiologists at Children's Hospital but also specifically pediatric radiologists that outside hospitals so that everybody is involved.

Speaker 2 [12:13:11 PM]
It's

Speaker 9 [12:13:11 PM]
a great, that's a great point. I think one of the hidden um benefits of AI is that the IT infrastructures had to improve significantly to enable the technology to do what it does. One of the things that's just been the exchange of radiologic images. So we've had a number of hospitals say, thanks for being able to just share the images. We're not sure if we want to use your AI tool, but you at least got us to that part.

Speaker 15 [12:13:33 PM]
So thank you. I'm gonna to just quickly, I, I, I don't have time to ask you the question, Dr. Mallow, but I just want to bring up the issue of physician liability, that when you have AI giving one answer and a physician giving another answer and something goes wrong. Uh, I think we need to think hard about, uh, where the liability is. Is it on the AI company or is it on the physician and uh the toll that that takes some physicians also to be a checkpoint and also to just be a reviewer of uh loads of data. Thank you uh, all for your testimony. You'll

Speaker 2 [12:14:06 PM]
back.

Speaker 11 [12:14:07 PM]
Thank you. As a gentlewoman, you Sack, and I now recognize,

Speaker 2 [12:14:11 PM]
uh,

Speaker 11 [12:14:12 PM]
my dear friend from Iowa, Dr. Miller

Speaker 2 [12:14:14 PM]
Meeks.

Speaker 15 [12:14:15 PM]
Uh thank you, Madam Chairman, and I want to thank the witnesses for testifying before the subcommittee today. Um, 3 years ago, uh, we were, uh, asked as uh as,

Speaker 17 [12:14:25 PM]
as a, as a conference uh to be on certain task force. And so there was a healthy future task force, and I chaired the subcommittee on modernization, and with the chair of the current subcommittee on Health, and we focused on AI, uh, uh, dad data interoperability devices, technology, and how it can help with both access to care, affordability, prevention, and better outcomes. So I'm delighted uh for this hearing today and for your testimonies. And earlier this summer, I hosted a bipartisan briefing to Spotlight how artificial intelligence is transforming clinical practice and patient care. Um, and thank you, Doctor Thoi for assisting the provider, augmenting the provider rather than replacing providers or physicians. During the briefing, we heard from Doctor Michael Abramoff from the University of Iowa about how his company, Digital Diagnostics is using AI to tackle uh diabetic retinopathy. In fact, it's the, I think the first autonomous AI device to be approved by the FDA, uh, Doctor Abraham and his diagnostic device is now used in numerous healthcare systems around the country, and it underscores that AI powered diagnostic platforms can be deployed safely while improving patient outcomes and healthcare productivity So, um, Doctor Troy, your testimony mentions the importance of interoperability and standardized data access for effective AI performance. How can Congress help accelebrate accelerate interoperability across federal and private healthcare systems in a way that encourages innovation but avoids imposing rigid one size fits all, uh, technical mandates.

Speaker 3 [12:16:10 PM]
Yes, thank you for the question there. Um, I think the key on interoperability is AI runs on data, and the better uh more uh relevant, the volume of data, and also like the more personalized that data is, uh, the better the AI is going to be able to run. So it's critical, critical that we have built infrastructure around healthcare interoperability. The current rules that we have on the books right now, I think that uh it would be wonderful if we could focus on modernizing those particular areas. I would point everyone to, for example, HIPAA, HIPAA does, uh, you know, good work, the intention of it is very good, but it was originally developed in a almost pre-internet world, let alone pre-AI world. And so the intentions of portability and the intentions of accountability and HIPA must remain, but we must update some of those regulations, I think. Otherwise they will start to hinder uh interoperability.

Speaker 17 [12:17:05 PM]
Oh, I think that AI has tremendous potential uh in healthcare as I have previously mentioned. I'm gonna discuss some of the dangers of AI. We know that older individuals have less trust, but that younger individuals who have grown up in a world connected remotely or by the internet, have greater trust in these systems. Um, and we know that they're looking towards at the same time, uh, the internet, uh, and social media platforms to address loneliness and isolation and connectivity exacerbated by the pandemic, but they also, it's a source of bullying and threats to them. I'd like to enter into the record uh article August 26th by the New York Times, a teen with suicidal chat GPT was the friend he confided in. Um, the tragic story of Adam Raine as reported by The New York Times has ignited a difficult but urgent conversation about the role of AI in mental health support. I'm not gonna list everything cause my time is running out, but his parents are now suing OpenAI alleging that the chatbot became his closest confidant and ultimately and contributor to his death. And Dr. Ry in, your testimony and we have very little time. Direct to consumer chatbots are making deceptive and dangerous claims, with one presenting itself as such psych psychologist that validated a user's violent thoughts. And where should the boundary lie if you could be uh brief in your comments.

Speaker 1 [12:18:29 PM]
Well, again, I think that the boundary really lies in ensuring that these types of chatbots, A, don't misrepresent themselves, that they're not allowed to call themselves a licensed anything. We wouldn't want them to call themselves a licensed lawyer. I mean, we just, we would not want that, um, because it gives a sense of credibility that doesn't exist. I think that we also have to um build better chatbots. I mean, I think everybody deserves therapy. Everyone deserves human one on one therapy. That might not be what everybody needs. So we need to think about how can we actually leverage emerging technologies, personalize them in a way that actually reaches people where they're at. We have a system that waits till people get in crisis. What

Speaker 17 [12:19:11 PM]
if we them first? I'm running out of time, but you mentioned the human connectivity and everybody uh that interaction and parental oversight. And I just want to emphasize that groups, programs, schools that are pushing to exclude parents, prohibit informing parents of children's activities when at school. It actually undermines the very human connectivity and support from those groups and those parents and those families that our youth desperately need. Thank you, and I yell

Speaker 2 [12:19:40 PM]
back.

Speaker 11 [12:19:43 PM]
Gentlewoman yields back and I recognize Representative Trehand from Massachusetts for her 5 minutes of questions.

Speaker 1 [12:19:50 PM]
I want to thank the chair and certainly the witnesses here today. Uh, in normal times, a hearing on artificial intelligence can be

Speaker 2 [12:19:58 PM]
um uh

Speaker 1 [12:20:00 PM]
used to advance healthcare access would be a welcome and an important conversation. And in those times, I'd be asking how we can harness AI for powerful uses like improving medical imaging to detect disease s earlier and more accurately,

Speaker 2 [12:20:15 PM]
but

Speaker 1 [12:20:17 PM]
these aren't normal times. Uh, just weeks ago this Congress passed the largest healthcare cut in our country's history and our federal public health agencies are in chaos with mass resignations, dismantled programs, and an exodus of scientists that leave us less prepared for outbreaks, less secure as a country, and an erosion of public trust in government and medical guidance. And it's all of this unfolds, you know, the Secretary of Health and Human Services is busy posting videos of himself drinking raw milk and competing in push-up contests. Against this backdrop, my questions today will be about AI in the clinical setting, but just pointing out, some patients won't even make it there because they're going to lose their coverage. If we want technology to improve health, we must start by ensuring that people are covered. And history shows technology can either wrongfully take that coverage away or help keep people eligible, uh, and enrolled. By February 1st, 20 24 more than 16 million Americans had lost Medicaid coverage as as state's sunset, the continuous enrollment protections that were in place during COVID-19. Nearly 70% of these losses were procedural, not due to changes in eligibility, but to missed paperwork or state software glitches. These cases are a stark reminder that technology can either amplify or improve systemic uh problems, and it's up to policy m ak ers to direct responsible uses of technology design, appropriate safeguards and conduct oversight when necessary. Now, with states required to implement burdensome Medicaid paperwork requirements thanks to the Republican big ugly Bill. It is critical that technology is used to protect access to care for as many folks as possible. We know that these new requirements

Speaker 10 [12:22:11 PM]
have led to the removal of tens

Speaker 1 [12:22:13 PM]
of thousands of Americans who are eligible for coverage in the past, and that's when these requirements were implemented for only a short time and for a small number of people, but Republicans just took that model of burdening people with unnecessary paperwork to keep their health coverage, and they expanded it nationwide. States must use every tool to keep eligible people covered and ensure that automation safeguards coverage rather than triggers wrongful terminations. In Tennessee and other states, automated eligibility systems have wrongfully cut Medicaid for thousands who were still eligible. 10Care Connect, that, which cost over $400 million was meant to use income and health data to determine eligibility, but instead, often misloaded data assigned people to run households and made incorrect determinations according to a federal court ruling. Doctor Mellow, as we consider AI's role in health programs. What safeguards should be in place so that technology doesn't duplicate the procedural disenrollments we saw during the Medicaid unwinding.

Speaker 10 [12:23:22 PM]
Thank you for the question. The kind of situation that you described is, frankly, inexcusable, that there would be failure on that larger scale really raises fundamental questions about the amount of testing that was done before that system was rolled out, and who was watching? So job one I think is if we're going to use automation to enforce these disenrollments that there are humans monitoring, not particularly individual disenrollments alone, but also what is happening at the population scale, but as you say, AI could be used to improve some of these problems, and so I, my hope is that there will be innovation in the private sector that develops apps that enable enrollees to be put on alert before they are disenrolled. I think AI has a lot of promise for making sure people don't miss filing deadlines and are aware when the paperwork that they've submitted is not going to be sufficient.

Speaker 1 [12:24:12 PM]
I appreciate that. Um, and building on that, we've also seen that even when technology is working as intended, it's often placed on an, on top of an overly complex reporting system, it can still cause harm. Um, automation is often sold as a silver bullet for eligibility determinations, but in practice, when it is layered on top of complicated reporting rules. It can speed up coverage losses for people who still qualify. So I appreciate the alerts. I'm wondering if we could, how if you could expound on how we design systems so that they clear barriers out of the way instead of building new ones for those who need care the most.

Speaker 10 [12:24:50 PM]
I think where the incentives, there are collaborative design is the key there. If you involve advocates who understand what the major pitfalls and errors are that keep people wrongly off of Medicaid rolls, people who are eligible under the rules that we've set up, that goes a long way to building AI that's designed to avoid replicating those

Speaker 2 [12:25:07 PM]
problems.

Speaker 1 [12:25:08 PM]
I appreciate your answers. Thank you, Ayoba,

Speaker 11 [12:25:11 PM]
OK, gentlewoman yields back in I recognize uh representative Bentz from Oregon for his five-minute questions.

Speaker 14 [12:25:19 PM]
Thank you, Madam Chair. Uh, thank you all for being here. This is extraordinarily interesting to me as a lawyer for a hospital for many years. Uh, I obviously became extremely familiar with the standard of care for doctors. So Dr. Mello,

Speaker 2 [12:25:30 PM]
where would

Speaker 4 [12:25:30 PM]
you put

Speaker 14 [12:25:31 PM]
AI? Were you on the witness stand and we were asking

Speaker 2 [12:25:34 PM]
you, um, if if the

Speaker 14 [12:25:37 PM]
doctor involved in the malpractice case, should have, could have did used AI and go both directions on it. They did use it and turned out wrong or they didn't use it and it turned out wrong. Tell me what, tell me where you think it

Speaker 2 [12:25:50 PM]
fits.

Speaker 10 [12:25:51 PM]
Thank you. It's an important question and although I'm not a medical doctor, I'm a scholar of medical malpractice law, and we know that a malpractice law, reasonableness of action is always the lodestar, even more so than custom, what your colleagues

Speaker 14 [12:26:02 PM]
would, I thought it was who the lawyers were, there was generally the digit never mind, go ahead.

Speaker 10 [12:26:08 PM]
So the question is, when is it reasonable for a physician to depart? And the problem with being able to answer that question in the courtroom is that physicians are provided with so little information by the tool that enables them to understand whether it's recommendation, which makes sense at a group level, applies well to this particular patient. So that's why I think there needs to be shared liability between physicians, hospitals, and developers because sometimes the errors that doctors make as a result of output could not reasonably have been foreseen by them and therefore are not unreasonable for the physician.

Speaker 14 [12:26:40 PM]
Let's let's let's take it, let's take it back to a point that was made earlier in the testimony of you folks have given today.

Speaker 2 [12:26:47 PM]
And

Speaker 14 [12:26:47 PM]
that was the lack of accountability or the promise by those who are providing AI that is going to work or that it meets certain standards. Don't you think that, that the law of of of the the you you and I are now discussing these standards. Don't you think that it creates some sort of accountability for those who are creating these AI systems.

Speaker 10 [12:27:07 PM]
Well, the difficulty will be, as you'll understand, as a hospital attorney, that when you contract away that responsibility at the licensing stage, it eliminates a lot of avenues for recovery, and many of these licensing agreements that hospitals are now executing with developers have disclaimers up and down that hospitals have to accept in many cases

Speaker 14 [12:27:26 PM]
to are you suggesting that we do something about that here at the congressional level that we say that's not something that they should be able to do.

Speaker 10 [12:27:33 PM]
I, I don't understand why AI is treated differently from other products where we don't allow makers to disclaim ordinary warranties? Why should that be? And if the answer is there isn't a good reason for treating it differently than we ought to treat it the

Speaker 2 [12:27:46 PM]
same.

Speaker 14 [12:27:47 PM]
Thank you. I, I want to shift to, to Mr. Toy and uh you and Ka or someone, forgive me, because it's been a long time since I've been waiting to ask my questions. I may have confused who it was that said what. But uh what at what point do you think that the human becomes less analytically able than AI. Do you see that in the next 2 years, 10 years, when?

Speaker 3 [12:28:07 PM]
I think that it depends on what kind of reasoning and what kind of information like I think humans are already, um, the AI is probably already better at searching a large corpus of data and finding something like relevant to show to a human being, so searching through data, I think AI is very, very good at that. I think you're asking about reasoning in particular. I, I, I do not think that most human thinking will be replaced by AI anytime soon. I think that what will be replaced will be more uh perfunctory kind of tasks, and that's where we should be focused right

Speaker 14 [12:28:38 PM]
now. Thank you, Doctor Wright, uh, you, you said a phrase I thought was very interesting, personal connections make us who we are. I have all these younger adults coming into my office and I asked them how many hours they're spending on their cell phones, and it runs, frankly, the average is about 12 hours a day. It's frightening. I would just ask you if you think algorithms have now replaced the human connection. And, and if so, why isn't this

Speaker 2 [12:29:03 PM]
kind

Speaker 14 [12:29:03 PM]
of uh about a wish that we go back to some previous time, uh, which I see unlikely. So where do you think this, uh, this human connection, this personal connection is going to come from now that we haven't we given it away?

Speaker 1 [12:29:17 PM]
really interesting question. Um, I would argue no, that we have not given it away. Um, I think that's, um, what makes relationships unique are the reciprocity. of it There is no reciprocity when it comes to

Speaker 2 [12:29:33 PM]
AI.

Speaker 1 [12:29:34 PM]
That's partly why people like it, cause they don't have to care about the AI and give back. But that's not a genuine relationship. And it does not build true intimacy. AI knows things, but it doesn't understand. It doesn't understand you or why.

Speaker 14 [12:29:52 PM]
I agree with that. What are we going to do about it?

Speaker 1 [12:29:57 PM]
I think we need to be much more intentional about AI literacy and technology literacy within schools. I think we need to train parents. I think that we need to incorporate AI literacy and the impact it can have developmentally within healthcare. I think we need to have a public uh campaigns, helping people understand how to use these tools appropriately and when to walk away.

Speaker 14 [12:30:24 PM]
And, and I very much appreciate your testimony and, and the entire panel's very interesting. yield

Speaker 2 [12:30:29 PM]
back.

Speaker 11 [12:30:30 PM]
gentleman's back, and I recognize Representative Ey from Texas for his 5 minutes of questions.

Speaker 7 [12:30:36 PM]
Thank you, Madam Chair. Um, and, uh, before I get into the AI I wanna, uh, begin by saying that I'm deeply disappointed and, and frankly fearful about the reckless direction that HHS is taking

Speaker 3 [12:30:49 PM]
uh under Secretary RFK Junior's failed leadership and the decision to include pulling the rug from under uh cancer vaccine research and putting America's lives directly at risk, in particular, and illnesses like cancer, quite frankly don't care about what political party you may happen

Speaker 7 [12:31:06 PM]
to belong to. It's something that has touched literally every everyone in this committee and probably in this body.

Speaker 4 [12:31:13 PM]
Uh, and yet the secretary is

Speaker 12 [12:31:14 PM]
abandoning the millions of Americans will face a who will face cancer in the years to come, and we're entering a very dark chapter in American history, and I hope that this committee will devote some serious time to demanding some answers. Uh, but today, uh,

Speaker 7 [12:31:29 PM]
hearing is also a matter of life and death, and we've seen some very

Speaker 3 [12:31:33 PM]
disturbing reports, and when people talk about what they see as an existential threat,

Speaker 2 [12:31:38 PM]
uh,

Speaker 4 [12:31:38 PM]
and

Speaker 7 [12:31:39 PM]
talk about things that scare them, AI scares

Speaker 9 [12:31:41 PM]
me more than any, anything else, quite frankly. Uh, we've seen

Speaker 3 [12:31:45 PM]
disturbing reports about AI chatbots leading to real harm,

Speaker 2 [12:31:48 PM]
uh,

Speaker 4 [12:31:48 PM]
and some stories are so shocking they can honestly be hard to believe.

Speaker 3 [12:31:53 PM]
Uh, I'd like to enter into the record for, uh, a Washington Post article titled Instagram's

Speaker 6 [12:31:59 PM]
chatbot, I

Speaker 2 [12:32:00 PM]
helped teen

Speaker 9 [12:32:02 PM]
accounts planned suicides, and parents can't disable

Speaker 3 [12:32:05 PM]
it Um, this article discusses uh Instagram's uh chatbot uh meta AI that actually walked teens through how to kill themselves.

Speaker 12 [12:32:17 PM]
And kids are turning to AI when they feel they have no one else to talk to, and they're being told that these bots are companions, and instead of guiding them towards parents, uh, teachers

Speaker 3 [12:32:27 PM]
or doctors who could

Speaker 7 [12:32:28 PM]
help them, the chatbot is actually helping them go through with the suicide.

Speaker 2 [12:32:33 PM]
Uh, and we

Speaker 12 [12:32:33 PM]
have to stop this. This is not rare, uh, and it's not just children, uh, it's a vulnerable adults who are at risk, and chatbots have been rein have reinforced paranoid delusions, validated dangerous thoughts, and in some cases contributed to self-harm or even violence. uh, and we know that these, uh, tools, uh, that there are millions of Americans already using them, uh, on the other hand, as Doctor Wright described in her opening testimony, there are AI programs deceptively marketed as mental health providers and some even masquerade as licensed psychologists, and they're racking up millions of conversations with people, uh, while handing out reckless, harmful advice to people in crisis. Uh again this is deceptive and it's a danger, and it is a threat to public safety. And yet every single Republican on this committee voted just a few months ago to prevent states from regulating these danger bots, including the companion bots that kids can access, uh, and programs uh marketed to adults suffering from mental illness and so we have to do something, uh, we should not be discouraging states from saving kids' lives. And Dr. Wright, in your testimony, uh, you spoke about the danger of unregulated products given harmful advice to people searching for help, and in some cases, treatment, uh

Speaker 3 [12:33:50 PM]
for their mental health

Speaker 12 [12:33:52 PM]
Why are children and adults in crisis, particularly those that are susceptible to our harmful uh outputs of uh why are children adults in crisis, particularly susceptible to the harmful outputs of AI chatbots.

Speaker 1 [12:34:09 PM]
I thank you for the question. Um, I, I think they're particularly vulnerable for a couple of reasons. One, adolescence and children, um, are already very different developmental stage. They're not, um, have the life experiences to be able to listen to their gut and know when something seems off. Um, and individuals in a vulnerable position, um, who are in uncertainty, want to seek out answers, and these chatbots are coded in a way to give them the answer that they want. They are unconditionally validating and reinforcing even harmful or unhealthy behaviors. Um, and they tell you exactly what you want to hear. Over and over and over again. And so when people engage in these prolonged chats, so not a one-off chat, but hours and hours and hours. We know that the algorithms A lose accuracy and become less safe. So what we need to do is somehow disincentivize these companies from a user engagement business model where they are incentivized to continue to program in an addictive way. They don't have to do that. There are ways to not code these things addictively so that they could be more helpful, but unless there's some regulation that's encouraging them to do that. I don't see them doing it on their

Speaker 7 [12:35:27 PM]
own. Well, thank you very much. Thank you, Madam Char. You're back.

Speaker 11 [12:35:32 PM]
We'll add your document to the record without objection. Thank

Speaker 2 [12:35:36 PM]
you.

Speaker 11 [12:35:38 PM]
OK, I now recognize, uh, Mr. Langworthy from New York for his 5 minutes of questions.

Speaker 4 [12:35:43 PM]
Thank you, Madam Chair. AI is no longer a theory about the future. It's already transforming the way we

Speaker 14 [12:35:50 PM]
deliver care and how

Speaker 8 [12:35:51 PM]
we diagnose disease and how we use data to improve outcomes. Uh, in my district in western New York in, in the rural Southern tier,

Speaker 10 [12:35:59 PM]
families are counting on

Speaker 2 [12:36:01 PM]
a healthcare system that's more efficient, more

Speaker 8 [12:36:03 PM]
affordable, and more responsive. Uh, AI-driven tech innovation and technology can help us meet those expectations by reducing administrative burdens, uh, strengthening clinical decision making and unlocking discoveries that once took years in a matter of months. Uh, and with

Speaker 2 [12:36:21 PM]
that, um, Mr. Toy, as you know, Medicare

Speaker 8 [12:36:26 PM]
Advantage has been at the forefront of developing AI tools to streamline beneficiary enrollment, manage costs of care and reduce administrative burdens. It is Medicare Advantage continues to grow both in New York and nationwide. More than half of New York's Medicare beneficiaries, about 2 million people have chosen Medicare Advantage over fee for service Medicare. And for them, Medicare Advantage is Medicare. Uh, Mr. Toy, can you

Speaker 18 [12:36:55 PM]
speak to how these innovations in AR are being used in Medicare Advantage and even Medicare more broadly by reducing administrative paperwork for providers in improving outcomes for

Speaker 2 [12:37:07 PM]
patients.

Speaker 3 [12:37:08 PM]
Absolutely. Thank you for the question. I think the advantage of the uh no pun intended, the advantage of the better care advantage model is that we can bring a lot of uh uh better outcomes, we can provide better data to doctors. We can actually provide better reimbursement to doctors as well. So a lot of the things we're discussing here at the at the committee are things that we can uh actually put into production right away, and we have put into production right away. So people in Medicare Advantage can go to a doctor. They can have a doctor use an AI tool safely, be trained on that AI tool. Know that that AI tool is helping them with not uh sort of like, uh, with the diseases that they actually have in their own personal life on the main diseases of aging, such as uh pulmonary disease such as kidney disease, such as diabetes, and know that their doctor is being reimbursed by that that MA plan for the time that they're using to use that AI tool because that's something we can do. We must reimburse on the CMS schedule. We can also reimburse about this uh the the CMS schedule. And so we're already reimbursing primary care physicians above the regular Medicare rate for the extra time that they're taking to use an AI tool. So there are doctors are using it, getting better outcomes, and being reimbursed better.

Speaker 2 [12:38:26 PM]
Mr.

Speaker 18 [12:38:26 PM]
Torre, how does Clover's use of AI inform your thinking on network design and delivering the best product that you can to seniors choosing to enroll in Medicare Advantage plan.

Speaker 3 [12:38:38 PM]
Uh, thank you for that as well. So, as I said before, um, when we improve outcomes, and when we're improving, uh, accelerating diabetes identification and accelerating diabetes management. When we are keeping kidney function at a higher level because management begins earlier. All of that results in a better medical loss ratio, which means that we are actually more efficient per unit dollar when we allocate dollars out to the the medical network. What that also means is we can re in ve s t those, uh, that efficiency back into lowering out of pocket costs for patients. So our intense focus is to reduce those financial barriers to care, making care more accessible, more available, and that's powered by AI improving the care that's being delivered to the membership as well.

Speaker 18 [12:39:27 PM]
Thank you. Uh, there's also been a lot of critiques over the past year or so about Medicare Advantage plans leveraging AI to make prior authorization determinations. Uh, does Clover leverage AI in their utilization management process, and if so, is there a clinician or a human that is a Cze in that

Speaker 2 [12:39:47 PM]
process.

Speaker 3 [12:39:48 PM]
So all of our prior authorization is being done by a clinician who was working with providers in our network in order to make those determinations. We are not using AI uh to to make any kind of utilization management or prior authorization, uh, determinations. I do think there's an opportunity to do that, but to accelerate getting to yes faster, to to lower friction for our provider network to make it easier, as you were mentioning, to, to reduce the amount of time they're spending, preparing documentation to apply for prior authorization. I think AI is going to have great use cases there, and that's where we should be heading.

Speaker 18 [12:40:23 PM]
Well, thank you. AI is not a replacement for doctors, nurses, or caregivers, but a tool to help them deliver better care for more people. Uh, if, if we embrace it responsibly, uh, and, and have the right framework in place. We can strengthen our healthcare system and ensure those across the country see the full benefits of this innovation in this great country, and with that you'll back me,

Speaker 2 [12:40:43 PM]
I'm sure.

Speaker 11 [12:40:45 PM]
Gentlemen, yields back and I recognize Representative Fletcher from Texas for her five minutes of questions.

Speaker 16 [12:40:50 PM]
Well, thank you, uh, thank you, Madam Chair, and thank you to all the witnesses for testifying today. Um, I do think that the opportunities as well as the concerns about AI are important for our committee and the subcommittee to consider and for the Congress to act on, and I appreciate your testimony today, um, but like my colleagues, I am deeply concerned about the context in which we're having this hearing, um, and this con this conversation we really do have to have in the context of 2025. Both the rapid advancements in AI and the massive reductions in access to healthcare that the Trump administration has set in motion with a rubber stamp from this Congress. Since January, the administration has dismantled our government agencies and public health infrastructure and this Congress hasn't just ignored it, although it has. It has enabled

Speaker 2 [12:41:44 PM]
it

Speaker 16 [12:41:46 PM]
This committee is

Speaker 1 [12:41:47 PM]
included in that problem.

Speaker 16 [12:41:49 PM]
From the mass layoffs to the firing of the vaccine advisory board to the Twitter firing, non-firing of the CDC director and the mass resignations of the CDC just last week, uh, to the gutting of the substance abuse and mental Health Agency. Um, this administration has weakened our public health agencies and at the same time it has demanded that Congress reduce access to care and efforts to make care affordable for all American

Speaker 1 [12:42:16 PM]
s And this committee has done

Speaker 16 [12:42:19 PM]
so. We've sat through those markups and those votes. This committee has done no oversight on the issues I just identified, um, and has held hearings and markups reauthorizing programs that the administration is gutting. And so while there is an important opportunity here and I really appreciate your testimony and your being here to help inform us, um, in this work. It's really important to know that it's happening in this environment, and that this committee and this Congress need to get serious about the things that you all are sharing with us. And with that said, uh, with kind of the time that I have, um, Doctor Mello, I do wanna follow up on your exchange with Ranking Member Paone about prior authorization, um, and on some of the issues we just heard about, um, as well with Mr. Toy in the last questions, um, yeah, I represent a lot of physicians in Houston, Texas, and they and their patients tell me that prior authorization slows down access to appropriate care by forcing physicians to spend time, as we've heard about, um, and also just leading to wasted time, worse health outcomes. It's documented and for years there's been bipartisan agreement, I think in Congress that uh the Medicare Advantage prior authorization practices need to be reformed. We also heard about that from Doctor Joyce, um, and particularly when it comes to the use of AI to deny

Speaker 2 [12:43:38 PM]
claims.

Speaker 16 [12:43:40 PM]
And despite the consensus, as you all know, the Trump administration announced the CMS pilot program, the wasteful and inappropriate Service reduction wiser model, um, that implements prior authorization for a list of services for people enrolled in traditional Medicare in 6 states, including my home state of Texas, as well as Arizona, New Jersey, Ohio, Oklahoma, and Washington. And um the way CMS plans on carrying out this pilot is to contract with companies that will use AI to determine whether a procedure will be

Speaker 1 [12:44:08 PM]
covered.

Speaker 16 [12:44:09 PM]
CMS has said that the ultimate decision making authority will be a clinician, but it has also included financial incentives for these AI companies to reduce spending, and one way they can reduce spending is by denying care. And so they're gonna receive a percentage of the savings from denying care to patients. And so instead of improving these prior authorization policies in Medicare Advantage that have been under scrutiny for years for denying critical medical care. The administration is really doubling down, um, as far as I can tell, and creating the same problems, um, for the traditional Medicare program. And so Doctor Mello, in your view, is current federal law sufficient to regulate the use of AI in prior authorization?

Speaker 10 [12:44:57 PM]
No, it is not.

Speaker 2 [12:44:59 PM]
Do

Speaker 16 [12:44:59 PM]
you wanna, um, expand on that a little bit on how and what specific things that we could do on this committee and in Congress with federal legislation to address um and ensure that AI used in coverage determinations doesn't deny or delay medically necessary care.

Speaker 10 [12:45:16 PM]
Well, I want to acknowledge that CMS did some very good work on the regs and the final rule for use of PA in Medicare Advantage plans. Much better. Uh, there are two gaps. One is that it specifies that there needs to be human review before a denial is issued. No, no one argues about that. Everybody does that, but the question of what does that mean? There are no standards for what that means. And in my opinion, when you present a human with a packaged up, predetermined denial, nicely curated with all the reasons that human approaches the decision in a very different way than they would with a fresh pair of eyes and a non-curated file. So it should mean that human isn't primed by a computer to, to validate the AI decision. And the second gap is commercial plans. So aside, people who are in uh employer sponsored plans, commercial insurance plans who are non-M Medicare, don't have any of these protections that Medicare Advantage

Speaker 2 [12:46:07 PM]
plans

Speaker 10 [12:46:08 PM]
do. And those plans have no little or no reporting obligations, particularly for ERISA plans. So finding ways to penetrate the commercial market and understand what they are doing, where AI is being used, uh, to get to yes faster, and where it's problematic, that requires additional action.

Speaker 16 [12:46:25 PM]
Well, thank you so much. I've gone over my time. I have one more question for you. I'll submit for the record, and with that, I

Speaker 2 [12:46:29 PM]
will yield back.

Speaker 11 [12:46:31 PM]
Thank you, gentlewoman Y's back and I recognize my good friend and another pharmacists in Congress, uh, Representative Carter

Speaker 2 [12:46:39 PM]
from

Speaker 11 [12:46:39 PM]
Georgia for his 5 minutes of questions.

Speaker 2 [12:46:42 PM]
Well, thank you and thank all of you for being

Speaker 12 [12:46:44 PM]
here. Very interesting discussion in case you're wondering why I'm at the top of the dais and at the bottom of the questions, I was 40 seconds late. So that explains that. But nevertheless, that's the rules we have to abide

Speaker 2 [12:46:54 PM]
by them. Mr.

Speaker 12 [12:46:56 PM]
Parker, thank you for being here. Haven't heard a lot from you, but I, I've got a lot of questions for you as a fellow pharmacist and certainly want to know how AI can help us, particularly when it comes to, to patient compliance and particularly when it comes to helping patients and, and making it easier for them, the process,

Speaker 2 [12:47:18 PM]
um, can you

Speaker 5 [12:47:19 PM]
tell me how AI helpplat healthcare platforms can empower pharmacy, America

Speaker 12 [12:47:25 PM]
' s vast pharmacy providers, particularly our independent pharmacies to serve

Speaker 2 [12:47:30 PM]
patients.

Speaker 8 [12:47:31 PM]
Sure. I mean, I think maybe helpful to talk through the patient journey at General Medicine in that context where, you know, prior to a visit with a patient, we are able to collect their full historical medical record. Uh, you use AI to analyze that and figure out where they might have care gaps and recommendations a clinician can provide. But there's no reason that information couldn't also be presented to a pharmacist to help them identify similar levels of care gaps, vaccinations, other opportunities to help the patient improve their health I mean, I think, you know, with general medicine, the ambition is that we're able to empower providers, not just our providers, but providers in the community to provide that level of care, and I think it's a combination of robust access to medical records based on all the work that's been done here, coupled with the intelligence of AI.

Speaker 19 [12:48:19 PM]
So obviously we'd have to have the patient's permission to use those medical records and that, that would, that would go without saying, but can you see it, um, you know, one of the things that I've seen over my years of practice in pharmacy is how insurance companies and, and third-party payers have, have really taken part. I, I can remember, and I'm telling my age here, but I, I can remember when, you know, everything was cash and and you you you you just got the lowest price you could get if you were a consumer. But now it's, it, it's so much of it depends on your insurance and what's covered and what's not covered. So I can see it helping in the sense that before you even go, you would, um, before you even visit the pharmacy, you ought to know whether that this is covered or not by your insurance company.

Speaker 8 [12:49:07 PM]
That's exactly how we think about it. So in reality, you should be able to see all of that information before you ever get to the pharmacy counter. Both the insurance price, the lowest cash price, whether it requires a prior authorization so as a consumer, you're not sitting there trying to wrestle through this at the pharmacy counter. I think one interesting anecdote from my previous experience building out the pharmacy business at Amazon, is that by just showing them a clear insurance and cash price upfront, half the time the consumer was choosing to use cash because it ended up being cheaper than their benefit. And I think you see a very similar dynamic across the medical benefit. I don't know the, the ratios specific to each category yet. Um, but it really is empowering to the consumer to have that information upfront and to be able to make an in form ed decision.

Speaker 19 [12:49:49 PM]
In that, that's going to improve patient compliance. You know, I, I can think of so many situations. One of my pharmacies, I had 3 pharmacies, but one of them was kind of in a rural area where people had to travel a long distance and whenever they bring me a prescription and they want to get it filled and I have to tell them I'm sorry, I gotta call you doctor cause I got to get a prior approval. A lot of times they'd never come back, never come back and get the medication. And so patient compliance, I would think with increased tremendously with this as well.

Speaker 8 [12:50:19 PM]
Yep, I totally agree. I mean, I think you, there's oftentimes in the, in the Amazon experience where something was $14 and required a prior authorization, like the amount of wasted energy that was going into that far, far exceeded the $14 cost so they could just pay out of pocket. Um, and so I think just pulling this forward into the customer experience as a tremendous impact.

Speaker 19 [12:50:37 PM]
Absolutely. Well, I'm glad to hear this because this is, this is something obviously that I've experienced over my career, my professional career, and, and, and ways to improve it and make it um more st re am line d if you will. I think we'll, we're really help, will really result in better health care for Americans. Um, real quickly, Doctor Ibrahim, I wanted to ask you, how can AI accelerate innovation in drug development.

Speaker 9 [12:51:04 PM]
Thank you so much. I think, um, one of the themes that you have heard today is

Speaker 2 [12:51:08 PM]
um

Speaker 9 [12:51:10 PM]
AI helps in a lot of the informational challenges, so much of the drug development historically has been empiric like we've almost been lucky. We just try hundreds or thousands of things to get the one that's right. AI does a good job in pattern recognition and to be able to predict of the 1000 things that we were going to try, these ones may be more likely. So there's enormous potential in the early discovery phase to make it more efficient.

Speaker 19 [12:51:33 PM]
Good. Well, I, I certainly hope and I'm looking forward to this particularly with um with AI because I've, you know, in my years of practicing pharmacy, I've seen nothing short of miracles as a result of research and development and drug development, and I hope that that's going to be the case with AI. Very good, very good panel. This has been very interesting. Thank y'all for being here and I you back.

Speaker 11 [12:51:56 PM]
Gentleman yields back and I recognize Miss um Ocasio-Cortez from New York for her 5 minutes of questioning.

Speaker 16 [12:52:04 PM]
Thank you so much, Madam Chairwoman, and thank you to our witnesses, uh, for being here today. Uh, and I want to kind of dig into a topic that's come up several times over the course of this hearing, uh, which is this area of prior authorization. Now, generally I like to take a step back so that folks at home can kind of understand what it is exactly that we're talking about here. I think most people hear the term prior authorization and understandably our eyes start glazing over in this bureaucratic language, but in the way that this affects our lives, is that if someone is diagnosed with a condition, an illness, a disease. They require medication treatment of some kind. They will, their doctor may recommend it to them, and that

Speaker 1 [12:52:54 PM]
doctor has to very

Speaker 16 [12:52:56 PM]
often, uh, depending on their insurance, ask their insurance for permission so that their insurance can say we will cover this treatment or we will not cover this treatment. And that is the process known as prior authorization. Is that in a fair description of it, Doctor

Speaker 2 [12:53:14 PM]
Mellow?

Speaker 10 [12:53:16 PM]
It is, and I would just add that it also applies to procedures and surgeries.

Speaker 16 [12:53:19 PM]
Yes. Um, and prior authorization oftentimes can be a really big headache and pain point for patients and doctors, and especially if you have interacted with a for-profit health insurance company, although all sorts of health insurance companies use a prior authorization. You've likely dealt with this, and there have been

Speaker 2 [12:53:43 PM]
famously,

Speaker 16 [12:53:44 PM]
I think, um, videos that have circulated on social media of doctors trying to haggle with an insurance company of everyday people trying to get navigate their chemotherapy or any other sort of condition with um the prior authorization system. And if you have a Medicare Advantage plan, which is the for-profit version of Medicare, you've definitely dealt with prior authorization. In fact, in 2023, Medicare Advantage for-profit health insurers filed over 100 times more uh prior authorization requests than traditional Medicare. And Medicare Advantage plans also deny care to patients at significantly higher rates than normal. Medicare Advantage plans deny as much as 16 times the normal rate. Does this sound consistent with some of what you've seen Doctor Mellow?

Speaker 10 [12:54:41 PM]
Yes, I believe that's what numerous reports have indicated.

Speaker 16 [12:54:43 PM]
And this is all to restrict patient care because we have a profit margin to maintain, and many of those for-profit insurers use unregulated and unsupervised AI models to review prior authorization requests. And I think it's very important that people understand that this is happening, that AI is being rolled out in the industry. So that when a doctor who has gone through 4 years of medical school in addition to their additional training. Say that a patient needs something, and they submit a prior authorization

Speaker 2 [12:55:22 PM]
request.

Speaker 16 [12:55:23 PM]
Many times in AI model may deny them that care to a human being who has gone through extensive medical training. Now, Mr. Toy, you've said earlier in this hearing that you are the CEO of Clover Health,

Speaker 2 [12:55:39 PM]
um.

Speaker 16 [12:55:41 PM]
but you've said in this hearing that Clover Health does not use AI in your company to implement uh prior authorizations, correct?

Speaker 3 [12:55:50 PM]
Correct.

Speaker 16 [12:55:50 PM]
And, but you have seen this happen in your industry.

Speaker 3 [12:55:54 PM]
That's correct.

Speaker 16 [12:55:55 PM]
And you disagree with this usage, why?

Speaker 3 [12:55:58 PM]
I disagree with it because it should always be a clinician who's making this decision. So I myself, as I said, I'm also a patient. I have had my own scans be denied through prior authorization. And I fortunately had the sophistication to navigate my own appeal, as you said, to to get there, but that is not a reasonable thing for 4 for for it to happen.

Speaker 16 [12:56:20 PM]
And for a person that is diagnosed with a condition in which time is of the essence. and in AI model has denied a

Speaker 2 [12:56:31 PM]
trained

Speaker 16 [12:56:33 PM]
clinician, the ability to provide them care. This could potentially threaten a person's life, correct?

Speaker 3 [12:56:40 PM]
Absolutely, timely care is critical in many cases.

Speaker 16 [12:56:42 PM]
And so we are seeing certain healthcare companies and on top of

Speaker 2 [12:56:47 PM]
that,

Speaker 16 [12:56:47 PM]
the Trump administration has planned to launch a new program to expand the use of AI in prior authorizations known as WISE Beyond Medicare Advantage and into regular Medicare recipients. Um, Mr. Toy, it is not your company's plans to participate in the WISE program, correct?

Speaker 3 [12:57:11 PM]
That's correct. We are not participating. And

Speaker 16 [12:57:12 PM]
you have no plans to,

Speaker 3 [12:57:13 PM]
and we have no plans to.

Speaker 16 [12:57:14 PM]
Thank you very much. And I go back my time. Thank

Speaker 2 [12:57:17 PM]
you,

Speaker 11 [12:57:18 PM]
gentlewoman yields back and I recognize my good friend from California, Representative Oberote for his 5 minutes of

Speaker 2 [12:57:24 PM]
questions.

Speaker 7 [12:57:26 PM]
Oh, thank you very much, Madam Chair, and thank you to our

Speaker 6 [12:57:28 PM]
panelists. I've really enjoyed this panel on one of my favorite topics, uh, Mr. Parker, I want to

Speaker 2 [12:57:32 PM]
start with you. Uh, I really enjoyed your

Speaker 7 [12:57:35 PM]
testimony about the impact that AI is going to have

Speaker 6 [12:57:38 PM]
on healthcare delivery and indeed it mirrors the findings that we made in the AI task force that I had the honor of chairing last year when we issued our report in December, we had a whole chapter on healthcare because honestly, there isn't a segment of the economy in the United States that's going to be more dramatically impacted by AI than healthcare. One thing I wanted to ask about though is that,

Speaker 2 [12:58:03 PM]
uh, you,

Speaker 1 [12:58:05 PM]
you

Speaker 6 [12:58:05 PM]
testified that as you see these startups come through that the most promising of them right now are the ones that uh use the application of AI to bring down administrative costs. Uh, and that actually mirrors what we found in our, uh, our task force reporters as well on health care. That's the seemingly the low hanging fruit that AI is going to bring first, uh, but you have to admit that if you're

Speaker 2 [12:58:30 PM]
a

Speaker 6 [12:58:31 PM]
uh, the average American that's a little disappointing, right? You know, we've been telling people for years how healthcare is gonna, how AI is going to aid in drug discovery, how it's going to aid in diagnosis, predictive diagnoses where there's pattern recognition and talking about risks you didn't even know existed tailored drug therapies that are tailored to your genome, you know, all of these things are what we've been promising people that AI is going to do, and we're coming now to them

Speaker 2 [12:58:54 PM]
with

Speaker 6 [12:58:55 PM]
it's, it's going to reduce your administrative costs, and that's what we're doing with it right now. Should people be disappointed about that, or is this just the first of many things to come?

Speaker 8 [12:59:04 PM]
Uh, thank you for the question and I think that is why I, you know, we're spending all of our energy on improving the customer experience and using AI in ways that create real tangible value to the inpatient, and I think I'm optimistic that those, those, uh, new experiences will help people be healthier, help them save money. And, and it's why our implementations are so pragmatic, right? I think everyone's always talked about how you can't get a price for anything in healthcare. So solving that, using AI is a very useful utility for the consumer.

Speaker 2 [12:59:36 PM]
I

Speaker 8 [12:59:36 PM]
think similar with the care plans, enabling consumers to be able to manage their health, understand what they should be doing as next steps is to me, what gets me up in the morning is helping patients realize the value of AI in their everyday life. It's not to diminish the value that will be created on the administrative side. I think that's low hanging fruit. There's a lot of opportunity there, um, but I'm personally most excited about the potential to impact the inpatient.

Speaker 6 [1:00:00 PM]
Right, well, let's not lose sight of that optimistic vision because I, I fear that when we start talking about how we're using AI today to automate note taking, to automate billing, you know, that that's going to distract away from what AI could do. Uh, Doctor Mello, I was really interested in your testimony. You were talking about how do we

Speaker 2 [1:00:18 PM]
get

Speaker 6 [1:00:20 PM]
Americans to trust the use of AI, especially in a domain as important to them as their healthcare, and you talked about a foundational trust deficit, which uh I very much agree with. That was one of our key findings, not just in healthcare, but over and over and over again as we did our task force hearings last year was the fact that Americans really don't trust this new technology, and in some ways they're right not to trust it because it is new. But another thing that you said that I'm not sure I agree with is that the solution to this is government certification, uh, standard settings, disclosure requirements, uh

Speaker 2 [1:01:01 PM]
and I'm not sure,

Speaker 6 [1:01:02 PM]
I mean, in my understanding of why that trust deficit exists is because Americans don't have a very realistic view of what AI is and what it isn't what it does and what it doesn't do. The way it works and what the real risks of AI are. And I don't think that uh short of educating them on those issues that just telling them that while the government says it's safe and so you ought to trust it is going to do the trick. Would you, would you agree with that or would you disagree?

Speaker 10 [1:01:28 PM]
I would, but to be clear, what I'm suggesting is that there be requirements that institutions do governance because hospitals and physician practices, they're the ones that are best situated to understand their patients, their staff, and what can go wrong. I spend a lot of time interviewing patients as part of my work at Stanford, including patients who are very sophisticated about AI. They're part of a learning community. And the message I consistently get from them is we expect you to be looking at this

Speaker 2 [1:01:55 PM]
stuff,

Speaker 10 [1:01:56 PM]
especially when policymakers turn to things like consent and disclosure requirements in lieu of requiring things that will actually keep them safe. Can the government do this directly? No. But does it need to provide additional incentives and nudges for organizations to do it. Yes.

Speaker 6 [1:02:12 PM]
Yeah, I just want to make sure we don't conflate the two because I think with absent

Speaker 2 [1:02:16 PM]
that, that

Speaker 6 [1:02:17 PM]
uh education, I think that foundational trust issue is going to continue to exist and it's going to be an impediment to deploying AI not just in healthcare, but in a lot of different productive domains. Anyway, I could talk about this all day. Thank you very much to our panelists. I've really enjoyed the hearing. Are you

Speaker 2 [1:02:31 PM]
back.

Speaker 11 [1:02:32 PM]
Gentleman Neil's back, and I recognize my good friend from Ohio, Representative Greg Lazman for his five minutes of questions.

Speaker 14 [1:02:40 PM]
Uh

Speaker 12 [1:02:40 PM]
thank you, Madam Chairwoman, and uh ranking member, uh, to get for uh today's hearing,

Speaker 2 [1:02:48 PM]
uh,

Speaker 12 [1:02:48 PM]
on the use of AI in in our healthcare system. Obviously, as, as we've heard, there are so many opportunities to improve care and uh to lower

Speaker 2 [1:03:00 PM]
costs.

Speaker 12 [1:03:01 PM]
There are also enormous dangers, uh, associated with this and I wanna talk about the medica uh Medicare piece and uh this uh potential new program that the administration has announced. Um because Ohio is one of the states. So this, this is urgent for us,

Speaker 2 [1:03:24 PM]
uh,

Speaker 12 [1:03:24 PM]
and I wanna make sure that this committee, which I

Speaker 2 [1:03:28 PM]
think

Speaker 12 [1:03:29 PM]
will appreciate the need for some bipartisan pushback and guardrails here. Uh, we'll act because it is going to be our seniors in Ohio and in Texas and and and the other states, uh, that may get hurt and we don't, we don't want that to happen. Um, but as you all know, for, for decades, tens of millions of Americans have seniors have paid for and relied on on Medicare, uh, for their healthcare needs. Uh, the administration announced this new effort that will require pre-authorization. pre-approval uh, for procedures.

Speaker 2 [1:04:09 PM]
uh

Speaker 12 [1:04:10 PM]
under Medicare.

Speaker 2 [1:04:12 PM]
Uh,

Speaker 12 [1:04:12 PM]
and it's been referred to as the AI death panel. in that you're taking what private health

Speaker 2 [1:04:24 PM]
insurance

Speaker 12 [1:04:25 PM]
companies do now in terms of denying care, care that ultimately leads to the loss of life, and you're handing it over as I've, as I understand it, to a tech company that is going to use an AI model that has not been vetted. Um, and to make matters worse, uh, the incentive is there to deny the claim. You get more money if you're that AI tech, uh, uh company. If you're, if you're able to deny more and more claims. That is going to lead to people getting hurt. Uh, and I, I do again think there is a bipartisan desire to to ensure this doesn't happen. Uh,

Speaker 2 [1:05:09 PM]
the

Speaker 12 [1:05:11 PM]
the doctor and the patient should determine. what care is needed and we all agree on that. Uh, and while AI could provide some additional insight. I, I

Speaker 2 [1:05:25 PM]
think

Speaker 12 [1:05:26 PM]
Doctor Mella, you, you talked a little bit about what needs to happen. Um, but I wanted to get your thoughts on the legal, moral, and

Speaker 2 [1:05:37 PM]
health.

Speaker 12 [1:05:39 PM]
challenges that this new program. uh

Speaker 2 [1:05:44 PM]
creates.

Speaker 10 [1:05:48 PM]
As you pointed out, the reimbursement model for these tech companies really stands the concept of shared savings on its head. You know, shared savings evolved in the Medicare program to give healthcare organizations incentives to take better care of people and then when they got better if they saved money on expensive procedures that the healthcare organization got to save that money. This is flipped. Now they're gonna make more money by denying care. And yes, there are safeguards, there are procedural safeguards to prevent the worst abuses, but that is a very weird reimbursement model for what they're trying to do here. The other thing I would point out is there, there is some political genius in the architecture of this program in that they have chosen to begin with a small set of procedures that most people who do what I do for a living and assess health services would say we're providing too much of they are expensive and there's a very thin to no evidence base. The question is, where does this program go in the future? And the problem is going to be that we don't have national coverage determinations to expand it in ways that can protect beneficiaries.

Speaker 12 [1:06:49 PM]
Yeah, I, until we have those answers, until we have those assurances, I think that the, the, uh, the pilot should be stopped and, and hopefully they'll be support to stop it uh because you mentioned I want to just do this very quickly and, and others have agreed or reiterated. that there should be disclosure of the product, full disclosure of the products being

Speaker 2 [1:07:12 PM]
used

Speaker 12 [1:07:13 PM]
seems smart enough

Speaker 2 [1:07:16 PM]
that

Speaker 12 [1:07:17 PM]
uh there's full vetting of those products that an independent review board, uh, and maybe the Joint commission, as you, as you mentioned, can serve as, as that review, uh, board, deal with the liability questions and ensure that this doesn't touch. uh, quite frankly, anything that could harm

Speaker 2 [1:07:39 PM]
patients.

Speaker 12 [1:07:40 PM]
Uh, and, and, and until we have that, I think the, the, the program should be shut down, should, should they, and, and, and, and, and I'll help lead on that. Uh, sorry, my time ran ran out. You're

Speaker 11 [1:07:52 PM]
back, gentlemen, yieldsack, and I recognized my good friend from Florida Representative Kemmick for her 5 minutes of questions. And the new mama by the way, congratulations.

Speaker 15 [1:08:05 PM]
A new mama who's actually got to go pump. So I'll make this

Speaker 2 [1:08:07 PM]
quick.

Speaker 15 [1:08:09 PM]
So thank you, Madam Chairwoman, and thank you to my wonderful colleagues for letting me jump the line and to our witnesses for being here. This is really important as we're grappling with all the new technology and all the opportunities, but also some of the challenges along with it. So, uh, we know that healthcare and AI have incredible opportunities and potential. We're seeing it speed up drug development, cutting down on paperwork, uh, and giving the doctors and patients more time, which is really the upside, the good side that has been talked about at length here today. I really do appreciate a lot of, uh, the commentary on data privacy as well. So when we're talking about these potentials, we need to also examine the downsides, which has been, few have been highlighted here today. We all agree that AI should never replace a doctor's judgment, and it shouldn't become another way for bureaucrats, uh, or swamp creatures as I call them, or big corporations to pull strings. Patients deserve to know that their data is safe, their privacy is respected, and that their care is being guided by people, not just algorithms. So in my district, the University of Florida, AKA the Everything school. Uh, we are testing some of the most exciting applications of AI from digital twins of ICU units to patient level models that help predict the most effective treatments and outcomes in tough cases like cancer. We're showing what's possible.

Speaker 2 [1:09:28 PM]
So I wanna highlight

Speaker 15 [1:09:30 PM]
that, but also talk to you guys about some data privacy issues that we're wrestling with. So I'm going to start with you, Doctor Ibrahim. As I mentioned, my district, un of Florida, Gator Nation. I keep having to say that, you know, lots of national titles, 5 in the country, just putting that out there for my fellow SEC friends here on the, the, the, the committee. Uh, researchers are using digital twins to not just replicate hospital units like uh the ICU and operating rooms, but also to model individual patient trajectories in complex cases like cancer or intensive care. How close are we to seeing this type of patient-level digital twin technology guiding real-time treatment decisions nationwide and beyond direct care, what role do you see digital twins playing in education and training, particularly for providers in smaller or rural hospitals who don't have access to some of this cutting edge technology.

Speaker 9 [1:10:24 PM]
Thank you so much for the question and I'll keep my big 10 thoughts to myself. Um, the, um, importance of this technology in rural communities is incredibly important. And um in our own program, we've done discounted rates to help ensure that rural hospitals can participate about 25% of our hospitals are in rural communities, um, and they're often partnering with large communities, a large,

Speaker 2 [1:10:47 PM]
um

Speaker 9 [1:10:48 PM]
hospitals, so they can have some coordination of care and triaging and sharing of expertise. Your question about our ability to identify better treatment plans for patients is super important. One of the things we've spent a lot of time on is finding diagnoses that potentially could have been caught sooner or weren't identified initially. One example was hypertrophic cardiomyopathy, where we've looked back in old EKGs and rerun our models and found that for many patients we could have diagnosed years earlier. So I think in the current state, we have the ability to diagnose things faster. Um, I think the future state you described that we could actually tailor a unique novel treatment. I think that's in its infancy. It's certainly in the pipeline and horizon, but I think in today, we can point to that we are able to diagnose people faster, whether how well we can tailor the treatment, um, is still um nascent but coming very quickly.

Speaker 15 [1:11:42 PM]
How soon do you expect the digital twin technology utilizing someone's medical history, their chart, their DN A biometrics, how, how soon do you see that being regular and commonplace.

Speaker 9 [1:11:52 PM]
I think for common conditions because the, the hitch of these models is having enough patiences to train on. So for common conditions, I think that's very plausible within the next year or two, and there's probably some pilots that already exist for more rare conditions, nuanced, novel, cancers and things. I think we're more than a couple of years away.

Speaker 2 [1:12:12 PM]
OK.

Speaker 15 [1:12:12 PM]
I appreciate that. Thank you. I'm gonna go to uh you, Mr. Toy, um, as we talked about, UF is pioneering immune system, digital twins to personalized treatment and developing synthetic data that allows AI to train without risking patient privacy. From your perspective, kin synthetic data and patient-level digital twins serve as a foundation for fair coding and care management across pairs. And also what safeguards are needed to ensure that they don't become tools that privatize patient data or constrain physician judgment.

Speaker 3 [1:12:45 PM]
Yes, absolutely. So a very interesting question. So number one, doing the second part first, I think there's a there's a lot of privacy implications around digital twin technology. There's a lot of upside, but literally, if you are making a digital Twitter for yourself, you probably want to know how that's going to be used, scary, right? So, so it can be a little scary. So I think the answer is we haven't solved all of that yet, but there are technologies that will help with this. So I think that what's probably gonna end up happening is you're not making a full twin as in it's literally my thing moving around and being used, that's gonna have too many privacy implications, but it' s going to be sort of like a collective model of people who are kind of like me that can then be analyzed and processed, so I don't have, I have fewer privacy concerns.

Speaker 15 [1:13:24 PM]
OK. And I know my time has expired, but I'll submit for the record some questions about uh Deonna deanonymization of data and some of the honest broker questions that surround that. But thank you all so much for your time and thank you to my colleagues again for your understanding. Thank you,

Speaker 11 [1:13:39 PM]
gentlewoman yields back, and I now recognize my friend from, uh, Indiana, Representative Houghton for her finance

Speaker 2 [1:13:45 PM]
questions.

Speaker 1 [1:13:46 PM]
Thank you, Madam Chair. Um, I appreciate all the panelists' testimony today. This has been

Speaker 15 [1:13:51 PM]
a great hearing and, and I think one that's much needed. I am particularly uh interested in hearing from Doctor Wright, uh, and I wanna just expound upon the the written testimony that you've provided. You've

Speaker 5 [1:14:03 PM]
said AI is a tool built by humans for human systems. Therefore, a deep understanding of human cognition and behavior must be central

Speaker 15 [1:14:10 PM]
to its deployment to ensure effective ethical and equitable, uh, use of the technology. I couldn't agree more. I think the American Psychological Association probably will be playing a big role, hopefully in ensuring that, and I appreciate that you've asked the FTC for um and the CPSC for an investigation into um

Speaker 1 [1:14:32 PM]
unregulated products

Speaker 15 [1:14:33 PM]
making claims of being a psychologist, um, that's particularly dangerous and um I joined your call for information from the FTC um

Speaker 2 [1:14:45 PM]
on

Speaker 5 [1:14:46 PM]
the health disparities that you mention in your

Speaker 15 [1:14:48 PM]
comments. I, I do think, and I think Mr. Landsman alluded to this too, that, that, that does create concerns for rationing care, uh, and it resurrects fears of death panels and other things if AI is in the mix, and I think that we have to be particularly concerned about

Speaker 2 [1:15:04 PM]
that.

Speaker 5 [1:15:06 PM]
But my focus of my comments is really on the impact on youth

Speaker 15 [1:15:09 PM]
and children, teens and children, um, you know, we know the reports and we've heard them today. The New York Times, The Wall Street Journal, uh, raising concerns about how children have been engaging with AI chatbots and companions and while I'm encouraged that companies like um OpenAI and Meta have updated their policies. I think we have to be thoughtful in understanding how these technologies are being used, what risks they pose to children and teens and and to our vulnerable Americans, uh, and, and what we should be thinking about as policymakers for those protections that need to be in place. Uh, the risks, the benefits, how families can be equipped with necessary tools. So, uh, you mentioned in your um in your comments that we should require age-appropriate safeguards, uh, and robust data protections to support healthy development. When we passed the Kids Online Privacy Protection Act in 199 8 enacted in 2000, uh, we couldn't possibly have imagined the threats to children and teens that we see today through social media interactions and others, and I think that um this issue is is exacerbated by access to chatbots as we've recently seen. Um, so I, I guess uh several questions that I have for you, and then I'll let you expound on, on this. It is

Speaker 2 [1:16:31 PM]
um

Speaker 15 [1:16:33 PM]
what should we be thinking about as policymakers to protect children from harm? Should we consider limits such as age restrictions on access to AI chatbot bots from children and teens. Uh, should we consider disruptors, periodic interruptions within the chatbot that reminds the user that it's not a human and that uh it's not um licensed mental health professional.

Speaker 2 [1:16:55 PM]
What things

Speaker 15 [1:16:56 PM]
are we not thinking about to further protect children from harm, um, COA 1.0 basically set an online standard that a 13 year old is an adult online and um we know now that the highest rate of teen suicide among 5 is among 15 year old males. Uh, so I think we have a lot of work to do in this arena, and I welcome your input.

Speaker 1 [1:17:22 PM]
Thank you so much for, um, that incredibly important question.

Speaker 2 [1:17:25 PM]
Um,

Speaker 1 [1:17:27 PM]
I, I think that there are probably several things we could try, we could try age restriction, we could try cutting people off the platform when they're on for a prolonged period of time, we could um roll out, you

Speaker 2 [1:17:41 PM]
know, uh

Speaker 1 [1:17:42 PM]
parent programs where they linked to the kids, we could, you know, as I mentioned earlier, have disclosures around detected suicidality. Really, the thing is, though, these are all empirical questions. What we actually need is independent research looking at what the problem is and what the solutions ought to be and those should be empirically driven, not just us kind of throwing spaghetti at the wall because it makes sense at the time, and so I think that really requires a greater investment in research. of these products and in particular research that happens before they go to the marketplace.

Speaker 15 [1:18:17 PM]
Yeah, I, I thank you so much for, for, um, for your note about that because I do agree that we have to require independent testing on the harms, almost like sandboxing some of these technologies before they go live to make sure that we're adequately protecting the public. I also agree with you that we need to be distributing educational materials to parents, uh, and, and maybe through our school systems about the dangers of AI chat bots. Thank you all for your testimony. I yield

Speaker 2 [1:18:44 PM]
back.

Speaker 11 [1:18:45 PM]
Gentlewoman yields back, and I now recognize my friend from North Dakota, uh, Representative Fedorzek for her 5 minutes of

Speaker 2 [1:18:52 PM]
questions. Thank

Speaker 1 [1:18:56 PM]
you, Madam Chair. Oops, a chatbox is talking to me right now. Sorry about that. Thank you all for your um participation today. It's been a great panel. Uh, there's been a lot of talk about context. I want to take an even bigger context than what's been referenced today and look more broadly, um, 50, there's been a 50% increase in total national health expenditures since 2019. By 2028, projections call for healthcare spending to consume nearly 20% of our nation's GDP.

Speaker 2 [1:19:32 PM]
Health

Speaker 15 [1:19:33 PM]
insurance premiums are skyrocketing. And for all this additional money that we're spending, our actual health outcomes are not improving at all. In fact, many indicators suggest we're getting less healthy. So, and what I've learned, I've only been here for 8 months, is when you talk to the different players in healthcare industry. It's a lot of this. Somebody else is to blame. So enter AI, which I think has very serious, you know, downfalls and potential risks,

Speaker 1 [1:20:05 PM]
but also incredible upsides which many of

Speaker 15 [1:20:07 PM]
you have highlighted today.

Speaker 2 [1:20:09 PM]
So

Speaker 1 [1:20:09 PM]
I want to drill into some of those. In your um conversation with Mr. Landsman, he correctly outlined some concerns about the pre-au. When

Speaker 15 [1:20:18 PM]
I go home

Speaker 1 [1:20:20 PM]
and talk to healthcare

Speaker 15 [1:20:21 PM]
providers. This is their biggest issue is how much time and expense and delays it takes to get through the pre-auth process. So how can we use AI and not just say AI is bad. It has to be, you know, it has to only be human beings. How can we use AI and provide the right guidelines and parameters to protect against the death panels and these blanket, you know, disapprovals, but use the best of it to help us improve the pria situation so that patients get, get their care faster. And I'll turn that over to you, Mr. Parker and Mr. Toy.

Speaker 1 [1:21:02 PM]
A lot

Speaker 2 [1:21:03 PM]
of

Speaker 1 [1:21:04 PM]
conversation today about prior authorization and automating both sides of that transaction, but we've heard a little conversation about how to actually help the consumer navigate that problem, um, and very little sort of investment and energy into that. And so our frame of reference here is how do we enable the consumer to both understand what their options are, understand what the price is. And in the world with a prior authors required help them both navigate that prior auth and ultimately get it approved if it's appropriate. And I think if we can reorient a bunch of this energy into that experience. And, and oftentimes that might mean that there's a, there's a lower level of acuity, a lower level of care that's more appropriate. And the concern might be happy to, to utilize that level of care. They just don't have any of that information. They don't really understand, uh, how to navigate any of this. And so we're super focused on how do you help the consumer figure out the right level of care and in a world where that does require a prior auth, help them get that prior auth approved.

Speaker 3 [1:21:59 PM]
OK, and I'm gonna come back to you with a follow-up question after Mr. Choi speaks, but the question will be, what do we need in terms of rules, guidelines, or incentives to make that happen. So Mr. Toy.

Speaker 4 [1:22:12 PM]
Yes sir thank you for the question. So, so something that um I think can definitely help is that um something I used my experience at Clover for since we run a plan is I actually advise on the Marfan Foundation for the Rare Disease, I advise our expert clinicians and I advise patients on how to navigate their own prior au. So you can think about that as using expertise to say this is how you talk to an insurance company to get them to cover your care. And so something we're looking at doing it on the Kaluver side is providing actually that in a chatbot form, so that people can say, hey, this is what I'm trying to get covered. What's the right way to get that covered, and then that will synthesize the data, we're all the documentation for you, package it up, phrase it in a way that makes it easy for the insurance company to say yes to, and I think that will greatly help.

Speaker 3 [1:22:55 PM]
Mr. Mr. Parker. How do we incentivize

Speaker 2 [1:22:58 PM]
this

Speaker 1 [1:22:59 PM]
I, I largely agree with that. I think we're, we're building a very similar experience where we can take your full medical record. Use AI to analyze it, help justify what procedure or medication you might need based on your clinical record and then to Mr. Toi's point, package that up in a way that the insurance company can approve that. And I think this is a place where the AI is very capable, and the, the data is now available enough to make that experience really possible. Um, and I do think it's a place where if you can execute that customer experience, it will both be more convenient, more sort of understandable and ultimately help them get these things approved.

Speaker 3 [1:23:37 PM]
OK, I have 20 seconds left. Does anyone else have short thoughts to offer?

Speaker 5 [1:23:42 PM]
I just say there's enormous opportunity that we're trying to explore that the things that you need for prior authorization are predictable. They're public information, they're online. Wouldn't it be great to know that when a patient's in front of you, I just have to ask him these two more things, and that'll meet the 10 things that I need to do. So we're exploring other real-time ways to notify physicians of what else is left on that checklist, so that before the patient goes home and then you have to bring them back and require new things. So in the

Speaker 2 [1:24:08 PM]
works.

Speaker 3 [1:24:09 PM]
Very good. Thank you. I appreciate your insights

Speaker 2 [1:24:11 PM]
today.

Speaker 6 [1:24:12 PM]
OK, the gentlewoman yields back, I ask unanimous consent to insert in the records and documents included on the staff hearing documents list and without objection, so

Speaker 2 [1:24:21 PM]
ordered.

Speaker 6 [1:24:22 PM]
And I'd like to thank, uh, all of the witnesses for being here today. We have talked about how good this panel has been and members may have additional written questions for you all, and I'll remind members that they have 10 business days to submit questions for the record, and I asked the witnesses to respond to questions promptly. Members should uh submit their questions by the close of business on Wednesday, September 17th, and without objection, the subcommittee is adjourned. Thank you

Speaker 2 [1:24:49 PM]
all